//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-36037853
// Cuda compilation tools, release 12.9, V12.9.86
// Based on NVVM 7.0.1
//

.version 8.8
.target sm_86
.address_size 64

	// .globl	_Z15sampleLensPointfff
.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
.visible .const .align 4 .f32 R2_G = 0f3FA9905C;
.visible .const .align 4 .f32 R2_A1 = 0f3F413FAA;
.visible .const .align 4 .f32 R2_A2 = 0f3F11E10E;
.const .align 1 .b8 __nv_static_39__84590ad7_21_optix_milo_kernels_cu_R2_G__ZN48_INTERNAL_84590ad7_21_optix_milo_kernels_cu_R2_G6shared16PermutationTableE[76] = {0, 10, 2, 7, 3, 5, 6, 4, 8, 1, 9, 5, 11, 6, 8, 1, 10, 12, 9, 3, 7, 0, 4, 2, 13, 10, 11, 5, 6, 9, 4, 3, 8, 7, 14, 2, 0, 1, 15, 12, 1, 13, 5, 14, 12, 3, 6, 16, 0, 8, 9, 2, 11, 4, 15, 7, 10, 10, 6, 5, 8, 15, 0, 17, 7, 14, 18, 13, 16, 2, 9, 12, 1, 11, 4, 3};
.weak .global .align 4 .b8 _Z18mx_fresnel_schlickfRK5RGB_TIfE$137[12] = {0, 0, 128, 63, 0, 0, 128, 63, 0, 0, 128, 63};
.weak .global .align 4 .b8 _Z29mx_ggx_importance_sample_VNDFRK10Vector2D_TIfERK10Vector3D_TIfLb0EES2_$155[12] = {0, 0, 128, 63};
.weak .global .align 4 .b8 _Z26mx_ggx_energy_compensationffRK5RGB_TIfE$179[12] = {0, 0, 128, 63, 0, 0, 128, 63, 0, 0, 128, 63};
.extern .const .align 8 .b8 plp[424];
.global .align 1 .b8 $str[38] = {101, 110, 118, 105, 114, 111, 32, 116, 101, 120, 116, 117, 114, 101, 32, 101, 109, 105, 116, 116, 97, 110, 99, 101, 58, 32, 37, 102, 44, 32, 37, 102, 44, 32, 37, 102, 10};
.weak .global .align 4 .b8 _Z15sampleAreaLightRK9Point3D_TIfEfffPN11milo_shared11LightSampleEPf$286[12];
.weak .global .align 4 .b8 _Z19computeSurfacePointRKN6shared20GeometryInstanceDataEjffRK9Point3D_TIfEPS4_P10Vector3D_TIfLb1EEPS8_IfLb0EESA_P9Point2D_TIfEPf$366[12] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 63};
.weak .global .align 4 .b8 _Z19computeSurfacePointRKN6shared20GeometryInstanceDataEjffRK9Point3D_TIfEPS4_P10Vector3D_TIfLb1EEPS8_IfLb0EESA_P9Point2D_TIfEPf$367[12] = {0, 0, 128, 63};
.global .align 1 .b8 $str$1[79] = {77, 105, 108, 111, 69, 110, 103, 105, 110, 101, 32, 82, 71, 58, 32, 116, 114, 97, 118, 72, 97, 110, 100, 108, 101, 61, 37, 108, 108, 117, 44, 32, 111, 114, 105, 103, 105, 110, 61, 40, 37, 46, 50, 102, 44, 37, 46, 50, 102, 44, 37, 46, 50, 102, 41, 44, 32, 100, 105, 114, 61, 40, 37, 46, 50, 102, 44, 37, 46, 50, 102, 44, 37, 46, 50, 102, 41, 10};
.weak .global .align 4 .b8 _ZNK16DisneyPrincipled8evaluateERK10Vector3D_TIfLb0EES3_$908[12] = {0, 0, 128, 63, 0, 0, 128, 63, 0, 0, 128, 63};
.weak .global .align 4 .b8 _ZNK16DisneyPrincipled8evaluateERK10Vector3D_TIfLb0EES3_$909[12] = {10, 215, 163, 61, 10, 215, 163, 61, 10, 215, 163, 61};
.weak .global .align 4 .b8 _ZNK16DisneyPrincipled8evaluateERK10Vector3D_TIfLb0EES3_$910[12] = {0, 0, 128, 63, 0, 0, 128, 63, 0, 0, 128, 63};
.weak .global .align 4 .b8 _ZNK16DisneyPrincipled29evaluateDHReflectanceEstimateERK10Vector3D_TIfLb0EE$1099[12] = {10, 215, 163, 61, 10, 215, 163, 61, 10, 215, 163, 61};

.visible .func  (.param .align 4 .b8 func_retval0[12]) _Z15sampleLensPointfff(
	.param .b32 _Z15sampleLensPointfff_param_0,
	.param .b32 _Z15sampleLensPointfff_param_1,
	.param .b32 _Z15sampleLensPointfff_param_2
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<31>;
	.reg .b32 	%r<2>;


	ld.param.f32 	%f1, [_Z15sampleLensPointfff_param_0];
	ld.param.f32 	%f2, [_Z15sampleLensPointfff_param_1];
	ld.param.f32 	%f3, [_Z15sampleLensPointfff_param_2];
	mul.ftz.f32 	%f4, %f1, 0f41100000;
	cvt.rzi.ftz.s32.f32 	%r1, %f4;
	cvt.rn.f32.s32 	%f5, %r1;
	fma.rn.ftz.f32 	%f6, %f5, 0fBDE38E39, %f1;
	mul.ftz.f32 	%f7, %f6, 0f41100000;
	mul.ftz.f32 	%f8, %f5, 0f40490FDB;
	mov.f32 	%f9, 0f40900000;
	div.approx.ftz.f32 	%f10, %f8, %f9;
	add.ftz.f32 	%f11, %f5, 0f3F800000;
	mov.f32 	%f12, 0f3F800000;
	mul.ftz.f32 	%f13, %f11, 0f40490FDB;
	div.approx.ftz.f32 	%f14, %f13, %f9;
	cos.approx.ftz.f32 	%f15, %f10;
	sin.approx.ftz.f32 	%f16, %f10;
	cos.approx.ftz.f32 	%f17, %f14;
	sin.approx.ftz.f32 	%f18, %f14;
	add.ftz.f32 	%f19, %f7, %f2;
	setp.gt.ftz.f32 	%p1, %f19, 0f3F800000;
	sub.ftz.f32 	%f20, %f12, %f2;
	sub.ftz.f32 	%f21, %f12, %f7;
	selp.f32 	%f22, %f20, %f2, %p1;
	selp.f32 	%f23, %f21, %f7, %p1;
	mul.ftz.f32 	%f24, %f17, %f23;
	fma.rn.ftz.f32 	%f25, %f15, %f22, %f24;
	mul.ftz.f32 	%f26, %f18, %f23;
	fma.rn.ftz.f32 	%f27, %f16, %f22, %f26;
	mul.ftz.f32 	%f28, %f27, %f3;
	mul.ftz.f32 	%f29, %f25, %f3;
	mov.f32 	%f30, 0f00000000;
	st.param.f32 	[func_retval0+0], %f29;
	st.param.f32 	[func_retval0+4], %f28;
	st.param.f32 	[func_retval0+8], %f30;
	ret;

}
	// .globl	_Z17generateCameraRayRN6shared8PCG32RNGERKN11milo_shared17PerspectiveCameraERK9Point2D_TIfEP9Point3D_TIfEP10Vector3D_TIfLb0EE
.visible .func _Z17generateCameraRayRN6shared8PCG32RNGERKN11milo_shared17PerspectiveCameraERK9Point2D_TIfEP9Point3D_TIfEP10Vector3D_TIfLb0EE(
	.param .b64 _Z17generateCameraRayRN6shared8PCG32RNGERKN11milo_shared17PerspectiveCameraERK9Point2D_TIfEP9Point3D_TIfEP10Vector3D_TIfLb0EE_param_0,
	.param .b64 _Z17generateCameraRayRN6shared8PCG32RNGERKN11milo_shared17PerspectiveCameraERK9Point2D_TIfEP9Point3D_TIfEP10Vector3D_TIfLb0EE_param_1,
	.param .b64 _Z17generateCameraRayRN6shared8PCG32RNGERKN11milo_shared17PerspectiveCameraERK9Point2D_TIfEP9Point3D_TIfEP10Vector3D_TIfLb0EE_param_2,
	.param .b64 _Z17generateCameraRayRN6shared8PCG32RNGERKN11milo_shared17PerspectiveCameraERK9Point2D_TIfEP9Point3D_TIfEP10Vector3D_TIfLb0EE_param_3,
	.param .b64 _Z17generateCameraRayRN6shared8PCG32RNGERKN11milo_shared17PerspectiveCameraERK9Point2D_TIfEP9Point3D_TIfEP10Vector3D_TIfLb0EE_param_4
)
{
	.reg .pred 	%p<3>;
	.reg .f32 	%f<108>;
	.reg .b32 	%r<12>;
	.reg .b64 	%rd<20>;


	ld.param.u64 	%rd4, [_Z17generateCameraRayRN6shared8PCG32RNGERKN11milo_shared17PerspectiveCameraERK9Point2D_TIfEP9Point3D_TIfEP10Vector3D_TIfLb0EE_param_0];
	ld.param.u64 	%rd5, [_Z17generateCameraRayRN6shared8PCG32RNGERKN11milo_shared17PerspectiveCameraERK9Point2D_TIfEP9Point3D_TIfEP10Vector3D_TIfLb0EE_param_2];
	ld.param.u64 	%rd2, [_Z17generateCameraRayRN6shared8PCG32RNGERKN11milo_shared17PerspectiveCameraERK9Point2D_TIfEP9Point3D_TIfEP10Vector3D_TIfLb0EE_param_3];
	ld.param.u64 	%rd3, [_Z17generateCameraRayRN6shared8PCG32RNGERKN11milo_shared17PerspectiveCameraERK9Point2D_TIfEP9Point3D_TIfEP10Vector3D_TIfLb0EE_param_4];
	ld.param.u64 	%rd6, [_Z17generateCameraRayRN6shared8PCG32RNGERKN11milo_shared17PerspectiveCameraERK9Point2D_TIfEP9Point3D_TIfEP10Vector3D_TIfLb0EE_param_1];
	add.s64 	%rd1, %rd6, 4;
	ld.f32 	%f4, [%rd6+4];
	mul.ftz.f32 	%f5, %f4, 0f3F000000;
	mov.f32 	%f6, 0f3F000000;
	sin.approx.ftz.f32 	%f7, %f5;
	cos.approx.ftz.f32 	%f8, %f5;
	div.approx.ftz.f32 	%f9, %f7, %f8;
	add.ftz.f32 	%f10, %f9, %f9;
	ld.f32 	%f11, [%rd6];
	mul.ftz.f32 	%f12, %f11, %f10;
	ld.f32 	%f13, [%rd5];
	sub.ftz.f32 	%f14, %f6, %f13;
	mul.ftz.f32 	%f15, %f12, %f14;
	ld.f32 	%f16, [%rd6+20];
	ld.f32 	%f17, [%rd6+24];
	ld.f32 	%f18, [%rd6+28];
	ld.f32 	%f19, [%rd5+4];
	sub.ftz.f32 	%f20, %f6, %f19;
	mul.ftz.f32 	%f21, %f10, %f20;
	ld.f32 	%f22, [%rd6+32];
	mul.ftz.f32 	%f23, %f22, %f21;
	ld.f32 	%f24, [%rd6+36];
	mul.ftz.f32 	%f25, %f24, %f21;
	ld.f32 	%f26, [%rd6+40];
	mul.ftz.f32 	%f27, %f21, %f26;
	fma.rn.ftz.f32 	%f28, %f16, %f15, %f23;
	fma.rn.ftz.f32 	%f29, %f17, %f15, %f25;
	fma.rn.ftz.f32 	%f30, %f15, %f18, %f27;
	ld.f32 	%f31, [%rd6+44];
	add.ftz.f32 	%f1, %f28, %f31;
	ld.f32 	%f32, [%rd6+48];
	add.ftz.f32 	%f2, %f29, %f32;
	ld.f32 	%f33, [%rd6+52];
	add.ftz.f32 	%f3, %f30, %f33;
	ld.f32 	%f34, [%rd6+56];
	setp.gt.ftz.f32 	%p1, %f34, 0f00000000;
	@%p1 bra 	$L__BB1_2;
	bra.uni 	$L__BB1_1;

$L__BB1_2:
	ld.u64 	%rd7, [%rd4];
	mul.lo.s64 	%rd8, %rd7, 6364136223846793005;
	add.s64 	%rd9, %rd8, 1;
	mul.lo.s64 	%rd10, %rd7, 7520897724310334953;
	shr.u64 	%rd11, %rd7, 18;
	xor.b64  	%rd12, %rd11, %rd7;
	shr.u64 	%rd13, %rd12, 27;
	cvt.u32.u64 	%r1, %rd13;
	shr.u64 	%rd14, %rd7, 59;
	cvt.u32.u64 	%r2, %rd14;
	shf.r.wrap.b32 	%r3, %r1, %r1, %r2;
	shr.u32 	%r4, %r3, 9;
	or.b32  	%r5, %r4, 1065353216;
	mov.b32 	%f45, %r5;
	add.ftz.f32 	%f46, %f45, 0fBF800000;
	add.s64 	%rd15, %rd10, 6364136223846793006;
	st.u64 	[%rd4], %rd15;
	shr.u64 	%rd16, %rd9, 18;
	xor.b64  	%rd17, %rd16, %rd9;
	shr.u64 	%rd18, %rd17, 27;
	cvt.u32.u64 	%r6, %rd18;
	shr.u64 	%rd19, %rd9, 59;
	cvt.u32.u64 	%r7, %rd19;
	shf.r.wrap.b32 	%r8, %r6, %r6, %r7;
	shr.u32 	%r9, %r8, 9;
	or.b32  	%r10, %r9, 1065353216;
	mov.b32 	%f47, %r10;
	add.ftz.f32 	%f48, %f47, 0fBF800000;
	mul.ftz.f32 	%f49, %f46, 0f41100000;
	cvt.rzi.ftz.s32.f32 	%r11, %f49;
	cvt.rn.f32.s32 	%f50, %r11;
	fma.rn.ftz.f32 	%f51, %f50, 0fBDE38E39, %f46;
	mul.ftz.f32 	%f52, %f51, 0f41100000;
	mul.ftz.f32 	%f53, %f50, 0f40490FDB;
	mov.f32 	%f54, 0f40900000;
	div.approx.ftz.f32 	%f55, %f53, %f54;
	add.ftz.f32 	%f56, %f50, 0f3F800000;
	mov.f32 	%f57, 0f3F800000;
	mul.ftz.f32 	%f58, %f56, 0f40490FDB;
	div.approx.ftz.f32 	%f59, %f58, %f54;
	cos.approx.ftz.f32 	%f60, %f55;
	sin.approx.ftz.f32 	%f61, %f55;
	cos.approx.ftz.f32 	%f62, %f59;
	sin.approx.ftz.f32 	%f63, %f59;
	add.ftz.f32 	%f64, %f52, %f48;
	setp.gt.ftz.f32 	%p2, %f64, 0f3F800000;
	sub.ftz.f32 	%f65, %f57, %f48;
	sub.ftz.f32 	%f66, %f57, %f52;
	selp.f32 	%f67, %f65, %f48, %p2;
	selp.f32 	%f68, %f66, %f52, %p2;
	mul.ftz.f32 	%f69, %f62, %f68;
	fma.rn.ftz.f32 	%f70, %f60, %f67, %f69;
	mul.ftz.f32 	%f71, %f63, %f68;
	fma.rn.ftz.f32 	%f72, %f61, %f67, %f71;
	ld.f32 	%f73, [%rd1+52];
	mul.ftz.f32 	%f74, %f73, %f70;
	mul.ftz.f32 	%f75, %f73, %f72;
	ld.f32 	%f76, [%rd1+16];
	ld.f32 	%f77, [%rd1+20];
	ld.f32 	%f78, [%rd1+24];
	ld.f32 	%f79, [%rd1+4];
	fma.rn.ftz.f32 	%f80, %f76, %f74, %f79;
	ld.f32 	%f81, [%rd1+8];
	fma.rn.ftz.f32 	%f82, %f77, %f74, %f81;
	ld.f32 	%f83, [%rd1+12];
	fma.rn.ftz.f32 	%f84, %f78, %f74, %f83;
	ld.f32 	%f85, [%rd1+28];
	ld.f32 	%f86, [%rd1+32];
	ld.f32 	%f87, [%rd1+36];
	fma.rn.ftz.f32 	%f88, %f85, %f75, %f80;
	fma.rn.ftz.f32 	%f89, %f75, %f86, %f82;
	fma.rn.ftz.f32 	%f90, %f75, %f87, %f84;
	st.f32 	[%rd2], %f88;
	st.f32 	[%rd2+4], %f89;
	st.f32 	[%rd2+8], %f90;
	ld.f32 	%f91, [%rd1+56];
	ld.f32 	%f92, [%rd1+4];
	fma.rn.ftz.f32 	%f93, %f1, %f91, %f92;
	ld.f32 	%f94, [%rd1+8];
	fma.rn.ftz.f32 	%f95, %f2, %f91, %f94;
	ld.f32 	%f96, [%rd1+12];
	fma.rn.ftz.f32 	%f97, %f3, %f91, %f96;
	sub.ftz.f32 	%f98, %f93, %f88;
	sub.ftz.f32 	%f99, %f95, %f89;
	sub.ftz.f32 	%f100, %f97, %f90;
	mul.ftz.f32 	%f101, %f99, %f99;
	fma.rn.ftz.f32 	%f102, %f98, %f98, %f101;
	fma.rn.ftz.f32 	%f103, %f100, %f100, %f102;
	rsqrt.approx.ftz.f32 	%f104, %f103;
	mul.ftz.f32 	%f105, %f98, %f104;
	mul.ftz.f32 	%f106, %f99, %f104;
	mul.ftz.f32 	%f107, %f100, %f104;
	st.f32 	[%rd3], %f105;
	st.f32 	[%rd3+4], %f106;
	st.f32 	[%rd3+8], %f107;
	bra.uni 	$L__BB1_3;

$L__BB1_1:
	ld.f32 	%f35, [%rd1+4];
	ld.f32 	%f36, [%rd1+8];
	ld.f32 	%f37, [%rd1+12];
	st.f32 	[%rd2], %f35;
	st.f32 	[%rd2+4], %f36;
	st.f32 	[%rd2+8], %f37;
	mul.ftz.f32 	%f38, %f2, %f2;
	fma.rn.ftz.f32 	%f39, %f1, %f1, %f38;
	fma.rn.ftz.f32 	%f40, %f3, %f3, %f39;
	rsqrt.approx.ftz.f32 	%f41, %f40;
	mul.ftz.f32 	%f42, %f1, %f41;
	mul.ftz.f32 	%f43, %f2, %f41;
	mul.ftz.f32 	%f44, %f3, %f41;
	st.f32 	[%rd3], %f42;
	st.f32 	[%rd3+4], %f43;
	st.f32 	[%rd3+8], %f44;

$L__BB1_3:
	ret;

}
	// .globl	__raygen__pathTracing
.visible .entry __raygen__pathTracing()
{
	.local .align 8 .b8 	__local_depot2[208];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<10>;
	.reg .f32 	%f<412>;
	.reg .b32 	%r<199>;
	.reg .f64 	%fd<7>;
	.reg .b64 	%rd<52>;


	mov.u64 	%SPL, __local_depot2;
	cvta.local.u64 	%SP, %SPL;
	// begin inline asm
	call (%r55), _optix_get_launch_index_x, ();
	// end inline asm
	// begin inline asm
	call (%r56), _optix_get_launch_index_y, ();
	// end inline asm
	ld.const.u64 	%rd16, [plp+24];
	cvta.to.global.u64 	%rd17, %rd16;
	shr.u32 	%r57, %r55, 1;
	shr.u32 	%r58, %r56, 1;
	ld.const.u32 	%r59, [plp+40];
	mad.lo.s32 	%r60, %r59, %r58, %r57;
	and.b32  	%r61, %r55, 1;
	and.b32  	%r62, %r56, 1;
	bfi.b32 	%r63, %r62, %r61, 1, 1;
	bfi.b32 	%r64, %r60, %r63, 2, 30;
	mul.wide.u32 	%rd18, %r64, 8;
	add.s64 	%rd1, %rd17, %rd18;
	ld.global.u64 	%rd2, [%rd1];
	ld.const.f32 	%f1, [plp+136];
	setp.gt.ftz.f32 	%p1, %f1, 0f00000000;
	ld.const.v2.u32 	{%r65, %r66}, [plp+8];
	ld.const.u32 	%r5, [plp+16];
	mad.lo.s32 	%r67, %r66, %r5, %r56;
	mad.lo.s32 	%r68, %r67, %r65, %r55;
	cvt.rn.f32.u32 	%f53, %r68;
	ld.const.f32 	%f54, [R2_A1];
	mul.ftz.f32 	%f55, %f54, %f53;
	cvt.rmi.ftz.f32.f32 	%f56, %f55;
	sub.ftz.f32 	%f2, %f55, %f56;
	ld.const.f32 	%f57, [R2_A2];
	mul.ftz.f32 	%f58, %f57, %f53;
	cvt.rmi.ftz.f32.f32 	%f59, %f58;
	sub.ftz.f32 	%f3, %f58, %f59;
	@%p1 bra 	$L__BB2_2;
	bra.uni 	$L__BB2_1;

$L__BB2_2:
	cvt.rn.f32.u32 	%f117, %r55;
	add.ftz.f32 	%f118, %f2, %f117;
	cvt.rn.f32.s32 	%f119, %r65;
	div.approx.ftz.f32 	%f120, %f118, %f119;
	cvt.rn.f32.u32 	%f121, %r56;
	add.ftz.f32 	%f122, %f3, %f121;
	cvt.rn.f32.s32 	%f123, %r66;
	div.approx.ftz.f32 	%f124, %f122, %f123;
	ld.const.v2.f32 	{%f125, %f126}, [plp+80];
	mul.ftz.f32 	%f129, %f126, 0f3F000000;
	mov.f32 	%f130, 0f3F000000;
	sin.approx.ftz.f32 	%f131, %f129;
	cos.approx.ftz.f32 	%f132, %f129;
	div.approx.ftz.f32 	%f133, %f131, %f132;
	add.ftz.f32 	%f134, %f133, %f133;
	mul.ftz.f32 	%f135, %f125, %f134;
	sub.ftz.f32 	%f136, %f130, %f120;
	mul.ftz.f32 	%f137, %f136, %f135;
	ld.const.v2.f32 	{%f138, %f139}, [plp+96];
	ld.const.v2.f32 	{%f142, %f143}, [plp+104];
	sub.ftz.f32 	%f146, %f130, %f124;
	mul.ftz.f32 	%f147, %f146, %f134;
	ld.const.v2.f32 	{%f148, %f149}, [plp+112];
	ld.const.v2.f32 	{%f152, %f153}, [plp+120];
	mul.ftz.f32 	%f156, %f147, %f148;
	mul.ftz.f32 	%f157, %f147, %f149;
	mul.ftz.f32 	%f158, %f147, %f152;
	fma.rn.ftz.f32 	%f159, %f139, %f137, %f156;
	fma.rn.ftz.f32 	%f160, %f142, %f137, %f157;
	fma.rn.ftz.f32 	%f161, %f137, %f143, %f158;
	add.ftz.f32 	%f162, %f159, %f153;
	ld.const.v2.f32 	{%f163, %f164}, [plp+128];
	add.ftz.f32 	%f167, %f160, %f163;
	add.ftz.f32 	%f168, %f161, %f164;
	mul.lo.s64 	%rd19, %rd2, 6364136223846793005;
	add.s64 	%rd20, %rd19, 1;
	mul.lo.s64 	%rd21, %rd2, 7520897724310334953;
	shr.u64 	%rd22, %rd2, 18;
	xor.b64  	%rd23, %rd22, %rd2;
	shr.u64 	%rd24, %rd23, 27;
	cvt.u32.u64 	%r69, %rd24;
	shr.u64 	%rd25, %rd2, 59;
	cvt.u32.u64 	%r70, %rd25;
	shf.r.wrap.b32 	%r71, %r69, %r69, %r70;
	shr.u32 	%r72, %r71, 9;
	or.b32  	%r73, %r72, 1065353216;
	mov.b32 	%f169, %r73;
	add.ftz.f32 	%f170, %f169, 0fBF800000;
	add.s64 	%rd26, %rd21, 6364136223846793006;
	mov.b64 	{%r196, %r195}, %rd26;
	shr.u64 	%rd27, %rd20, 18;
	xor.b64  	%rd28, %rd27, %rd20;
	shr.u64 	%rd29, %rd28, 27;
	cvt.u32.u64 	%r74, %rd29;
	shr.u64 	%rd30, %rd20, 59;
	cvt.u32.u64 	%r75, %rd30;
	shf.r.wrap.b32 	%r76, %r74, %r74, %r75;
	shr.u32 	%r77, %r76, 9;
	or.b32  	%r78, %r77, 1065353216;
	mov.b32 	%f171, %r78;
	add.ftz.f32 	%f172, %f171, 0fBF800000;
	mul.ftz.f32 	%f173, %f170, 0f41100000;
	cvt.rzi.ftz.s32.f32 	%r79, %f173;
	cvt.rn.f32.s32 	%f174, %r79;
	fma.rn.ftz.f32 	%f175, %f174, 0fBDE38E39, %f170;
	mul.ftz.f32 	%f176, %f175, 0f41100000;
	mul.ftz.f32 	%f177, %f174, 0f40490FDB;
	mov.f32 	%f178, 0f40900000;
	div.approx.ftz.f32 	%f179, %f177, %f178;
	add.ftz.f32 	%f180, %f174, 0f3F800000;
	mov.f32 	%f181, 0f3F800000;
	mul.ftz.f32 	%f182, %f180, 0f40490FDB;
	div.approx.ftz.f32 	%f183, %f182, %f178;
	cos.approx.ftz.f32 	%f184, %f179;
	sin.approx.ftz.f32 	%f185, %f179;
	cos.approx.ftz.f32 	%f186, %f183;
	sin.approx.ftz.f32 	%f187, %f183;
	add.ftz.f32 	%f188, %f176, %f172;
	setp.gt.ftz.f32 	%p2, %f188, 0f3F800000;
	sub.ftz.f32 	%f189, %f181, %f172;
	sub.ftz.f32 	%f190, %f181, %f176;
	selp.f32 	%f191, %f189, %f172, %p2;
	selp.f32 	%f192, %f190, %f176, %p2;
	mul.ftz.f32 	%f193, %f186, %f192;
	fma.rn.ftz.f32 	%f194, %f184, %f191, %f193;
	mul.ftz.f32 	%f195, %f187, %f192;
	fma.rn.ftz.f32 	%f196, %f185, %f191, %f195;
	mul.ftz.f32 	%f197, %f1, %f194;
	mul.ftz.f32 	%f198, %f1, %f196;
	ld.const.v2.f32 	{%f199, %f200}, [plp+88];
	fma.rn.ftz.f32 	%f203, %f139, %f197, %f199;
	fma.rn.ftz.f32 	%f204, %f142, %f197, %f200;
	fma.rn.ftz.f32 	%f205, %f143, %f197, %f138;
	fma.rn.ftz.f32 	%f400, %f148, %f198, %f203;
	fma.rn.ftz.f32 	%f401, %f198, %f149, %f204;
	fma.rn.ftz.f32 	%f402, %f198, %f152, %f205;
	ld.const.f32 	%f206, [plp+140];
	fma.rn.ftz.f32 	%f207, %f162, %f206, %f199;
	fma.rn.ftz.f32 	%f208, %f167, %f206, %f200;
	fma.rn.ftz.f32 	%f209, %f168, %f206, %f138;
	sub.ftz.f32 	%f210, %f207, %f400;
	sub.ftz.f32 	%f211, %f208, %f401;
	sub.ftz.f32 	%f212, %f209, %f402;
	mul.ftz.f32 	%f213, %f211, %f211;
	fma.rn.ftz.f32 	%f214, %f210, %f210, %f213;
	fma.rn.ftz.f32 	%f215, %f212, %f212, %f214;
	rsqrt.approx.ftz.f32 	%f216, %f215;
	mul.ftz.f32 	%f397, %f210, %f216;
	mul.ftz.f32 	%f398, %f211, %f216;
	mul.ftz.f32 	%f399, %f212, %f216;
	bra.uni 	$L__BB2_3;

$L__BB2_1:
	mov.b64 	{%r196, %r195}, %rd2;
	cvt.rn.f32.u32 	%f60, %r55;
	add.ftz.f32 	%f61, %f2, %f60;
	cvt.rn.f32.s32 	%f62, %r65;
	div.approx.ftz.f32 	%f63, %f61, %f62;
	cvt.rn.f32.u32 	%f64, %r56;
	add.ftz.f32 	%f65, %f3, %f64;
	cvt.rn.f32.s32 	%f66, %r66;
	div.approx.ftz.f32 	%f67, %f65, %f66;
	ld.const.v2.f32 	{%f68, %f69}, [plp+80];
	mul.ftz.f32 	%f72, %f69, 0f3F000000;
	mov.f32 	%f73, 0f3F000000;
	sin.approx.ftz.f32 	%f74, %f72;
	cos.approx.ftz.f32 	%f75, %f72;
	div.approx.ftz.f32 	%f76, %f74, %f75;
	add.ftz.f32 	%f77, %f76, %f76;
	mul.ftz.f32 	%f78, %f68, %f77;
	ld.const.v2.f32 	{%f400, %f401}, [plp+88];
	ld.const.v2.f32 	{%f402, %f82}, [plp+96];
	sub.ftz.f32 	%f84, %f73, %f63;
	mul.ftz.f32 	%f85, %f84, %f78;
	sub.ftz.f32 	%f86, %f73, %f67;
	mul.ftz.f32 	%f87, %f86, %f77;
	ld.const.v2.f32 	{%f88, %f89}, [plp+112];
	ld.const.v2.f32 	{%f92, %f93}, [plp+120];
	mul.ftz.f32 	%f96, %f87, %f88;
	fma.rn.ftz.f32 	%f97, %f85, %f82, %f96;
	add.ftz.f32 	%f98, %f93, %f97;
	ld.const.v2.f32 	{%f99, %f100}, [plp+104];
	ld.const.v2.f32 	{%f103, %f104}, [plp+128];
	mul.ftz.f32 	%f107, %f87, %f89;
	fma.rn.ftz.f32 	%f108, %f85, %f99, %f107;
	add.ftz.f32 	%f109, %f103, %f108;
	mul.ftz.f32 	%f110, %f87, %f92;
	fma.rn.ftz.f32 	%f111, %f85, %f100, %f110;
	add.ftz.f32 	%f112, %f104, %f111;
	mul.ftz.f32 	%f113, %f109, %f109;
	fma.rn.ftz.f32 	%f114, %f98, %f98, %f113;
	fma.rn.ftz.f32 	%f115, %f112, %f112, %f114;
	rsqrt.approx.ftz.f32 	%f116, %f115;
	mul.ftz.f32 	%f397, %f98, %f116;
	mul.ftz.f32 	%f398, %f109, %f116;
	mul.ftz.f32 	%f399, %f112, %f116;

$L__BB2_3:
	or.b32  	%r80, %r56, %r55;
	setp.ne.s32 	%p3, %r80, 0;
	ld.const.u64 	%rd3, [plp];
	@%p3 bra 	$L__BB2_5;

	add.u64 	%rd31, %SP, 152;
	add.u64 	%rd32, %SPL, 152;
	st.local.u64 	[%rd32], %rd3;
	cvt.ftz.f64.f32 	%fd1, %f400;
	st.local.f64 	[%rd32+8], %fd1;
	cvt.ftz.f64.f32 	%fd2, %f401;
	st.local.f64 	[%rd32+16], %fd2;
	cvt.ftz.f64.f32 	%fd3, %f402;
	st.local.f64 	[%rd32+24], %fd3;
	cvt.ftz.f64.f32 	%fd4, %f397;
	st.local.f64 	[%rd32+32], %fd4;
	cvt.ftz.f64.f32 	%fd5, %f398;
	st.local.f64 	[%rd32+40], %fd5;
	cvt.ftz.f64.f32 	%fd6, %f399;
	st.local.f64 	[%rd32+48], %fd6;
	mov.u64 	%rd33, $str$1;
	cvta.global.u64 	%rd34, %rd33;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd34;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd31;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r81, [retval0+0];
	} // callseq 0

$L__BB2_5:
	add.u64 	%rd48, %SP, 0;
	cvta.to.local.u64 	%rd39, %rd48;
	add.s64 	%rd4, %rd39, 24;
	mov.u32 	%r82, 0;
	st.local.u32 	[%rd39+24], %r82;
	st.local.u32 	[%rd39+28], %r82;
	st.local.u32 	[%rd39+32], %r82;
	st.local.u32 	[%rd39+36], %r82;
	st.local.u32 	[%rd39+40], %r82;
	st.local.u32 	[%rd39+44], %r82;
	mov.u32 	%r83, 1065353216;
	st.local.u32 	[%rd39], %r83;
	st.local.u32 	[%rd39+4], %r83;
	st.local.u32 	[%rd39+8], %r83;
	st.local.u32 	[%rd39+12], %r82;
	st.local.u32 	[%rd39+16], %r82;
	st.local.u32 	[%rd39+20], %r82;
	st.local.u32 	[%rd39+48], %r83;
	mov.u32 	%r84, 1;
	st.local.u32 	[%rd39+52], %r84;
	add.u64 	%rd50, %SP, 56;
	cvta.to.local.u64 	%rd5, %rd50;
	st.local.u32 	[%rd5], %r82;
	st.local.u32 	[%rd5+4], %r82;
	st.local.u32 	[%rd5+8], %r82;
	add.u64 	%rd51, %SP, 68;
	cvta.to.local.u64 	%rd6, %rd51;
	st.local.u32 	[%rd6], %r82;
	st.local.u32 	[%rd6+4], %r82;
	st.local.u32 	[%rd6+8], %r82;
	add.u64 	%rd49, %SP, 80;
	cvta.to.local.u64 	%rd7, %rd49;
	st.local.u32 	[%rd7], %r82;
	st.local.u32 	[%rd7+4], %r82;
	st.local.u32 	[%rd7+8], %r82;
	mov.u32 	%r85, 2143289344;
	st.local.u32 	[%rd7+12], %r85;
	st.local.u32 	[%rd7+16], %r85;
	st.local.u32 	[%rd7+20], %r85;
	st.local.u32 	[%rd7+24], %r85;
	st.local.u32 	[%rd7+28], %r85;
	st.local.u32 	[%rd7+32], %r85;
	st.local.u32 	[%rd7+36], %r85;
	st.local.u32 	[%rd7+40], %r85;
	st.local.u32 	[%rd7+44], %r85;
	st.local.u32 	[%rd7+48], %r85;
	st.local.u32 	[%rd7+52], %r85;
	ld.const.u32 	%r12, [plp+212];
	bra.uni 	$L__BB2_6;

$L__BB2_14:
	mov.b64 	%rd51, {%r94, %r95};
	mov.b64 	%rd50, {%r92, %r93};
	mov.b64 	%rd49, {%r90, %r91};
	mov.b64 	%rd48, {%r88, %r89};
	ld.local.f32 	%f400, [%rd4];
	ld.local.f32 	%f401, [%rd4+4];
	ld.local.f32 	%f402, [%rd4+8];
	ld.local.f32 	%f397, [%rd4+12];
	ld.local.f32 	%f398, [%rd4+16];
	ld.local.f32 	%f399, [%rd4+20];
	add.s32 	%r189, %r47, 1;
	and.b32  	%r190, %r189, 1073741823;
	and.b32  	%r191, %r47, -1073741824;
	or.b32  	%r192, %r190, %r191;
	st.local.u32 	[%rd4+28], %r192;

$L__BB2_6:
	mov.b64 	{%r127, %r128}, %rd48;
	mov.b64 	{%r129, %r130}, %rd49;
	mov.b64 	{%r131, %r132}, %rd50;
	mov.b64 	{%r133, %r134}, %rd51;
	mov.f32 	%f224, 0f7F7FFFFF;
	mov.f32 	%f225, 0f00000000;
	mov.u32 	%r119, 255;
	mov.u32 	%r122, 2;
	mov.u32 	%r124, 10;
	// begin inline asm
	call(%r196,%r195,%r88,%r89,%r90,%r91,%r92,%r93,%r94,%r95,%r96,%r97,%r98,%r99,%r100,%r101,%r102,%r103,%r104,%r105,%r106,%r107,%r108,%r109,%r110,%r111,%r112,%r113,%r114,%r115,%r116,%r117),_optix_trace_typed_32,(%r82,%rd3,%f400,%f401,%f402,%f397,%f398,%f399,%f225,%f224,%f225,%r119,%r82,%r82,%r122,%r82,%r124,%r196,%r195,%r127,%r128,%r129,%r130,%r131,%r132,%r133,%r134,%r82,%r82,%r82,%r82,%r82,%r82,%r82,%r82,%r82,%r82,%r82,%r82,%r82,%r82,%r82,%r82,%r82,%r82,%r82,%r82,%r82,%r82);
	// end inline asm
	ld.local.u32 	%r47, [%rd4+28];
	and.b32  	%r157, %r47, 1073741824;
	setp.eq.s32 	%p4, %r157, 0;
	and.b32  	%r158, %r47, 1073741823;
	setp.lt.u32 	%p5, %r158, %r12;
	and.pred  	%p6, %p4, %p5;
	@%p6 bra 	$L__BB2_14;

	st.global.v2.u32 	[%rd1], {%r196, %r195};
	setp.eq.s32 	%p7, %r5, 0;
	@%p7 bra 	$L__BB2_9;

	ld.const.u64 	%rd41, [plp+48];
	shl.b32 	%r159, %r55, 4;
	suld.b.2d.v4.b32.trap {%r160, %r161, %r162, %r163}, [%rd41, {%r159, %r56}];
	mov.b32 	%f406, %r160;
	mov.b32 	%f407, %r161;
	mov.b32 	%f408, %r162;
	ld.const.u64 	%rd42, [plp+56];
	suld.b.2d.v4.b32.trap {%r164, %r165, %r166, %r167}, [%rd42, {%r159, %r56}];
	mov.b32 	%f409, %r164;
	mov.b32 	%f410, %r165;
	mov.b32 	%f411, %r166;
	ld.const.u64 	%rd43, [plp+64];
	suld.b.2d.v4.b32.trap {%r168, %r169, %r170, %r171}, [%rd43, {%r159, %r56}];
	mov.b32 	%f403, %r168;
	mov.b32 	%f404, %r169;
	mov.b32 	%f405, %r170;
	bra.uni 	$L__BB2_10;

$L__BB2_9:
	mov.f32 	%f403, 0f00000000;
	mov.f32 	%f404, %f403;
	mov.f32 	%f405, %f403;
	mov.f32 	%f406, %f403;
	mov.f32 	%f407, %f403;
	mov.f32 	%f408, %f403;
	mov.f32 	%f409, %f403;
	mov.f32 	%f410, %f403;
	mov.f32 	%f411, %f403;

$L__BB2_10:
	add.s32 	%r174, %r5, 1;
	cvt.rn.f32.u32 	%f235, %r174;
	rcp.approx.ftz.f32 	%f236, %f235;
	mov.f32 	%f237, 0f3F800000;
	ld.const.f32 	%f238, [plp+416];
	ld.local.f32 	%f239, [%rd4+-12];
	min.ftz.f32 	%f240, %f239, %f238;
	ld.local.f32 	%f241, [%rd4+-8];
	min.ftz.f32 	%f242, %f241, %f238;
	ld.local.f32 	%f243, [%rd4+-4];
	min.ftz.f32 	%f244, %f243, %f238;
	sub.ftz.f32 	%f245, %f237, %f236;
	mul.ftz.f32 	%f246, %f236, %f240;
	mul.ftz.f32 	%f247, %f236, %f242;
	mul.ftz.f32 	%f248, %f236, %f244;
	fma.rn.ftz.f32 	%f249, %f406, %f245, %f246;
	fma.rn.ftz.f32 	%f250, %f407, %f245, %f247;
	fma.rn.ftz.f32 	%f251, %f408, %f245, %f248;
	mov.b32 	%r175, %f249;
	mov.b32 	%r176, %f250;
	mov.b32 	%r177, %f251;
	ld.const.u64 	%rd44, [plp+48];
	shl.b32 	%r48, %r55, 4;
	mov.u32 	%r178, 1065353216;
	sust.b.2d.v4.b32.trap 	[%rd44, {%r48, %r56}], {%r175, %r176, %r177, %r178};
	ld.local.f32 	%f252, [%rd5];
	mul.ftz.f32 	%f253, %f236, %f252;
	ld.local.f32 	%f254, [%rd5+4];
	mul.ftz.f32 	%f255, %f236, %f254;
	ld.local.f32 	%f256, [%rd5+8];
	mul.ftz.f32 	%f257, %f236, %f256;
	fma.rn.ftz.f32 	%f258, %f409, %f245, %f253;
	fma.rn.ftz.f32 	%f259, %f410, %f245, %f255;
	fma.rn.ftz.f32 	%f260, %f411, %f245, %f257;
	mov.b32 	%r179, %f258;
	mov.b32 	%r180, %f259;
	mov.b32 	%r181, %f260;
	ld.const.u64 	%rd45, [plp+56];
	sust.b.2d.v4.b32.trap 	[%rd45, {%r48, %r56}], {%r179, %r180, %r181, %r178};
	ld.local.f32 	%f261, [%rd6];
	mul.ftz.f32 	%f262, %f236, %f261;
	ld.local.f32 	%f263, [%rd6+4];
	mul.ftz.f32 	%f264, %f236, %f263;
	ld.local.f32 	%f265, [%rd6+8];
	mul.ftz.f32 	%f266, %f236, %f265;
	fma.rn.ftz.f32 	%f267, %f403, %f245, %f262;
	fma.rn.ftz.f32 	%f268, %f404, %f245, %f264;
	fma.rn.ftz.f32 	%f269, %f405, %f245, %f266;
	mov.b32 	%r182, %f267;
	mov.b32 	%r183, %f268;
	mov.b32 	%r184, %f269;
	ld.const.u64 	%rd46, [plp+64];
	sust.b.2d.v4.b32.trap 	[%rd46, {%r48, %r56}], {%r182, %r183, %r184, %r178};
	ld.local.f32 	%f270, [%rd7+12];
	abs.ftz.f32 	%f271, %f270;
	setp.gtu.ftz.f32 	%p8, %f271, 0f7F800000;
	mov.u32 	%r173, 0;
	mov.u32 	%r197, %r173;
	mov.u32 	%r198, %r173;
	@%p8 bra 	$L__BB2_13;

	ld.local.f32 	%f46, [%rd7+24];
	abs.ftz.f32 	%f272, %f46;
	setp.gtu.ftz.f32 	%p9, %f272, 0f7F800000;
	@%p9 bra 	$L__BB2_13;

	cvt.rn.f32.u32 	%f273, %r55;
	add.ftz.f32 	%f274, %f273, 0f3F000000;
	cvt.rn.f32.u32 	%f275, %r56;
	add.ftz.f32 	%f276, %f275, 0f3F000000;
	ld.const.v2.f32 	{%f277, %f278}, [plp+160];
	ld.const.v2.f32 	{%f281, %f282}, [plp+168];
	ld.const.v2.f32 	{%f285, %f286}, [plp+176];
	ld.const.v2.f32 	{%f289, %f290}, [plp+184];
	ld.const.v2.f32 	{%f293, %f294}, [plp+192];
	mul.ftz.f32 	%f297, %f278, %f286;
	mul.ftz.f32 	%f298, %f285, %f293;
	mul.ftz.f32 	%f299, %f282, %f298;
	fma.rn.ftz.f32 	%f300, %f297, %f294, %f299;
	mul.ftz.f32 	%f301, %f281, %f290;
	fma.rn.ftz.f32 	%f302, %f289, %f301, %f300;
	mul.ftz.f32 	%f303, %f286, %f290;
	mul.ftz.f32 	%f304, %f282, %f303;
	sub.ftz.f32 	%f305, %f302, %f304;
	mul.ftz.f32 	%f306, %f281, %f285;
	mul.ftz.f32 	%f307, %f306, %f294;
	sub.ftz.f32 	%f308, %f305, %f307;
	mul.ftz.f32 	%f309, %f278, %f293;
	mul.ftz.f32 	%f310, %f289, %f309;
	sub.ftz.f32 	%f311, %f308, %f310;
	mul.ftz.f32 	%f312, %f286, %f294;
	mul.ftz.f32 	%f313, %f289, %f293;
	sub.ftz.f32 	%f314, %f312, %f313;
	mul.ftz.f32 	%f315, %f285, %f294;
	mul.ftz.f32 	%f316, %f289, %f290;
	sub.ftz.f32 	%f317, %f315, %f316;
	sub.ftz.f32 	%f318, %f298, %f303;
	mul.ftz.f32 	%f319, %f281, %f294;
	mul.ftz.f32 	%f320, %f282, %f293;
	sub.ftz.f32 	%f321, %f319, %f320;
	mul.ftz.f32 	%f322, %f278, %f294;
	mul.ftz.f32 	%f323, %f282, %f290;
	sub.ftz.f32 	%f324, %f322, %f323;
	sub.ftz.f32 	%f325, %f309, %f301;
	mul.ftz.f32 	%f326, %f281, %f289;
	mul.ftz.f32 	%f327, %f282, %f286;
	sub.ftz.f32 	%f328, %f326, %f327;
	mul.ftz.f32 	%f329, %f278, %f289;
	mul.ftz.f32 	%f330, %f282, %f285;
	sub.ftz.f32 	%f331, %f329, %f330;
	sub.ftz.f32 	%f332, %f297, %f306;
	rcp.approx.ftz.f32 	%f333, %f311;
	mov.f32 	%f334, 0f3F800000;
	mul.ftz.f32 	%f335, %f314, %f333;
	mul.ftz.f32 	%f336, %f321, %f333;
	mul.ftz.f32 	%f337, %f328, %f333;
	mul.ftz.f32 	%f338, %f317, %f333;
	mul.ftz.f32 	%f339, %f324, %f333;
	mul.ftz.f32 	%f340, %f331, %f333;
	mul.ftz.f32 	%f341, %f318, %f333;
	mul.ftz.f32 	%f342, %f325, %f333;
	mul.ftz.f32 	%f343, %f332, %f333;
	ld.const.v2.f32 	{%f344, %f345}, [plp+152];
	sub.ftz.f32 	%f348, %f46, %f344;
	ld.local.f32 	%f349, [%rd7+28];
	sub.ftz.f32 	%f350, %f349, %f345;
	ld.local.f32 	%f351, [%rd7+32];
	sub.ftz.f32 	%f352, %f351, %f277;
	mul.ftz.f32 	%f353, %f348, %f335;
	mul.ftz.f32 	%f354, %f350, %f338;
	sub.ftz.f32 	%f355, %f353, %f354;
	fma.rn.ftz.f32 	%f356, %f352, %f341, %f355;
	mul.ftz.f32 	%f357, %f348, %f336;
	mul.ftz.f32 	%f358, %f350, %f339;
	sub.ftz.f32 	%f359, %f358, %f357;
	mul.ftz.f32 	%f360, %f352, %f342;
	sub.ftz.f32 	%f361, %f359, %f360;
	mul.ftz.f32 	%f362, %f348, %f337;
	mul.ftz.f32 	%f363, %f350, %f340;
	sub.ftz.f32 	%f364, %f362, %f363;
	fma.rn.ftz.f32 	%f365, %f352, %f343, %f364;
	div.approx.ftz.f32 	%f366, %f356, %f365;
	div.approx.ftz.f32 	%f367, %f361, %f365;
	ld.const.v2.f32 	{%f368, %f369}, [plp+144];
	mov.f32 	%f372, 0f40000000;
	div.approx.ftz.f32 	%f373, %f369, %f372;
	sin.approx.ftz.f32 	%f374, %f373;
	cos.approx.ftz.f32 	%f375, %f373;
	div.approx.ftz.f32 	%f376, %f374, %f375;
	add.ftz.f32 	%f377, %f376, %f376;
	mul.ftz.f32 	%f378, %f368, %f377;
	fma.rn.ftz.f32 	%f379, %f378, 0f3F000000, %f366;
	div.approx.ftz.f32 	%f380, %f379, %f378;
	sub.ftz.f32 	%f381, %f334, %f380;
	fma.rn.ftz.f32 	%f382, %f377, 0f3F000000, %f367;
	div.approx.ftz.f32 	%f383, %f382, %f377;
	sub.ftz.f32 	%f384, %f334, %f383;
	cvt.rn.f32.s32 	%f385, %r65;
	mul.ftz.f32 	%f386, %f381, %f385;
	cvt.rn.f32.s32 	%f387, %r66;
	mul.ftz.f32 	%f388, %f384, %f387;
	sub.ftz.f32 	%f389, %f274, %f386;
	sub.ftz.f32 	%f390, %f276, %f388;
	mov.b32 	%r197, %f389;
	mov.b32 	%r198, %f390;

$L__BB2_13:
	ld.const.u64 	%rd47, [plp+72];
	sust.b.2d.v4.b32.trap 	[%rd47, {%r48, %r56}], {%r197, %r198, %r173, %r178};
	ret;

}
	// .globl	__miss__miss
.visible .entry __miss__miss()
{
	.reg .pred 	%p<37>;
	.reg .f32 	%f<215>;
	.reg .b32 	%r<67>;
	.reg .b64 	%rd<15>;


	mov.u32 	%r12, 2;
	mov.u32 	%r14, 3;
	// begin inline asm
	call (%r11), _optix_get_payload, (%r12);
	// end inline asm
	// begin inline asm
	call (%r13), _optix_get_payload, (%r14);
	// end inline asm
	mov.b64 	%rd1, {%r11, %r13};
	mov.u32 	%r16, 4;
	mov.u32 	%r18, 5;
	// begin inline asm
	call (%r15), _optix_get_payload, (%r16);
	// end inline asm
	// begin inline asm
	call (%r17), _optix_get_payload, (%r18);
	// end inline asm
	mov.b64 	%rd3, {%r15, %r17};
	// begin inline asm
	call (%f49), _optix_get_world_ray_direction_x, ();
	// end inline asm
	// begin inline asm
	call (%f50), _optix_get_world_ray_direction_y, ();
	// end inline asm
	// begin inline asm
	call (%f51), _optix_get_world_ray_direction_z, ();
	// end inline asm
	neg.ftz.f32 	%f58, %f49;
	neg.ftz.f32 	%f59, %f50;
	neg.ftz.f32 	%f60, %f51;
	st.f32 	[%rd3+36], %f58;
	st.f32 	[%rd3+40], %f59;
	st.f32 	[%rd3+44], %f60;
	ld.const.u64 	%rd2, [plp+328];
	setp.eq.s64 	%p1, %rd2, 0;
	mov.f32 	%f206, 0f00000000;
	mov.f32 	%f207, %f206;
	mov.f32 	%f208, %f206;
	mov.f32 	%f209, %f206;
	mov.f32 	%f210, %f206;
	mov.f32 	%f211, %f206;
	@%p1 bra 	$L__BB3_19;

	// begin inline asm
	call (%f61), _optix_get_world_ray_direction_x, ();
	// end inline asm
	// begin inline asm
	call (%f62), _optix_get_world_ray_direction_y, ();
	// end inline asm
	// begin inline asm
	call (%f63), _optix_get_world_ray_direction_z, ();
	// end inline asm
	mul.ftz.f32 	%f64, %f62, %f62;
	fma.rn.ftz.f32 	%f65, %f61, %f61, %f64;
	fma.rn.ftz.f32 	%f66, %f63, %f63, %f65;
	rsqrt.approx.ftz.f32 	%f67, %f66;
	mov.f32 	%f68, 0f3F800000;
	mul.ftz.f32 	%f69, %f61, %f67;
	mul.ftz.f32 	%f70, %f62, %f67;
	mul.ftz.f32 	%f1, %f63, %f67;
	mov.f32 	%f71, 0fBF800000;
	max.ftz.f32 	%f72, %f70, %f71;
	min.ftz.f32 	%f73, %f72, %f68;
	abs.ftz.f32 	%f74, %f73;
	neg.ftz.f32 	%f75, %f74;
	mov.f32 	%f76, 0f3F000000;
	fma.rn.ftz.f32 	%f77, %f76, %f75, %f76;
	rsqrt.approx.ftz.f32 	%f78, %f77;
	mul.ftz.f32 	%f79, %f77, %f78;
	mul.ftz.f32 	%f80, %f78, 0f3F000000;
	neg.ftz.f32 	%f81, %f79;
	fma.rn.ftz.f32 	%f82, %f81, %f80, %f76;
	fma.rn.ftz.f32 	%f83, %f79, %f82, %f79;
	setp.eq.ftz.f32 	%p2, %f74, 0f3F800000;
	selp.f32 	%f84, 0f00000000, %f83, %p2;
	setp.gt.ftz.f32 	%p3, %f74, 0f3F0F5C29;
	selp.f32 	%f85, %f84, %f74, %p3;
	mov.b32 	%r19, %f85;
	mov.b32 	%r20, %f73;
	and.b32  	%r21, %r20, -2147483648;
	or.b32  	%r22, %r21, %r19;
	mov.b32 	%f86, %r22;
	mul.ftz.f32 	%f87, %f86, %f86;
	mov.f32 	%f88, 0f3C8B1ABB;
	mov.f32 	%f89, 0f3D10ECEF;
	fma.rn.ftz.f32 	%f90, %f89, %f87, %f88;
	mov.f32 	%f91, 0f3CFC028C;
	fma.rn.ftz.f32 	%f92, %f90, %f87, %f91;
	mov.f32 	%f93, 0f3D372139;
	fma.rn.ftz.f32 	%f94, %f92, %f87, %f93;
	mov.f32 	%f95, 0f3D9993DB;
	fma.rn.ftz.f32 	%f96, %f94, %f87, %f95;
	mov.f32 	%f97, 0f3E2AAAC6;
	fma.rn.ftz.f32 	%f98, %f96, %f87, %f97;
	mul.ftz.f32 	%f99, %f98, %f87;
	fma.rn.ftz.f32 	%f100, %f99, %f86, %f86;
	neg.ftz.f32 	%f101, %f100;
	selp.f32 	%f102, %f100, %f101, %p3;
	mov.f32 	%f103, 0f3FD774EB;
	mov.f32 	%f104, 0f3F6EE581;
	fma.rn.ftz.f32 	%f105, %f104, %f103, %f102;
	setp.gt.ftz.f32 	%p4, %f73, 0f3F0F5C29;
	selp.f32 	%f106, %f100, %f105, %p4;
	add.ftz.f32 	%f107, %f106, %f106;
	selp.f32 	%f208, %f107, %f106, %p3;
	neg.ftz.f32 	%f3, %f69;
	abs.ftz.f32 	%f4, %f1;
	abs.ftz.f32 	%f5, %f3;
	setp.eq.ftz.f32 	%p5, %f4, 0f00000000;
	setp.eq.ftz.f32 	%p6, %f5, 0f00000000;
	and.pred  	%p7, %p5, %p6;
	@%p7 bra 	$L__BB3_5;
	bra.uni 	$L__BB3_2;

$L__BB3_5:
	mov.b32 	%r33, %f1;
	shr.s32 	%r34, %r33, 31;
	and.b32  	%r35, %r34, 1078530011;
	mov.b32 	%r36, %f3;
	and.b32  	%r37, %r36, -2147483648;
	or.b32  	%r38, %r35, %r37;
	mov.b32 	%f202, %r38;
	bra.uni 	$L__BB3_6;

$L__BB3_2:
	setp.eq.ftz.f32 	%p8, %f4, 0f7F800000;
	setp.eq.ftz.f32 	%p9, %f5, 0f7F800000;
	and.pred  	%p10, %p8, %p9;
	@%p10 bra 	$L__BB3_4;
	bra.uni 	$L__BB3_3;

$L__BB3_4:
	mov.b32 	%r28, %f1;
	setp.lt.s32 	%p14, %r28, 0;
	selp.b32 	%r29, 1075235812, 1061752795, %p14;
	mov.b32 	%r30, %f3;
	and.b32  	%r31, %r30, -2147483648;
	or.b32  	%r32, %r29, %r31;
	mov.b32 	%f202, %r32;
	bra.uni 	$L__BB3_6;

$L__BB3_3:
	max.ftz.f32 	%f108, %f5, %f4;
	min.ftz.f32 	%f109, %f5, %f4;
	div.full.ftz.f32 	%f110, %f109, %f108;
	mul.rn.ftz.f32 	%f111, %f110, %f110;
	mov.f32 	%f112, 0fC0B59883;
	mov.f32 	%f113, 0fBF52C7EA;
	fma.rn.ftz.f32 	%f114, %f111, %f113, %f112;
	mov.f32 	%f115, 0fC0D21907;
	fma.rn.ftz.f32 	%f116, %f114, %f111, %f115;
	mul.ftz.f32 	%f117, %f111, %f116;
	mul.ftz.f32 	%f118, %f110, %f117;
	add.ftz.f32 	%f119, %f111, 0f41355DC0;
	mov.f32 	%f120, 0f41E6BD60;
	fma.rn.ftz.f32 	%f121, %f119, %f111, %f120;
	mov.f32 	%f122, 0f419D92C8;
	fma.rn.ftz.f32 	%f123, %f121, %f111, %f122;
	rcp.approx.ftz.f32 	%f124, %f123;
	fma.rn.ftz.f32 	%f125, %f118, %f124, %f110;
	mov.f32 	%f126, 0f3FC90FDB;
	sub.ftz.f32 	%f127, %f126, %f125;
	setp.gt.ftz.f32 	%p11, %f5, %f4;
	selp.f32 	%f128, %f127, %f125, %p11;
	mov.b32 	%r23, %f1;
	setp.lt.s32 	%p12, %r23, 0;
	mov.f32 	%f129, 0f40490FDB;
	sub.ftz.f32 	%f130, %f129, %f128;
	selp.f32 	%f131, %f130, %f128, %p12;
	mov.b32 	%r24, %f131;
	mov.b32 	%r25, %f3;
	and.b32  	%r26, %r25, -2147483648;
	or.b32  	%r27, %r26, %r24;
	mov.b32 	%f132, %r27;
	add.ftz.f32 	%f133, %f4, %f5;
	setp.le.ftz.f32 	%p13, %f133, 0f7F800000;
	selp.f32 	%f202, %f132, %f133, %p13;

$L__BB3_6:
	add.ftz.f32 	%f10, %f202, 0f40C90FDB;
	mov.f32 	%f134, 0f40C90FDB;
	abs.ftz.f32 	%f205, %f10;
	abs.ftz.f32 	%f12, %f134;
	setp.lt.ftz.f32 	%p15, %f205, %f12;
	@%p15 bra 	$L__BB3_18;

	mul.ftz.f32 	%f13, %f12, 0f4B000000;
	setp.gtu.ftz.f32 	%p16, %f205, %f13;
	@%p16 bra 	$L__BB3_14;
	bra.uni 	$L__BB3_8;

$L__BB3_14:
	mov.b32 	%r2, %f205;
	mov.b32 	%r3, %f13;
	and.b32  	%r40, %r2, 8388607;
	or.b32  	%r65, %r40, 1065353216;
	mov.b32 	%f204, %r65;
	add.s32 	%r41, %r3, -192937984;
	and.b32  	%r42, %r41, -8388608;
	sub.s32 	%r43, %r2, %r42;
	and.b32  	%r66, %r43, -8388608;
	setp.eq.s32 	%p22, %r66, 0;
	@%p22 bra 	$L__BB3_17;

	and.b32  	%r44, %r3, 8388607;
	or.b32  	%r45, %r44, 1065353216;
	mov.b32 	%f143, %r45;
	rcp.approx.ftz.f32 	%f23, %f143;
	neg.ftz.f32 	%f24, %f143;

$L__BB3_16:
	min.u32 	%r46, %r66, 192937984;
	add.s32 	%r47, %r46, %r65;
	mov.b32 	%f144, %r47;
	mov.f32 	%f145, 0f80000000;
	fma.rn.ftz.f32 	%f146, %f144, %f23, %f145;
	fma.rn.ftz.f32 	%f147, %f24, %f146, %f144;
	fma.rn.ftz.f32 	%f148, %f147, %f23, %f146;
	fma.rn.ftz.f32 	%f149, %f24, %f148, %f144;
	fma.rz.ftz.f32 	%f150, %f149, %f23, %f148;
	cvt.rzi.f32.f32 	%f151, %f150;
	fma.rn.ftz.f32 	%f204, %f24, %f151, %f144;
	sub.s32 	%r66, %r66, %r46;
	mov.b32 	%r65, %f204;
	setp.ne.s32 	%p23, %r66, 0;
	setp.ne.s32 	%p24, %r65, 0;
	and.pred  	%p25, %p23, %p24;
	@%p25 bra 	$L__BB3_16;

$L__BB3_17:
	setp.gt.u32 	%p26, %r2, 2139095039;
	setp.leu.ftz.f32 	%p27, %f12, 0f00000000;
	or.pred  	%p28, %p27, %p26;
	and.b32  	%r48, %r3, -8388608;
	mov.b32 	%f152, %r48;
	selp.f32 	%f153, 0f7FFFFFFF, %f152, %p28;
	mul.ftz.f32 	%f154, %f204, 0f34000000;
	mul.ftz.f32 	%f205, %f153, %f154;
	bra.uni 	$L__BB3_18;

$L__BB3_8:
	div.approx.ftz.f32 	%f135, %f205, %f12;
	cvt.rzi.f32.f32 	%f203, %f135;
	neg.ftz.f32 	%f15, %f12;
	fma.rn.f32 	%f16, %f15, %f203, %f205;
	mov.b32 	%r1, %f16;
	mov.b32 	%r39, %f12;
	setp.lt.u32 	%p17, %r1, %r39;
	@%p17 bra 	$L__BB3_13;

	setp.gt.u32 	%p18, %r1, -2147483648;
	@%p18 bra 	$L__BB3_12;
	bra.uni 	$L__BB3_10;

$L__BB3_12:
	add.ftz.f32 	%f141, %f203, 0fBF800000;
	add.ftz.f32 	%f142, %f141, 0fBF800000;
	setp.lt.ftz.f32 	%p21, %f16, %f15;
	selp.f32 	%f203, %f142, %f141, %p21;
	bra.uni 	$L__BB3_13;

$L__BB3_10:
	add.ftz.f32 	%f203, %f203, 0f3F800000;
	add.ftz.f32 	%f136, %f12, %f12;
	setp.ltu.ftz.f32 	%p19, %f16, %f136;
	@%p19 bra 	$L__BB3_13;

	add.ftz.f32 	%f137, %f203, 0f3F800000;
	mov.f32 	%f138, 0fC0400000;
	fma.rn.ftz.f32 	%f139, %f138, %f12, %f16;
	setp.ge.ftz.f32 	%p20, %f139, 0f00000000;
	add.ftz.f32 	%f140, %f137, 0f3F800000;
	selp.f32 	%f203, %f140, %f137, %p20;

$L__BB3_13:
	fma.rn.ftz.f32 	%f205, %f15, %f203, %f205;

$L__BB3_18:
	abs.ftz.f32 	%f155, %f205;
	setp.gtu.ftz.f32 	%p29, %f155, 0f7F800000;
	mov.b32 	%r49, %f10;
	and.b32  	%r50, %r49, -2147483648;
	mov.b32 	%r51, %f205;
	or.b32  	%r52, %r50, %r51;
	mov.b32 	%f156, %r52;
	selp.f32 	%f157, %f205, %f156, %p29;
	ld.const.f32 	%f158, [plp+236];
	add.ftz.f32 	%f159, %f158, %f157;
	div.approx.ftz.f32 	%f161, %f159, %f134;
	cvt.rmi.ftz.f32.f32 	%f162, %f161;
	mul.ftz.f32 	%f163, %f162, 0fC0000000;
	mov.f32 	%f164, 0f40490FDB;
	fma.rn.ftz.f32 	%f165, %f163, 0f40490FDB, %f159;
	div.approx.ftz.f32 	%f206, %f165, %f134;
	div.approx.ftz.f32 	%f207, %f208, %f164;
	mov.f32 	%f166, 0f00000000;
	tex.level.2d.v4.f32.f32 	{%f209, %f210, %f211, %f167}, [%rd2, {%f206, %f207}], %f166;

$L__BB3_19:
	ld.const.u32 	%r53, [plp+240];
	and.b32  	%r54, %r53, 1;
	setp.eq.b32 	%p30, %r54, 1;
	or.pred  	%p32, %p30, %p1;
	mov.f32 	%f212, %f209;
	mov.f32 	%f213, %f210;
	mov.f32 	%f214, %f211;
	@%p32 bra 	$L__BB3_20;
	bra.uni 	$L__BB3_21;

$L__BB3_20:
	ld.const.v2.f32 	{%f213, %f214}, [plp+248];
	ld.const.f32 	%f212, [plp+244];

$L__BB3_21:
	ld.u32 	%r10, [%rd1+52];
	and.b32  	%r55, %r10, 1073741822;
	setp.ne.s32 	%p33, %r55, 0;
	setp.gt.s32 	%p34, %r10, -1;
	and.pred  	%p35, %p33, %p34;
	@%p35 bra 	$L__BB3_23;
	bra.uni 	$L__BB3_22;

$L__BB3_23:
	ld.const.u32 	%r56, [plp+324];
	cvt.rn.f32.u32 	%f170, %r56;
	mul.ftz.f32 	%f171, %f207, %f170;
	cvt.rzi.ftz.u32.f32 	%r57, %f171;
	add.s32 	%r58, %r56, -1;
	min.u32 	%r59, %r57, %r58;
	ld.const.u64 	%rd4, [plp+304];
	cvta.to.global.u64 	%rd5, %rd4;
	mul.wide.s32 	%rd6, %r59, 4;
	add.s64 	%rd7, %rd5, %rd6;
	ld.const.u64 	%rd8, [plp+296];
	cvta.to.global.u64 	%rd9, %rd8;
	mul.wide.u32 	%rd10, %r59, 24;
	add.s64 	%rd11, %rd9, %rd10;
	ld.global.u32 	%r60, [%rd11+20];
	add.s32 	%r61, %r60, -1;
	cvt.rn.f32.u32 	%f172, %r60;
	mul.ftz.f32 	%f173, %f206, %f172;
	cvt.rzi.ftz.u32.f32 	%r62, %f173;
	min.u32 	%r63, %r61, %r62;
	ld.global.u64 	%rd12, [%rd11];
	mul.wide.s32 	%rd13, %r63, 4;
	add.s64 	%rd14, %rd12, %rd13;
	ld.f32 	%f174, [%rd14];
	ld.global.f32 	%f175, [%rd7];
	mul.ftz.f32 	%f176, %f175, %f174;
	sin.approx.ftz.f32 	%f177, %f208;
	mul.ftz.f32 	%f178, %f177, 0f419DE9E7;
	div.approx.ftz.f32 	%f179, %f176, %f178;
	ld.const.f32 	%f180, [plp+272];
	setp.gt.ftz.f32 	%p36, %f180, 0f00000000;
	mul.ftz.f32 	%f181, %f179, 0f3E800000;
	selp.f32 	%f182, %f181, %f179, %p36;
	fma.rn.ftz.f32 	%f183, %f182, %f182, 0f3D800000;
	mov.f32 	%f184, 0f3D800000;
	div.approx.ftz.f32 	%f185, %f184, %f183;
	ld.const.f32 	%f186, [plp+232];
	mul.ftz.f32 	%f187, %f209, %f186;
	mul.ftz.f32 	%f188, %f210, %f186;
	mul.ftz.f32 	%f189, %f211, %f186;
	ld.f32 	%f190, [%rd1];
	mul.ftz.f32 	%f191, %f190, %f187;
	ld.f32 	%f192, [%rd1+4];
	mul.ftz.f32 	%f193, %f188, %f192;
	ld.f32 	%f194, [%rd1+8];
	mul.ftz.f32 	%f195, %f189, %f194;
	ld.f32 	%f196, [%rd1+12];
	fma.rn.ftz.f32 	%f197, %f185, %f191, %f196;
	st.f32 	[%rd1+12], %f197;
	ld.f32 	%f198, [%rd1+16];
	fma.rn.ftz.f32 	%f199, %f185, %f193, %f198;
	st.f32 	[%rd1+16], %f199;
	ld.f32 	%f200, [%rd1+20];
	fma.rn.ftz.f32 	%f201, %f185, %f195, %f200;
	st.f32 	[%rd1+20], %f201;
	bra.uni 	$L__BB3_24;

$L__BB3_22:
	st.f32 	[%rd1+12], %f212;
	st.f32 	[%rd1+16], %f213;
	st.f32 	[%rd1+20], %f214;

$L__BB3_24:
	or.b32  	%r64, %r10, 1073741824;
	st.u32 	[%rd1+52], %r64;
	ret;

}
	// .globl	__closesthit__shading
.visible .entry __closesthit__shading()
{
	.local .align 8 .b8 	__local_depot4[24];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<346>;
	.reg .b16 	%rs<11>;
	.reg .f32 	%f<7809>;
	.reg .b32 	%r<2539>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<1977>;


	mov.u64 	%SPL, __local_depot4;
	cvta.local.u64 	%SP, %SPL;
	// begin inline asm
	call (%rd142), _optix_get_sbt_data_ptr_64, ();
	// end inline asm
	mov.u64 	%rd143, plp;
	ld.u32 	%rd2, [%rd142+4];
	ld.const.u64 	%rd145, [plp+352];
	cvta.to.global.u64 	%rd3, %rd145;
	ld.u32 	%r154, [%rd142];
	ld.const.u32 	%r155, [plp+20];
	// begin inline asm
	call (%r131), _optix_read_instance_id, ();
	// end inline asm
	mul.wide.u32 	%rd146, %r155, 16;
	add.s64 	%rd147, %rd143, %rd146;
	ld.const.u64 	%rd148, [%rd147+368];
	cvta.to.global.u64 	%rd4, %rd148;
	cvt.u64.u32 	%rd5, %r131;
	mov.u32 	%r133, 0;
	// begin inline asm
	call (%r2534), _optix_get_payload, (%r133);
	// end inline asm
	mov.u32 	%r135, 1;
	// begin inline asm
	call (%r2533), _optix_get_payload, (%r135);
	// end inline asm
	mov.u32 	%r137, 2;
	mov.u32 	%r139, 3;
	// begin inline asm
	call (%r136), _optix_get_payload, (%r137);
	// end inline asm
	// begin inline asm
	call (%r138), _optix_get_payload, (%r139);
	// end inline asm
	mov.b64 	%rd6, {%r136, %r138};
	mov.u32 	%r141, 4;
	mov.u32 	%r143, 5;
	// begin inline asm
	call (%r140), _optix_get_payload, (%r141);
	// end inline asm
	// begin inline asm
	call (%r142), _optix_get_payload, (%r143);
	// end inline asm
	mov.b64 	%rd7, {%r140, %r142};
	mov.u32 	%r145, 6;
	mov.u32 	%r147, 7;
	// begin inline asm
	call (%r144), _optix_get_payload, (%r145);
	// end inline asm
	// begin inline asm
	call (%r146), _optix_get_payload, (%r147);
	// end inline asm
	mov.b64 	%rd8, {%r144, %r146};
	mov.u32 	%r149, 8;
	// begin inline asm
	call (%r148), _optix_get_payload, (%r149);
	// end inline asm
	mov.u32 	%r151, 9;
	// begin inline asm
	call (%r150), _optix_get_payload, (%r151);
	// end inline asm
	// begin inline asm
	call (%f2690, %f2691), _optix_get_triangle_barycentrics, ();
	// end inline asm
	// begin inline asm
	call (%r152), _optix_read_primitive_idx, ();
	// end inline asm
	mul.wide.u32 	%rd149, %r154, 64;
	add.s64 	%rd9, %rd3, %rd149;
	cvt.u64.u32 	%rd10, %r152;
	ld.global.u64 	%rd150, [%rd9+16];
	mul.wide.u32 	%rd151, %r152, 12;
	add.s64 	%rd152, %rd150, %rd151;
	ld.u32 	%r156, [%rd152];
	ld.u32 	%r5, [%rd152+4];
	ld.u32 	%r6, [%rd152+8];
	ld.global.u64 	%rd11, [%rd9];
	mul.wide.u32 	%rd153, %r156, 44;
	add.s64 	%rd12, %rd11, %rd153;
	ld.f32 	%f6895, [%rd12];
	ld.f32 	%f6896, [%rd12+4];
	ld.f32 	%f6897, [%rd12+8];
	// begin inline asm
	call (%r153), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p5, %r153, 0;
	@%p5 bra 	$L__BB4_19;

	// begin inline asm
	call (%r157), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f2692), _optix_get_ray_time, ();
	// end inline asm
	setp.lt.s32 	%p6, %r157, 1;
	@%p6 bra 	$L__BB4_18;

	mov.u32 	%r2498, %r157;

$L__BB4_3:
	.pragma "nounroll";
	add.s32 	%r158, %r2498, -1;
	// begin inline asm
	call (%rd154), _optix_get_transform_list_handle, (%r158);
	// end inline asm
	// begin inline asm
	call (%r159), _optix_get_transform_type_from_handle, (%rd154);
	// end inline asm
	or.b32  	%r160, %r159, 1;
	setp.eq.s32 	%p7, %r160, 3;
	@%p7 bra 	$L__BB4_9;
	bra.uni 	$L__BB4_4;

$L__BB4_9:
	setp.eq.s32 	%p10, %r159, 2;
	@%p10 bra 	$L__BB4_13;
	bra.uni 	$L__BB4_10;

$L__BB4_13:
	// begin inline asm
	call (%rd226), _optix_get_matrix_motion_transform_from_handle, (%rd154);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd228, %rd226;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r248,%r249,%r250,%r251}, [%rd228];
	// end inline asm
	add.s64 	%rd232, %rd226, 16;
	// begin inline asm
	cvta.to.global.u64 %rd231, %rd232;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r252,%r253,%r254,%r255}, [%rd231];
	// end inline asm
	add.s64 	%rd235, %rd226, 32;
	// begin inline asm
	cvta.to.global.u64 %rd234, %rd235;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r256,%r257,%r258,%r259}, [%rd234];
	// end inline asm
	add.s64 	%rd238, %rd226, 48;
	// begin inline asm
	cvta.to.global.u64 %rd237, %rd238;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r260,%r261,%r262,%r263}, [%rd237];
	// end inline asm
	add.s64 	%rd241, %rd226, 64;
	// begin inline asm
	cvta.to.global.u64 %rd240, %rd241;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r264,%r265,%r266,%r267}, [%rd240];
	// end inline asm
	add.s64 	%rd244, %rd226, 80;
	// begin inline asm
	cvta.to.global.u64 %rd243, %rd244;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r268,%r269,%r270,%r271}, [%rd243];
	// end inline asm
	add.s64 	%rd247, %rd226, 96;
	// begin inline asm
	cvta.to.global.u64 %rd246, %rd247;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r272,%r273,%r274,%r275}, [%rd246];
	// end inline asm
	add.s64 	%rd250, %rd226, 112;
	// begin inline asm
	cvta.to.global.u64 %rd249, %rd250;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r276,%r277,%r278,%r279}, [%rd249];
	// end inline asm
	mov.b32 	%f2813, %r251;
	mov.b32 	%f2814, %r252;
	and.b32  	%r292, %r250, 65535;
	add.s32 	%r293, %r292, -1;
	cvt.rn.f32.s32 	%f2815, %r293;
	sub.ftz.f32 	%f2816, %f2692, %f2813;
	sub.ftz.f32 	%f2817, %f2814, %f2813;
	div.approx.ftz.f32 	%f2818, %f2816, %f2817;
	mul.ftz.f32 	%f2819, %f2818, %f2815;
	min.ftz.f32 	%f2820, %f2815, %f2819;
	mov.f32 	%f2821, 0f00000000;
	max.ftz.f32 	%f2822, %f2821, %f2820;
	setp.num.ftz.f32 	%p13, %f2822, %f2822;
	selp.f32 	%f2823, %f2822, 0f00000000, %p13;
	cvt.rmi.ftz.f32.f32 	%f2824, %f2823;
	add.ftz.f32 	%f2825, %f2815, 0fBF800000;
	min.ftz.f32 	%f2826, %f2824, %f2825;
	sub.ftz.f32 	%f92, %f2823, %f2826;
	cvt.rzi.ftz.s32.f32 	%r294, %f2826;
	cvt.s64.s32 	%rd19, %r294;
	mul.wide.s32 	%rd261, %r294, 48;
	add.s64 	%rd253, %rd235, %rd261;
	// begin inline asm
	cvta.to.global.u64 %rd252, %rd253;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r280,%r281,%r282,%r283}, [%rd252];
	// end inline asm
	mov.b32 	%f6862, %r280;
	mov.b32 	%f6861, %r281;
	mov.b32 	%f6860, %r282;
	mov.b32 	%f6859, %r283;
	add.s64 	%rd256, %rd253, 16;
	// begin inline asm
	cvta.to.global.u64 %rd255, %rd256;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r284,%r285,%r286,%r287}, [%rd255];
	// end inline asm
	mov.b32 	%f6866, %r284;
	mov.b32 	%f6865, %r285;
	mov.b32 	%f6864, %r286;
	mov.b32 	%f6863, %r287;
	add.s64 	%rd259, %rd253, 32;
	// begin inline asm
	cvta.to.global.u64 %rd258, %rd259;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r288,%r289,%r290,%r291}, [%rd258];
	// end inline asm
	mov.b32 	%f6870, %r288;
	mov.b32 	%f6869, %r289;
	mov.b32 	%f6868, %r290;
	mov.b32 	%f6867, %r291;
	setp.leu.ftz.f32 	%p14, %f92, 0f00000000;
	@%p14 bra 	$L__BB4_15;

	mov.f32 	%f2827, 0f3F800000;
	sub.ftz.f32 	%f2828, %f2827, %f92;
	mul.lo.s64 	%rd271, %rd19, 48;
	add.s64 	%rd272, %rd226, %rd271;
	add.s64 	%rd263, %rd272, 80;
	// begin inline asm
	cvta.to.global.u64 %rd262, %rd263;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r295,%r296,%r297,%r298}, [%rd262];
	// end inline asm
	mov.b32 	%f2829, %r295;
	mov.b32 	%f2830, %r296;
	mov.b32 	%f2831, %r297;
	mov.b32 	%f2832, %r298;
	mul.ftz.f32 	%f2833, %f92, %f2829;
	mul.ftz.f32 	%f2834, %f92, %f2830;
	mul.ftz.f32 	%f2835, %f92, %f2831;
	mul.ftz.f32 	%f2836, %f92, %f2832;
	fma.rn.ftz.f32 	%f6862, %f2828, %f6862, %f2833;
	fma.rn.ftz.f32 	%f6861, %f2828, %f6861, %f2834;
	fma.rn.ftz.f32 	%f6860, %f2828, %f6860, %f2835;
	fma.rn.ftz.f32 	%f6859, %f2828, %f6859, %f2836;
	add.s64 	%rd266, %rd272, 96;
	// begin inline asm
	cvta.to.global.u64 %rd265, %rd266;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r299,%r300,%r301,%r302}, [%rd265];
	// end inline asm
	mov.b32 	%f2837, %r299;
	mov.b32 	%f2838, %r300;
	mov.b32 	%f2839, %r301;
	mov.b32 	%f2840, %r302;
	mul.ftz.f32 	%f2841, %f92, %f2837;
	mul.ftz.f32 	%f2842, %f92, %f2838;
	mul.ftz.f32 	%f2843, %f92, %f2839;
	mul.ftz.f32 	%f2844, %f92, %f2840;
	fma.rn.ftz.f32 	%f6866, %f2828, %f6866, %f2841;
	fma.rn.ftz.f32 	%f6865, %f2828, %f6865, %f2842;
	fma.rn.ftz.f32 	%f6864, %f2828, %f6864, %f2843;
	fma.rn.ftz.f32 	%f6863, %f2828, %f6863, %f2844;
	add.s64 	%rd269, %rd272, 112;
	// begin inline asm
	cvta.to.global.u64 %rd268, %rd269;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r303,%r304,%r305,%r306}, [%rd268];
	// end inline asm
	mov.b32 	%f2845, %r303;
	mov.b32 	%f2846, %r304;
	mov.b32 	%f2847, %r305;
	mov.b32 	%f2848, %r306;
	mul.ftz.f32 	%f2849, %f92, %f2845;
	mul.ftz.f32 	%f2850, %f92, %f2846;
	mul.ftz.f32 	%f2851, %f92, %f2847;
	mul.ftz.f32 	%f2852, %f92, %f2848;
	fma.rn.ftz.f32 	%f6870, %f2828, %f6870, %f2849;
	fma.rn.ftz.f32 	%f6869, %f2828, %f6869, %f2850;
	fma.rn.ftz.f32 	%f6868, %f2828, %f6868, %f2851;
	fma.rn.ftz.f32 	%f6867, %f2828, %f6867, %f2852;
	bra.uni 	$L__BB4_15;

$L__BB4_4:
	mov.f32 	%f6859, 0f00000000;
	mov.f32 	%f6862, 0f3F800000;
	setp.eq.s32 	%p8, %r159, 4;
	@%p8 bra 	$L__BB4_7;

	setp.ne.s32 	%p9, %r159, 1;
	mov.f32 	%f6860, %f6859;
	mov.f32 	%f6861, %f6859;
	mov.f32 	%f6863, %f6859;
	mov.f32 	%f6864, %f6859;
	mov.f32 	%f6865, %f6862;
	mov.f32 	%f6866, %f6859;
	mov.f32 	%f6867, %f6859;
	mov.f32 	%f6868, %f6862;
	mov.f32 	%f6869, %f6859;
	mov.f32 	%f6870, %f6859;
	@%p9 bra 	$L__BB4_15;

	// begin inline asm
	call (%rd156), _optix_get_static_transform_from_handle, (%rd154);
	// end inline asm
	add.s64 	%rd1963, %rd156, 16;
	bra.uni 	$L__BB4_8;

$L__BB4_10:
	// begin inline asm
	call (%rd169), _optix_get_srt_motion_transform_from_handle, (%rd154);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd171, %rd169;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r173,%r174,%r175,%r176}, [%rd171];
	// end inline asm
	add.s64 	%rd175, %rd169, 16;
	// begin inline asm
	cvta.to.global.u64 %rd174, %rd175;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r177,%r178,%r179,%r180}, [%rd174];
	// end inline asm
	add.s64 	%rd178, %rd169, 32;
	// begin inline asm
	cvta.to.global.u64 %rd177, %rd178;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r181,%r182,%r183,%r184}, [%rd177];
	// end inline asm
	add.s64 	%rd181, %rd169, 48;
	// begin inline asm
	cvta.to.global.u64 %rd180, %rd181;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r185,%r186,%r187,%r188}, [%rd180];
	// end inline asm
	add.s64 	%rd184, %rd169, 64;
	// begin inline asm
	cvta.to.global.u64 %rd183, %rd184;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r189,%r190,%r191,%r192}, [%rd183];
	// end inline asm
	add.s64 	%rd187, %rd169, 80;
	// begin inline asm
	cvta.to.global.u64 %rd186, %rd187;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r193,%r194,%r195,%r196}, [%rd186];
	// end inline asm
	add.s64 	%rd190, %rd169, 96;
	// begin inline asm
	cvta.to.global.u64 %rd189, %rd190;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r197,%r198,%r199,%r200}, [%rd189];
	// end inline asm
	add.s64 	%rd193, %rd169, 112;
	// begin inline asm
	cvta.to.global.u64 %rd192, %rd193;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r201,%r202,%r203,%r204}, [%rd192];
	// end inline asm
	add.s64 	%rd196, %rd169, 128;
	// begin inline asm
	cvta.to.global.u64 %rd195, %rd196;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r205,%r206,%r207,%r208}, [%rd195];
	// end inline asm
	add.s64 	%rd199, %rd169, 144;
	// begin inline asm
	cvta.to.global.u64 %rd198, %rd199;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r209,%r210,%r211,%r212}, [%rd198];
	// end inline asm
	mov.b32 	%f2707, %r176;
	mov.b32 	%f2708, %r177;
	and.b32  	%r229, %r175, 65535;
	add.s32 	%r230, %r229, -1;
	cvt.rn.f32.s32 	%f2709, %r230;
	sub.ftz.f32 	%f2710, %f2692, %f2707;
	sub.ftz.f32 	%f2711, %f2708, %f2707;
	div.approx.ftz.f32 	%f2712, %f2710, %f2711;
	mul.ftz.f32 	%f2713, %f2712, %f2709;
	min.ftz.f32 	%f2714, %f2709, %f2713;
	mov.f32 	%f2715, 0f00000000;
	max.ftz.f32 	%f2716, %f2715, %f2714;
	setp.num.ftz.f32 	%p11, %f2716, %f2716;
	selp.f32 	%f2717, %f2716, 0f00000000, %p11;
	cvt.rmi.ftz.f32.f32 	%f2718, %f2717;
	add.ftz.f32 	%f2719, %f2709, 0fBF800000;
	min.ftz.f32 	%f2720, %f2718, %f2719;
	sub.ftz.f32 	%f31, %f2717, %f2720;
	cvt.rzi.ftz.s32.f32 	%r231, %f2720;
	mul.wide.s32 	%rd213, %r231, 64;
	add.s64 	%rd202, %rd178, %rd213;
	// begin inline asm
	cvta.to.global.u64 %rd201, %rd202;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r213,%r214,%r215,%r216}, [%rd201];
	// end inline asm
	mov.b32 	%f6843, %r213;
	mov.b32 	%f6844, %r214;
	mov.b32 	%f6845, %r215;
	mov.b32 	%f6846, %r216;
	add.s64 	%rd205, %rd202, 16;
	// begin inline asm
	cvta.to.global.u64 %rd204, %rd205;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r217,%r218,%r219,%r220}, [%rd204];
	// end inline asm
	mov.b32 	%f6847, %r217;
	mov.b32 	%f6848, %r218;
	mov.b32 	%f6849, %r219;
	mov.b32 	%f6850, %r220;
	add.s64 	%rd208, %rd202, 32;
	// begin inline asm
	cvta.to.global.u64 %rd207, %rd208;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r221,%r222,%r223,%r224}, [%rd207];
	// end inline asm
	mov.b32 	%f6851, %r221;
	mov.b32 	%f6852, %r222;
	mov.b32 	%f6853, %r223;
	mov.b32 	%f6854, %r224;
	add.s64 	%rd211, %rd202, 48;
	// begin inline asm
	cvta.to.global.u64 %rd210, %rd211;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r225,%r226,%r227,%r228}, [%rd210];
	// end inline asm
	mov.b32 	%f6855, %r225;
	mov.b32 	%f6856, %r226;
	mov.b32 	%f6857, %r227;
	mov.b32 	%f6858, %r228;
	setp.leu.ftz.f32 	%p12, %f31, 0f00000000;
	@%p12 bra 	$L__BB4_12;

	mov.f32 	%f2721, 0f3F800000;
	sub.ftz.f32 	%f2722, %f2721, %f31;
	add.s64 	%rd215, %rd202, 64;
	// begin inline asm
	cvta.to.global.u64 %rd214, %rd215;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r232,%r233,%r234,%r235}, [%rd214];
	// end inline asm
	mov.b32 	%f2723, %r232;
	mov.b32 	%f2724, %r233;
	mov.b32 	%f2725, %r234;
	mov.b32 	%f2726, %r235;
	mul.ftz.f32 	%f2727, %f31, %f2723;
	mul.ftz.f32 	%f2728, %f31, %f2724;
	mul.ftz.f32 	%f2729, %f31, %f2725;
	mul.ftz.f32 	%f2730, %f31, %f2726;
	fma.rn.ftz.f32 	%f6843, %f2722, %f6843, %f2727;
	fma.rn.ftz.f32 	%f6844, %f2722, %f6844, %f2728;
	fma.rn.ftz.f32 	%f6845, %f2722, %f6845, %f2729;
	fma.rn.ftz.f32 	%f6846, %f2722, %f6846, %f2730;
	add.s64 	%rd218, %rd202, 80;
	// begin inline asm
	cvta.to.global.u64 %rd217, %rd218;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r236,%r237,%r238,%r239}, [%rd217];
	// end inline asm
	mov.b32 	%f2731, %r236;
	mov.b32 	%f2732, %r237;
	mov.b32 	%f2733, %r238;
	mov.b32 	%f2734, %r239;
	mul.ftz.f32 	%f2735, %f31, %f2731;
	mul.ftz.f32 	%f2736, %f31, %f2732;
	mul.ftz.f32 	%f2737, %f31, %f2733;
	mul.ftz.f32 	%f2738, %f31, %f2734;
	fma.rn.ftz.f32 	%f6847, %f2722, %f6847, %f2735;
	fma.rn.ftz.f32 	%f6848, %f2722, %f6848, %f2736;
	fma.rn.ftz.f32 	%f6849, %f2722, %f6849, %f2737;
	fma.rn.ftz.f32 	%f6850, %f2722, %f6850, %f2738;
	add.s64 	%rd221, %rd202, 96;
	// begin inline asm
	cvta.to.global.u64 %rd220, %rd221;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r240,%r241,%r242,%r243}, [%rd220];
	// end inline asm
	mov.b32 	%f2739, %r240;
	mov.b32 	%f2740, %r241;
	mov.b32 	%f2741, %r242;
	mov.b32 	%f2742, %r243;
	mul.ftz.f32 	%f2743, %f31, %f2739;
	mul.ftz.f32 	%f2744, %f31, %f2740;
	mul.ftz.f32 	%f2745, %f31, %f2741;
	mul.ftz.f32 	%f2746, %f31, %f2742;
	fma.rn.ftz.f32 	%f6851, %f2722, %f6851, %f2743;
	fma.rn.ftz.f32 	%f2747, %f2722, %f6852, %f2744;
	fma.rn.ftz.f32 	%f2748, %f2722, %f6853, %f2745;
	fma.rn.ftz.f32 	%f2749, %f2722, %f6854, %f2746;
	add.s64 	%rd224, %rd202, 112;
	// begin inline asm
	cvta.to.global.u64 %rd223, %rd224;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r244,%r245,%r246,%r247}, [%rd223];
	// end inline asm
	mov.b32 	%f2750, %r244;
	mov.b32 	%f2751, %r245;
	mov.b32 	%f2752, %r246;
	mov.b32 	%f2753, %r247;
	mul.ftz.f32 	%f2754, %f31, %f2750;
	mul.ftz.f32 	%f2755, %f31, %f2751;
	mul.ftz.f32 	%f2756, %f31, %f2752;
	mul.ftz.f32 	%f2757, %f31, %f2753;
	fma.rn.ftz.f32 	%f2758, %f2722, %f6855, %f2754;
	fma.rn.ftz.f32 	%f6856, %f2722, %f6856, %f2755;
	fma.rn.ftz.f32 	%f6857, %f2722, %f6857, %f2756;
	fma.rn.ftz.f32 	%f6858, %f2722, %f6858, %f2757;
	mul.ftz.f32 	%f2759, %f2748, %f2748;
	fma.rn.ftz.f32 	%f2760, %f2747, %f2747, %f2759;
	fma.rn.ftz.f32 	%f2761, %f2749, %f2749, %f2760;
	fma.rn.ftz.f32 	%f2762, %f2758, %f2758, %f2761;
	rsqrt.approx.ftz.f32 	%f2763, %f2762;
	mul.ftz.f32 	%f6852, %f2747, %f2763;
	mul.ftz.f32 	%f6853, %f2748, %f2763;
	mul.ftz.f32 	%f6854, %f2749, %f2763;
	mul.ftz.f32 	%f6855, %f2763, %f2758;

$L__BB4_12:
	mul.ftz.f32 	%f2764, %f6853, %f6853;
	mul.ftz.f32 	%f2765, %f6852, %f6852;
	sub.ftz.f32 	%f2766, %f2765, %f2764;
	mul.ftz.f32 	%f2767, %f6854, %f6854;
	sub.ftz.f32 	%f2768, %f2766, %f2767;
	fma.rn.ftz.f32 	%f2769, %f6855, %f6855, %f2768;
	mul.ftz.f32 	%f2770, %f6854, %f6855;
	mul.ftz.f32 	%f2771, %f6852, %f6853;
	sub.ftz.f32 	%f2772, %f2771, %f2770;
	add.ftz.f32 	%f2773, %f2772, %f2772;
	mul.ftz.f32 	%f2774, %f6853, %f6855;
	mul.ftz.f32 	%f2775, %f6852, %f6854;
	add.ftz.f32 	%f2776, %f2775, %f2774;
	add.ftz.f32 	%f2777, %f2776, %f2776;
	add.ftz.f32 	%f2778, %f2771, %f2770;
	add.ftz.f32 	%f2779, %f2778, %f2778;
	sub.ftz.f32 	%f2780, %f2764, %f2765;
	sub.ftz.f32 	%f2781, %f2780, %f2767;
	fma.rn.ftz.f32 	%f2782, %f6855, %f6855, %f2781;
	mul.ftz.f32 	%f2783, %f6852, %f6855;
	mul.ftz.f32 	%f2784, %f6853, %f6854;
	sub.ftz.f32 	%f2785, %f2784, %f2783;
	add.ftz.f32 	%f2786, %f2785, %f2785;
	sub.ftz.f32 	%f2787, %f2775, %f2774;
	add.ftz.f32 	%f2788, %f2787, %f2787;
	add.ftz.f32 	%f2789, %f2784, %f2783;
	add.ftz.f32 	%f2790, %f2789, %f2789;
	neg.ftz.f32 	%f2791, %f2765;
	sub.ftz.f32 	%f2792, %f2791, %f2764;
	add.ftz.f32 	%f2793, %f2792, %f2767;
	fma.rn.ftz.f32 	%f2794, %f6855, %f6855, %f2793;
	mul.ftz.f32 	%f2795, %f6849, %f2773;
	fma.rn.ftz.f32 	%f2796, %f6846, %f2769, %f2795;
	fma.rn.ftz.f32 	%f2797, %f6851, %f2777, %f2796;
	add.ftz.f32 	%f6859, %f6856, %f2797;
	mul.ftz.f32 	%f2798, %f6846, %f2779;
	fma.rn.ftz.f32 	%f2799, %f6849, %f2782, %f2798;
	fma.rn.ftz.f32 	%f2800, %f6851, %f2786, %f2799;
	add.ftz.f32 	%f6863, %f6857, %f2800;
	mul.ftz.f32 	%f2801, %f6849, %f2790;
	fma.rn.ftz.f32 	%f2802, %f6846, %f2788, %f2801;
	fma.rn.ftz.f32 	%f2803, %f6851, %f2794, %f2802;
	add.ftz.f32 	%f6867, %f6858, %f2803;
	mul.ftz.f32 	%f2804, %f6848, %f2773;
	fma.rn.ftz.f32 	%f2805, %f6845, %f2769, %f2804;
	fma.rn.ftz.f32 	%f6860, %f6850, %f2777, %f2805;
	mul.ftz.f32 	%f2806, %f6845, %f2779;
	fma.rn.ftz.f32 	%f2807, %f6848, %f2782, %f2806;
	fma.rn.ftz.f32 	%f6864, %f6850, %f2786, %f2807;
	mul.ftz.f32 	%f2808, %f6848, %f2790;
	fma.rn.ftz.f32 	%f2809, %f6845, %f2788, %f2808;
	fma.rn.ftz.f32 	%f6868, %f6850, %f2794, %f2809;
	mul.ftz.f32 	%f2810, %f6847, %f2773;
	fma.rn.ftz.f32 	%f6861, %f6844, %f2769, %f2810;
	mul.ftz.f32 	%f2811, %f6844, %f2779;
	fma.rn.ftz.f32 	%f6865, %f6847, %f2782, %f2811;
	mul.ftz.f32 	%f2812, %f6847, %f2790;
	fma.rn.ftz.f32 	%f6869, %f6844, %f2788, %f2812;
	mul.ftz.f32 	%f6862, %f6843, %f2769;
	mul.ftz.f32 	%f6866, %f6843, %f2779;
	mul.ftz.f32 	%f6870, %f6843, %f2788;
	bra.uni 	$L__BB4_15;

$L__BB4_7:
	// begin inline asm
	call (%rd1963), _optix_get_instance_transform_from_handle, (%rd154);
	// end inline asm

$L__BB4_8:
	// begin inline asm
	cvta.to.global.u64 %rd160, %rd1963;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r161,%r162,%r163,%r164}, [%rd160];
	// end inline asm
	mov.b32 	%f6862, %r161;
	mov.b32 	%f6861, %r162;
	mov.b32 	%f6860, %r163;
	mov.b32 	%f6859, %r164;
	add.s64 	%rd164, %rd1963, 16;
	// begin inline asm
	cvta.to.global.u64 %rd163, %rd164;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r165,%r166,%r167,%r168}, [%rd163];
	// end inline asm
	mov.b32 	%f6866, %r165;
	mov.b32 	%f6865, %r166;
	mov.b32 	%f6864, %r167;
	mov.b32 	%f6863, %r168;
	add.s64 	%rd167, %rd1963, 32;
	// begin inline asm
	cvta.to.global.u64 %rd166, %rd167;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r169,%r170,%r171,%r172}, [%rd166];
	// end inline asm
	mov.b32 	%f6870, %r169;
	mov.b32 	%f6869, %r170;
	mov.b32 	%f6868, %r171;
	mov.b32 	%f6867, %r172;

$L__BB4_15:
	setp.eq.s32 	%p15, %r2498, %r157;
	@%p15 bra 	$L__BB4_17;

	mul.ftz.f32 	%f2853, %f6839, %f6862;
	fma.rn.ftz.f32 	%f2854, %f6835, %f6861, %f2853;
	fma.rn.ftz.f32 	%f129, %f6831, %f6860, %f2854;
	mul.ftz.f32 	%f2855, %f6840, %f6862;
	fma.rn.ftz.f32 	%f2856, %f6836, %f6861, %f2855;
	fma.rn.ftz.f32 	%f130, %f6832, %f6860, %f2856;
	mul.ftz.f32 	%f2857, %f6841, %f6862;
	fma.rn.ftz.f32 	%f2858, %f6837, %f6861, %f2857;
	fma.rn.ftz.f32 	%f131, %f6833, %f6860, %f2858;
	mul.ftz.f32 	%f2859, %f6842, %f6862;
	fma.rn.ftz.f32 	%f2860, %f6838, %f6861, %f2859;
	fma.rn.ftz.f32 	%f2861, %f6834, %f6860, %f2860;
	add.ftz.f32 	%f6859, %f6859, %f2861;
	mul.ftz.f32 	%f2862, %f6839, %f6866;
	fma.rn.ftz.f32 	%f2863, %f6835, %f6865, %f2862;
	fma.rn.ftz.f32 	%f133, %f6831, %f6864, %f2863;
	mul.ftz.f32 	%f2864, %f6840, %f6866;
	fma.rn.ftz.f32 	%f2865, %f6836, %f6865, %f2864;
	fma.rn.ftz.f32 	%f134, %f6832, %f6864, %f2865;
	mul.ftz.f32 	%f2866, %f6841, %f6866;
	fma.rn.ftz.f32 	%f2867, %f6837, %f6865, %f2866;
	fma.rn.ftz.f32 	%f135, %f6833, %f6864, %f2867;
	mul.ftz.f32 	%f2868, %f6842, %f6866;
	fma.rn.ftz.f32 	%f2869, %f6838, %f6865, %f2868;
	fma.rn.ftz.f32 	%f2870, %f6834, %f6864, %f2869;
	add.ftz.f32 	%f6863, %f6863, %f2870;
	mul.ftz.f32 	%f2871, %f6839, %f6870;
	fma.rn.ftz.f32 	%f2872, %f6835, %f6869, %f2871;
	fma.rn.ftz.f32 	%f137, %f6831, %f6868, %f2872;
	mul.ftz.f32 	%f2873, %f6840, %f6870;
	fma.rn.ftz.f32 	%f2874, %f6836, %f6869, %f2873;
	fma.rn.ftz.f32 	%f138, %f6832, %f6868, %f2874;
	mul.ftz.f32 	%f2875, %f6841, %f6870;
	fma.rn.ftz.f32 	%f2876, %f6837, %f6869, %f2875;
	fma.rn.ftz.f32 	%f139, %f6833, %f6868, %f2876;
	mul.ftz.f32 	%f2877, %f6842, %f6870;
	fma.rn.ftz.f32 	%f2878, %f6838, %f6869, %f2877;
	fma.rn.ftz.f32 	%f2879, %f6834, %f6868, %f2878;
	add.ftz.f32 	%f6867, %f6867, %f2879;
	mov.f32 	%f6860, %f131;
	mov.f32 	%f6861, %f130;
	mov.f32 	%f6862, %f129;
	mov.f32 	%f6864, %f135;
	mov.f32 	%f6865, %f134;
	mov.f32 	%f6866, %f133;
	mov.f32 	%f6868, %f139;
	mov.f32 	%f6869, %f138;
	mov.f32 	%f6870, %f137;

$L__BB4_17:
	add.s32 	%r2497, %r2498, -1;
	setp.gt.s32 	%p16, %r2498, 1;
	mov.u32 	%r2498, %r2497;
	mov.f32 	%f6831, %f6870;
	mov.f32 	%f6832, %f6869;
	mov.f32 	%f6833, %f6868;
	mov.f32 	%f6834, %f6867;
	mov.f32 	%f6835, %f6866;
	mov.f32 	%f6836, %f6865;
	mov.f32 	%f6837, %f6864;
	mov.f32 	%f6838, %f6863;
	mov.f32 	%f6839, %f6862;
	mov.f32 	%f6840, %f6861;
	mov.f32 	%f6841, %f6860;
	mov.f32 	%f6842, %f6859;
	@%p16 bra 	$L__BB4_3;

$L__BB4_18:
	mul.ftz.f32 	%f2880, %f6895, %f6862;
	fma.rn.ftz.f32 	%f2881, %f6896, %f6861, %f2880;
	fma.rn.ftz.f32 	%f2882, %f6897, %f6860, %f2881;
	mul.ftz.f32 	%f2883, %f6895, %f6866;
	fma.rn.ftz.f32 	%f2884, %f6896, %f6865, %f2883;
	fma.rn.ftz.f32 	%f2885, %f6897, %f6864, %f2884;
	mul.ftz.f32 	%f2886, %f6895, %f6870;
	fma.rn.ftz.f32 	%f2887, %f6896, %f6869, %f2886;
	fma.rn.ftz.f32 	%f2888, %f6897, %f6868, %f2887;
	add.ftz.f32 	%f6897, %f6867, %f2888;
	add.ftz.f32 	%f6896, %f6863, %f2885;
	add.ftz.f32 	%f6895, %f6859, %f2882;

$L__BB4_19:
	mul.wide.u32 	%rd273, %r5, 44;
	add.s64 	%rd20, %rd11, %rd273;
	ld.f32 	%f6962, [%rd20];
	ld.f32 	%f6963, [%rd20+4];
	ld.f32 	%f6964, [%rd20+8];
	// begin inline asm
	call (%r307), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p17, %r307, 0;
	@%p17 bra 	$L__BB4_38;

	// begin inline asm
	call (%r308), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f2889), _optix_get_ray_time, ();
	// end inline asm
	setp.lt.s32 	%p18, %r308, 1;
	@%p18 bra 	$L__BB4_37;

	mov.u32 	%r2499, %r308;

$L__BB4_22:
	.pragma "nounroll";
	add.s32 	%r309, %r2499, -1;
	// begin inline asm
	call (%rd274), _optix_get_transform_list_handle, (%r309);
	// end inline asm
	// begin inline asm
	call (%r310), _optix_get_transform_type_from_handle, (%rd274);
	// end inline asm
	or.b32  	%r311, %r310, 1;
	setp.eq.s32 	%p19, %r311, 3;
	@%p19 bra 	$L__BB4_28;
	bra.uni 	$L__BB4_23;

$L__BB4_28:
	setp.eq.s32 	%p22, %r310, 2;
	@%p22 bra 	$L__BB4_32;
	bra.uni 	$L__BB4_29;

$L__BB4_32:
	// begin inline asm
	call (%rd346), _optix_get_matrix_motion_transform_from_handle, (%rd274);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd348, %rd346;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r399,%r400,%r401,%r402}, [%rd348];
	// end inline asm
	add.s64 	%rd352, %rd346, 16;
	// begin inline asm
	cvta.to.global.u64 %rd351, %rd352;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r403,%r404,%r405,%r406}, [%rd351];
	// end inline asm
	add.s64 	%rd355, %rd346, 32;
	// begin inline asm
	cvta.to.global.u64 %rd354, %rd355;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r407,%r408,%r409,%r410}, [%rd354];
	// end inline asm
	add.s64 	%rd358, %rd346, 48;
	// begin inline asm
	cvta.to.global.u64 %rd357, %rd358;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r411,%r412,%r413,%r414}, [%rd357];
	// end inline asm
	add.s64 	%rd361, %rd346, 64;
	// begin inline asm
	cvta.to.global.u64 %rd360, %rd361;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r415,%r416,%r417,%r418}, [%rd360];
	// end inline asm
	add.s64 	%rd364, %rd346, 80;
	// begin inline asm
	cvta.to.global.u64 %rd363, %rd364;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r419,%r420,%r421,%r422}, [%rd363];
	// end inline asm
	add.s64 	%rd367, %rd346, 96;
	// begin inline asm
	cvta.to.global.u64 %rd366, %rd367;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r423,%r424,%r425,%r426}, [%rd366];
	// end inline asm
	add.s64 	%rd370, %rd346, 112;
	// begin inline asm
	cvta.to.global.u64 %rd369, %rd370;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r427,%r428,%r429,%r430}, [%rd369];
	// end inline asm
	mov.b32 	%f3010, %r402;
	mov.b32 	%f3011, %r403;
	and.b32  	%r443, %r401, 65535;
	add.s32 	%r444, %r443, -1;
	cvt.rn.f32.s32 	%f3012, %r444;
	sub.ftz.f32 	%f3013, %f2889, %f3010;
	sub.ftz.f32 	%f3014, %f3011, %f3010;
	div.approx.ftz.f32 	%f3015, %f3013, %f3014;
	mul.ftz.f32 	%f3016, %f3015, %f3012;
	min.ftz.f32 	%f3017, %f3012, %f3016;
	mov.f32 	%f3018, 0f00000000;
	max.ftz.f32 	%f3019, %f3018, %f3017;
	setp.num.ftz.f32 	%p25, %f3019, %f3019;
	selp.f32 	%f3020, %f3019, 0f00000000, %p25;
	cvt.rmi.ftz.f32.f32 	%f3021, %f3020;
	add.ftz.f32 	%f3022, %f3012, 0fBF800000;
	min.ftz.f32 	%f3023, %f3021, %f3022;
	sub.ftz.f32 	%f263, %f3020, %f3023;
	cvt.rzi.ftz.s32.f32 	%r445, %f3023;
	cvt.s64.s32 	%rd27, %r445;
	mul.wide.s32 	%rd381, %r445, 48;
	add.s64 	%rd373, %rd355, %rd381;
	// begin inline asm
	cvta.to.global.u64 %rd372, %rd373;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r431,%r432,%r433,%r434}, [%rd372];
	// end inline asm
	mov.b32 	%f6934, %r431;
	mov.b32 	%f6935, %r432;
	mov.b32 	%f6936, %r433;
	mov.b32 	%f6937, %r434;
	add.s64 	%rd376, %rd373, 16;
	// begin inline asm
	cvta.to.global.u64 %rd375, %rd376;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r435,%r436,%r437,%r438}, [%rd375];
	// end inline asm
	mov.b32 	%f6930, %r435;
	mov.b32 	%f6931, %r436;
	mov.b32 	%f6932, %r437;
	mov.b32 	%f6933, %r438;
	add.s64 	%rd379, %rd373, 32;
	// begin inline asm
	cvta.to.global.u64 %rd378, %rd379;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r439,%r440,%r441,%r442}, [%rd378];
	// end inline asm
	mov.b32 	%f6926, %r439;
	mov.b32 	%f6927, %r440;
	mov.b32 	%f6928, %r441;
	mov.b32 	%f6929, %r442;
	setp.leu.ftz.f32 	%p26, %f263, 0f00000000;
	@%p26 bra 	$L__BB4_34;

	mov.f32 	%f3024, 0f3F800000;
	sub.ftz.f32 	%f3025, %f3024, %f263;
	mul.lo.s64 	%rd391, %rd27, 48;
	add.s64 	%rd392, %rd346, %rd391;
	add.s64 	%rd383, %rd392, 80;
	// begin inline asm
	cvta.to.global.u64 %rd382, %rd383;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r446,%r447,%r448,%r449}, [%rd382];
	// end inline asm
	mov.b32 	%f3026, %r446;
	mov.b32 	%f3027, %r447;
	mov.b32 	%f3028, %r448;
	mov.b32 	%f3029, %r449;
	mul.ftz.f32 	%f3030, %f263, %f3026;
	mul.ftz.f32 	%f3031, %f263, %f3027;
	mul.ftz.f32 	%f3032, %f263, %f3028;
	mul.ftz.f32 	%f3033, %f263, %f3029;
	fma.rn.ftz.f32 	%f6934, %f3025, %f6934, %f3030;
	fma.rn.ftz.f32 	%f6935, %f3025, %f6935, %f3031;
	fma.rn.ftz.f32 	%f6936, %f3025, %f6936, %f3032;
	fma.rn.ftz.f32 	%f6937, %f3025, %f6937, %f3033;
	add.s64 	%rd386, %rd392, 96;
	// begin inline asm
	cvta.to.global.u64 %rd385, %rd386;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r450,%r451,%r452,%r453}, [%rd385];
	// end inline asm
	mov.b32 	%f3034, %r450;
	mov.b32 	%f3035, %r451;
	mov.b32 	%f3036, %r452;
	mov.b32 	%f3037, %r453;
	mul.ftz.f32 	%f3038, %f263, %f3034;
	mul.ftz.f32 	%f3039, %f263, %f3035;
	mul.ftz.f32 	%f3040, %f263, %f3036;
	mul.ftz.f32 	%f3041, %f263, %f3037;
	fma.rn.ftz.f32 	%f6930, %f3025, %f6930, %f3038;
	fma.rn.ftz.f32 	%f6931, %f3025, %f6931, %f3039;
	fma.rn.ftz.f32 	%f6932, %f3025, %f6932, %f3040;
	fma.rn.ftz.f32 	%f6933, %f3025, %f6933, %f3041;
	add.s64 	%rd389, %rd392, 112;
	// begin inline asm
	cvta.to.global.u64 %rd388, %rd389;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r454,%r455,%r456,%r457}, [%rd388];
	// end inline asm
	mov.b32 	%f3042, %r454;
	mov.b32 	%f3043, %r455;
	mov.b32 	%f3044, %r456;
	mov.b32 	%f3045, %r457;
	mul.ftz.f32 	%f3046, %f263, %f3042;
	mul.ftz.f32 	%f3047, %f263, %f3043;
	mul.ftz.f32 	%f3048, %f263, %f3044;
	mul.ftz.f32 	%f3049, %f263, %f3045;
	fma.rn.ftz.f32 	%f6926, %f3025, %f6926, %f3046;
	fma.rn.ftz.f32 	%f6927, %f3025, %f6927, %f3047;
	fma.rn.ftz.f32 	%f6928, %f3025, %f6928, %f3048;
	fma.rn.ftz.f32 	%f6929, %f3025, %f6929, %f3049;
	bra.uni 	$L__BB4_34;

$L__BB4_23:
	mov.f32 	%f6926, 0f00000000;
	mov.f32 	%f6928, 0f3F800000;
	setp.eq.s32 	%p20, %r310, 4;
	@%p20 bra 	$L__BB4_26;

	setp.ne.s32 	%p21, %r310, 1;
	mov.f32 	%f6927, %f6926;
	mov.f32 	%f6929, %f6926;
	mov.f32 	%f6930, %f6926;
	mov.f32 	%f6931, %f6928;
	mov.f32 	%f6932, %f6926;
	mov.f32 	%f6933, %f6926;
	mov.f32 	%f6934, %f6928;
	mov.f32 	%f6935, %f6926;
	mov.f32 	%f6936, %f6926;
	mov.f32 	%f6937, %f6926;
	@%p21 bra 	$L__BB4_34;

	// begin inline asm
	call (%rd276), _optix_get_static_transform_from_handle, (%rd274);
	// end inline asm
	add.s64 	%rd1964, %rd276, 16;
	bra.uni 	$L__BB4_27;

$L__BB4_29:
	// begin inline asm
	call (%rd289), _optix_get_srt_motion_transform_from_handle, (%rd274);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd291, %rd289;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r324,%r325,%r326,%r327}, [%rd291];
	// end inline asm
	add.s64 	%rd295, %rd289, 16;
	// begin inline asm
	cvta.to.global.u64 %rd294, %rd295;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r328,%r329,%r330,%r331}, [%rd294];
	// end inline asm
	add.s64 	%rd298, %rd289, 32;
	// begin inline asm
	cvta.to.global.u64 %rd297, %rd298;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r332,%r333,%r334,%r335}, [%rd297];
	// end inline asm
	add.s64 	%rd301, %rd289, 48;
	// begin inline asm
	cvta.to.global.u64 %rd300, %rd301;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r336,%r337,%r338,%r339}, [%rd300];
	// end inline asm
	add.s64 	%rd304, %rd289, 64;
	// begin inline asm
	cvta.to.global.u64 %rd303, %rd304;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r340,%r341,%r342,%r343}, [%rd303];
	// end inline asm
	add.s64 	%rd307, %rd289, 80;
	// begin inline asm
	cvta.to.global.u64 %rd306, %rd307;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r344,%r345,%r346,%r347}, [%rd306];
	// end inline asm
	add.s64 	%rd310, %rd289, 96;
	// begin inline asm
	cvta.to.global.u64 %rd309, %rd310;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r348,%r349,%r350,%r351}, [%rd309];
	// end inline asm
	add.s64 	%rd313, %rd289, 112;
	// begin inline asm
	cvta.to.global.u64 %rd312, %rd313;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r352,%r353,%r354,%r355}, [%rd312];
	// end inline asm
	add.s64 	%rd316, %rd289, 128;
	// begin inline asm
	cvta.to.global.u64 %rd315, %rd316;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r356,%r357,%r358,%r359}, [%rd315];
	// end inline asm
	add.s64 	%rd319, %rd289, 144;
	// begin inline asm
	cvta.to.global.u64 %rd318, %rd319;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r360,%r361,%r362,%r363}, [%rd318];
	// end inline asm
	mov.b32 	%f2904, %r327;
	mov.b32 	%f2905, %r328;
	and.b32  	%r380, %r326, 65535;
	add.s32 	%r381, %r380, -1;
	cvt.rn.f32.s32 	%f2906, %r381;
	sub.ftz.f32 	%f2907, %f2889, %f2904;
	sub.ftz.f32 	%f2908, %f2905, %f2904;
	div.approx.ftz.f32 	%f2909, %f2907, %f2908;
	mul.ftz.f32 	%f2910, %f2909, %f2906;
	min.ftz.f32 	%f2911, %f2906, %f2910;
	mov.f32 	%f2912, 0f00000000;
	max.ftz.f32 	%f2913, %f2912, %f2911;
	setp.num.ftz.f32 	%p23, %f2913, %f2913;
	selp.f32 	%f2914, %f2913, 0f00000000, %p23;
	cvt.rmi.ftz.f32.f32 	%f2915, %f2914;
	add.ftz.f32 	%f2916, %f2906, 0fBF800000;
	min.ftz.f32 	%f2917, %f2915, %f2916;
	sub.ftz.f32 	%f202, %f2914, %f2917;
	cvt.rzi.ftz.s32.f32 	%r382, %f2917;
	mul.wide.s32 	%rd333, %r382, 64;
	add.s64 	%rd322, %rd298, %rd333;
	// begin inline asm
	cvta.to.global.u64 %rd321, %rd322;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r364,%r365,%r366,%r367}, [%rd321];
	// end inline asm
	mov.b32 	%f6910, %r364;
	mov.b32 	%f6911, %r365;
	mov.b32 	%f6912, %r366;
	mov.b32 	%f6913, %r367;
	add.s64 	%rd325, %rd322, 16;
	// begin inline asm
	cvta.to.global.u64 %rd324, %rd325;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r368,%r369,%r370,%r371}, [%rd324];
	// end inline asm
	mov.b32 	%f6914, %r368;
	mov.b32 	%f6915, %r369;
	mov.b32 	%f6916, %r370;
	mov.b32 	%f6917, %r371;
	add.s64 	%rd328, %rd322, 32;
	// begin inline asm
	cvta.to.global.u64 %rd327, %rd328;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r372,%r373,%r374,%r375}, [%rd327];
	// end inline asm
	mov.b32 	%f6918, %r372;
	mov.b32 	%f6919, %r373;
	mov.b32 	%f6920, %r374;
	mov.b32 	%f6921, %r375;
	add.s64 	%rd331, %rd322, 48;
	// begin inline asm
	cvta.to.global.u64 %rd330, %rd331;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r376,%r377,%r378,%r379}, [%rd330];
	// end inline asm
	mov.b32 	%f6922, %r376;
	mov.b32 	%f6923, %r377;
	mov.b32 	%f6924, %r378;
	mov.b32 	%f6925, %r379;
	setp.leu.ftz.f32 	%p24, %f202, 0f00000000;
	@%p24 bra 	$L__BB4_31;

	mov.f32 	%f2918, 0f3F800000;
	sub.ftz.f32 	%f2919, %f2918, %f202;
	add.s64 	%rd335, %rd322, 64;
	// begin inline asm
	cvta.to.global.u64 %rd334, %rd335;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r383,%r384,%r385,%r386}, [%rd334];
	// end inline asm
	mov.b32 	%f2920, %r383;
	mov.b32 	%f2921, %r384;
	mov.b32 	%f2922, %r385;
	mov.b32 	%f2923, %r386;
	mul.ftz.f32 	%f2924, %f202, %f2920;
	mul.ftz.f32 	%f2925, %f202, %f2921;
	mul.ftz.f32 	%f2926, %f202, %f2922;
	mul.ftz.f32 	%f2927, %f202, %f2923;
	fma.rn.ftz.f32 	%f6910, %f2919, %f6910, %f2924;
	fma.rn.ftz.f32 	%f6911, %f2919, %f6911, %f2925;
	fma.rn.ftz.f32 	%f6912, %f2919, %f6912, %f2926;
	fma.rn.ftz.f32 	%f6913, %f2919, %f6913, %f2927;
	add.s64 	%rd338, %rd322, 80;
	// begin inline asm
	cvta.to.global.u64 %rd337, %rd338;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r387,%r388,%r389,%r390}, [%rd337];
	// end inline asm
	mov.b32 	%f2928, %r387;
	mov.b32 	%f2929, %r388;
	mov.b32 	%f2930, %r389;
	mov.b32 	%f2931, %r390;
	mul.ftz.f32 	%f2932, %f202, %f2928;
	mul.ftz.f32 	%f2933, %f202, %f2929;
	mul.ftz.f32 	%f2934, %f202, %f2930;
	mul.ftz.f32 	%f2935, %f202, %f2931;
	fma.rn.ftz.f32 	%f6914, %f2919, %f6914, %f2932;
	fma.rn.ftz.f32 	%f6915, %f2919, %f6915, %f2933;
	fma.rn.ftz.f32 	%f6916, %f2919, %f6916, %f2934;
	fma.rn.ftz.f32 	%f6917, %f2919, %f6917, %f2935;
	add.s64 	%rd341, %rd322, 96;
	// begin inline asm
	cvta.to.global.u64 %rd340, %rd341;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r391,%r392,%r393,%r394}, [%rd340];
	// end inline asm
	mov.b32 	%f2936, %r391;
	mov.b32 	%f2937, %r392;
	mov.b32 	%f2938, %r393;
	mov.b32 	%f2939, %r394;
	mul.ftz.f32 	%f2940, %f202, %f2936;
	mul.ftz.f32 	%f2941, %f202, %f2937;
	mul.ftz.f32 	%f2942, %f202, %f2938;
	mul.ftz.f32 	%f2943, %f202, %f2939;
	fma.rn.ftz.f32 	%f6918, %f2919, %f6918, %f2940;
	fma.rn.ftz.f32 	%f2944, %f2919, %f6919, %f2941;
	fma.rn.ftz.f32 	%f2945, %f2919, %f6920, %f2942;
	fma.rn.ftz.f32 	%f2946, %f2919, %f6921, %f2943;
	add.s64 	%rd344, %rd322, 112;
	// begin inline asm
	cvta.to.global.u64 %rd343, %rd344;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r395,%r396,%r397,%r398}, [%rd343];
	// end inline asm
	mov.b32 	%f2947, %r395;
	mov.b32 	%f2948, %r396;
	mov.b32 	%f2949, %r397;
	mov.b32 	%f2950, %r398;
	mul.ftz.f32 	%f2951, %f202, %f2947;
	mul.ftz.f32 	%f2952, %f202, %f2948;
	mul.ftz.f32 	%f2953, %f202, %f2949;
	mul.ftz.f32 	%f2954, %f202, %f2950;
	fma.rn.ftz.f32 	%f2955, %f2919, %f6922, %f2951;
	fma.rn.ftz.f32 	%f6923, %f2919, %f6923, %f2952;
	fma.rn.ftz.f32 	%f6924, %f2919, %f6924, %f2953;
	fma.rn.ftz.f32 	%f6925, %f2919, %f6925, %f2954;
	mul.ftz.f32 	%f2956, %f2945, %f2945;
	fma.rn.ftz.f32 	%f2957, %f2944, %f2944, %f2956;
	fma.rn.ftz.f32 	%f2958, %f2946, %f2946, %f2957;
	fma.rn.ftz.f32 	%f2959, %f2955, %f2955, %f2958;
	rsqrt.approx.ftz.f32 	%f2960, %f2959;
	mul.ftz.f32 	%f6919, %f2944, %f2960;
	mul.ftz.f32 	%f6920, %f2945, %f2960;
	mul.ftz.f32 	%f6921, %f2946, %f2960;
	mul.ftz.f32 	%f6922, %f2960, %f2955;

$L__BB4_31:
	mul.ftz.f32 	%f2961, %f6920, %f6920;
	mul.ftz.f32 	%f2962, %f6919, %f6919;
	sub.ftz.f32 	%f2963, %f2962, %f2961;
	mul.ftz.f32 	%f2964, %f6921, %f6921;
	sub.ftz.f32 	%f2965, %f2963, %f2964;
	fma.rn.ftz.f32 	%f2966, %f6922, %f6922, %f2965;
	mul.ftz.f32 	%f2967, %f6921, %f6922;
	mul.ftz.f32 	%f2968, %f6919, %f6920;
	sub.ftz.f32 	%f2969, %f2968, %f2967;
	add.ftz.f32 	%f2970, %f2969, %f2969;
	mul.ftz.f32 	%f2971, %f6920, %f6922;
	mul.ftz.f32 	%f2972, %f6919, %f6921;
	add.ftz.f32 	%f2973, %f2972, %f2971;
	add.ftz.f32 	%f2974, %f2973, %f2973;
	add.ftz.f32 	%f2975, %f2968, %f2967;
	add.ftz.f32 	%f2976, %f2975, %f2975;
	sub.ftz.f32 	%f2977, %f2961, %f2962;
	sub.ftz.f32 	%f2978, %f2977, %f2964;
	fma.rn.ftz.f32 	%f2979, %f6922, %f6922, %f2978;
	mul.ftz.f32 	%f2980, %f6919, %f6922;
	mul.ftz.f32 	%f2981, %f6920, %f6921;
	sub.ftz.f32 	%f2982, %f2981, %f2980;
	add.ftz.f32 	%f2983, %f2982, %f2982;
	sub.ftz.f32 	%f2984, %f2972, %f2971;
	add.ftz.f32 	%f2985, %f2984, %f2984;
	add.ftz.f32 	%f2986, %f2981, %f2980;
	add.ftz.f32 	%f2987, %f2986, %f2986;
	neg.ftz.f32 	%f2988, %f2962;
	sub.ftz.f32 	%f2989, %f2988, %f2961;
	add.ftz.f32 	%f2990, %f2989, %f2964;
	fma.rn.ftz.f32 	%f2991, %f6922, %f6922, %f2990;
	mul.ftz.f32 	%f2992, %f6916, %f2970;
	fma.rn.ftz.f32 	%f2993, %f6913, %f2966, %f2992;
	fma.rn.ftz.f32 	%f2994, %f6918, %f2974, %f2993;
	add.ftz.f32 	%f6937, %f6923, %f2994;
	mul.ftz.f32 	%f2995, %f6913, %f2976;
	fma.rn.ftz.f32 	%f2996, %f6916, %f2979, %f2995;
	fma.rn.ftz.f32 	%f2997, %f6918, %f2983, %f2996;
	add.ftz.f32 	%f6933, %f6924, %f2997;
	mul.ftz.f32 	%f2998, %f6916, %f2987;
	fma.rn.ftz.f32 	%f2999, %f6913, %f2985, %f2998;
	fma.rn.ftz.f32 	%f3000, %f6918, %f2991, %f2999;
	add.ftz.f32 	%f6929, %f6925, %f3000;
	mul.ftz.f32 	%f3001, %f6915, %f2970;
	fma.rn.ftz.f32 	%f3002, %f6912, %f2966, %f3001;
	fma.rn.ftz.f32 	%f6936, %f6917, %f2974, %f3002;
	mul.ftz.f32 	%f3003, %f6912, %f2976;
	fma.rn.ftz.f32 	%f3004, %f6915, %f2979, %f3003;
	fma.rn.ftz.f32 	%f6932, %f6917, %f2983, %f3004;
	mul.ftz.f32 	%f3005, %f6915, %f2987;
	fma.rn.ftz.f32 	%f3006, %f6912, %f2985, %f3005;
	fma.rn.ftz.f32 	%f6928, %f6917, %f2991, %f3006;
	mul.ftz.f32 	%f3007, %f6914, %f2970;
	fma.rn.ftz.f32 	%f6935, %f6911, %f2966, %f3007;
	mul.ftz.f32 	%f3008, %f6911, %f2976;
	fma.rn.ftz.f32 	%f6931, %f6914, %f2979, %f3008;
	mul.ftz.f32 	%f3009, %f6914, %f2987;
	fma.rn.ftz.f32 	%f6927, %f6911, %f2985, %f3009;
	mul.ftz.f32 	%f6934, %f6910, %f2966;
	mul.ftz.f32 	%f6930, %f6910, %f2976;
	mul.ftz.f32 	%f6926, %f6910, %f2985;
	bra.uni 	$L__BB4_34;

$L__BB4_26:
	// begin inline asm
	call (%rd1964), _optix_get_instance_transform_from_handle, (%rd274);
	// end inline asm

$L__BB4_27:
	// begin inline asm
	cvta.to.global.u64 %rd280, %rd1964;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r312,%r313,%r314,%r315}, [%rd280];
	// end inline asm
	mov.b32 	%f6934, %r312;
	mov.b32 	%f6935, %r313;
	mov.b32 	%f6936, %r314;
	mov.b32 	%f6937, %r315;
	add.s64 	%rd284, %rd1964, 16;
	// begin inline asm
	cvta.to.global.u64 %rd283, %rd284;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r316,%r317,%r318,%r319}, [%rd283];
	// end inline asm
	mov.b32 	%f6930, %r316;
	mov.b32 	%f6931, %r317;
	mov.b32 	%f6932, %r318;
	mov.b32 	%f6933, %r319;
	add.s64 	%rd287, %rd1964, 32;
	// begin inline asm
	cvta.to.global.u64 %rd286, %rd287;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r320,%r321,%r322,%r323}, [%rd286];
	// end inline asm
	mov.b32 	%f6926, %r320;
	mov.b32 	%f6927, %r321;
	mov.b32 	%f6928, %r322;
	mov.b32 	%f6929, %r323;

$L__BB4_34:
	setp.eq.s32 	%p27, %r2499, %r308;
	@%p27 bra 	$L__BB4_36;

	mul.ftz.f32 	%f3050, %f6905, %f6935;
	fma.rn.ftz.f32 	%f3051, %f6901, %f6934, %f3050;
	fma.rn.ftz.f32 	%f300, %f6909, %f6936, %f3051;
	mul.ftz.f32 	%f3052, %f6904, %f6935;
	fma.rn.ftz.f32 	%f3053, %f6900, %f6934, %f3052;
	fma.rn.ftz.f32 	%f301, %f6908, %f6936, %f3053;
	mul.ftz.f32 	%f3054, %f6903, %f6935;
	fma.rn.ftz.f32 	%f3055, %f6899, %f6934, %f3054;
	fma.rn.ftz.f32 	%f302, %f6907, %f6936, %f3055;
	mul.ftz.f32 	%f3056, %f6902, %f6935;
	fma.rn.ftz.f32 	%f3057, %f6898, %f6934, %f3056;
	fma.rn.ftz.f32 	%f3058, %f6906, %f6936, %f3057;
	add.ftz.f32 	%f6937, %f6937, %f3058;
	mul.ftz.f32 	%f3059, %f6905, %f6931;
	fma.rn.ftz.f32 	%f3060, %f6901, %f6930, %f3059;
	fma.rn.ftz.f32 	%f304, %f6909, %f6932, %f3060;
	mul.ftz.f32 	%f3061, %f6904, %f6931;
	fma.rn.ftz.f32 	%f3062, %f6900, %f6930, %f3061;
	fma.rn.ftz.f32 	%f305, %f6908, %f6932, %f3062;
	mul.ftz.f32 	%f3063, %f6903, %f6931;
	fma.rn.ftz.f32 	%f3064, %f6899, %f6930, %f3063;
	fma.rn.ftz.f32 	%f306, %f6907, %f6932, %f3064;
	mul.ftz.f32 	%f3065, %f6902, %f6931;
	fma.rn.ftz.f32 	%f3066, %f6898, %f6930, %f3065;
	fma.rn.ftz.f32 	%f3067, %f6906, %f6932, %f3066;
	add.ftz.f32 	%f6933, %f6933, %f3067;
	mul.ftz.f32 	%f3068, %f6905, %f6927;
	fma.rn.ftz.f32 	%f3069, %f6901, %f6926, %f3068;
	fma.rn.ftz.f32 	%f308, %f6909, %f6928, %f3069;
	mul.ftz.f32 	%f3070, %f6904, %f6927;
	fma.rn.ftz.f32 	%f3071, %f6900, %f6926, %f3070;
	fma.rn.ftz.f32 	%f309, %f6908, %f6928, %f3071;
	mul.ftz.f32 	%f3072, %f6903, %f6927;
	fma.rn.ftz.f32 	%f3073, %f6899, %f6926, %f3072;
	fma.rn.ftz.f32 	%f310, %f6907, %f6928, %f3073;
	mul.ftz.f32 	%f3074, %f6902, %f6927;
	fma.rn.ftz.f32 	%f3075, %f6898, %f6926, %f3074;
	fma.rn.ftz.f32 	%f3076, %f6906, %f6928, %f3075;
	add.ftz.f32 	%f6929, %f6929, %f3076;
	mov.f32 	%f6926, %f308;
	mov.f32 	%f6927, %f309;
	mov.f32 	%f6928, %f310;
	mov.f32 	%f6930, %f304;
	mov.f32 	%f6931, %f305;
	mov.f32 	%f6932, %f306;
	mov.f32 	%f6934, %f300;
	mov.f32 	%f6935, %f301;
	mov.f32 	%f6936, %f302;

$L__BB4_36:
	setp.gt.s32 	%p28, %r2499, 1;
	mov.u32 	%r2499, %r309;
	mov.f32 	%f6898, %f6937;
	mov.f32 	%f6899, %f6936;
	mov.f32 	%f6900, %f6935;
	mov.f32 	%f6901, %f6934;
	mov.f32 	%f6902, %f6933;
	mov.f32 	%f6903, %f6932;
	mov.f32 	%f6904, %f6931;
	mov.f32 	%f6905, %f6930;
	mov.f32 	%f6906, %f6929;
	mov.f32 	%f6907, %f6928;
	mov.f32 	%f6908, %f6927;
	mov.f32 	%f6909, %f6926;
	@%p28 bra 	$L__BB4_22;

$L__BB4_37:
	mul.ftz.f32 	%f3077, %f6963, %f6935;
	fma.rn.ftz.f32 	%f3078, %f6962, %f6934, %f3077;
	fma.rn.ftz.f32 	%f3079, %f6964, %f6936, %f3078;
	mul.ftz.f32 	%f3080, %f6963, %f6931;
	fma.rn.ftz.f32 	%f3081, %f6962, %f6930, %f3080;
	fma.rn.ftz.f32 	%f3082, %f6964, %f6932, %f3081;
	mul.ftz.f32 	%f3083, %f6963, %f6927;
	fma.rn.ftz.f32 	%f3084, %f6962, %f6926, %f3083;
	fma.rn.ftz.f32 	%f3085, %f6964, %f6928, %f3084;
	add.ftz.f32 	%f6964, %f6929, %f3085;
	add.ftz.f32 	%f6963, %f6933, %f3082;
	add.ftz.f32 	%f6962, %f6937, %f3079;

$L__BB4_38:
	mul.wide.u32 	%rd393, %r6, 44;
	add.s64 	%rd28, %rd11, %rd393;
	ld.f32 	%f7029, [%rd28];
	ld.f32 	%f7030, [%rd28+4];
	ld.f32 	%f7031, [%rd28+8];
	// begin inline asm
	call (%r458), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p29, %r458, 0;
	@%p29 bra 	$L__BB4_57;

	// begin inline asm
	call (%r459), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f3086), _optix_get_ray_time, ();
	// end inline asm
	setp.lt.s32 	%p30, %r459, 1;
	@%p30 bra 	$L__BB4_56;

	mov.u32 	%r2500, %r459;

$L__BB4_41:
	.pragma "nounroll";
	add.s32 	%r460, %r2500, -1;
	// begin inline asm
	call (%rd394), _optix_get_transform_list_handle, (%r460);
	// end inline asm
	// begin inline asm
	call (%r461), _optix_get_transform_type_from_handle, (%rd394);
	// end inline asm
	or.b32  	%r462, %r461, 1;
	setp.eq.s32 	%p31, %r462, 3;
	@%p31 bra 	$L__BB4_47;
	bra.uni 	$L__BB4_42;

$L__BB4_47:
	setp.eq.s32 	%p34, %r461, 2;
	@%p34 bra 	$L__BB4_51;
	bra.uni 	$L__BB4_48;

$L__BB4_51:
	// begin inline asm
	call (%rd466), _optix_get_matrix_motion_transform_from_handle, (%rd394);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd468, %rd466;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r550,%r551,%r552,%r553}, [%rd468];
	// end inline asm
	add.s64 	%rd472, %rd466, 16;
	// begin inline asm
	cvta.to.global.u64 %rd471, %rd472;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r554,%r555,%r556,%r557}, [%rd471];
	// end inline asm
	add.s64 	%rd475, %rd466, 32;
	// begin inline asm
	cvta.to.global.u64 %rd474, %rd475;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r558,%r559,%r560,%r561}, [%rd474];
	// end inline asm
	add.s64 	%rd478, %rd466, 48;
	// begin inline asm
	cvta.to.global.u64 %rd477, %rd478;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r562,%r563,%r564,%r565}, [%rd477];
	// end inline asm
	add.s64 	%rd481, %rd466, 64;
	// begin inline asm
	cvta.to.global.u64 %rd480, %rd481;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r566,%r567,%r568,%r569}, [%rd480];
	// end inline asm
	add.s64 	%rd484, %rd466, 80;
	// begin inline asm
	cvta.to.global.u64 %rd483, %rd484;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r570,%r571,%r572,%r573}, [%rd483];
	// end inline asm
	add.s64 	%rd487, %rd466, 96;
	// begin inline asm
	cvta.to.global.u64 %rd486, %rd487;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r574,%r575,%r576,%r577}, [%rd486];
	// end inline asm
	add.s64 	%rd490, %rd466, 112;
	// begin inline asm
	cvta.to.global.u64 %rd489, %rd490;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r578,%r579,%r580,%r581}, [%rd489];
	// end inline asm
	mov.b32 	%f3207, %r553;
	mov.b32 	%f3208, %r554;
	and.b32  	%r594, %r552, 65535;
	add.s32 	%r595, %r594, -1;
	cvt.rn.f32.s32 	%f3209, %r595;
	sub.ftz.f32 	%f3210, %f3086, %f3207;
	sub.ftz.f32 	%f3211, %f3208, %f3207;
	div.approx.ftz.f32 	%f3212, %f3210, %f3211;
	mul.ftz.f32 	%f3213, %f3212, %f3209;
	min.ftz.f32 	%f3214, %f3209, %f3213;
	mov.f32 	%f3215, 0f00000000;
	max.ftz.f32 	%f3216, %f3215, %f3214;
	setp.num.ftz.f32 	%p37, %f3216, %f3216;
	selp.f32 	%f3217, %f3216, 0f00000000, %p37;
	cvt.rmi.ftz.f32.f32 	%f3218, %f3217;
	add.ftz.f32 	%f3219, %f3209, 0fBF800000;
	min.ftz.f32 	%f3220, %f3218, %f3219;
	sub.ftz.f32 	%f434, %f3217, %f3220;
	cvt.rzi.ftz.s32.f32 	%r596, %f3220;
	cvt.s64.s32 	%rd35, %r596;
	mul.wide.s32 	%rd501, %r596, 48;
	add.s64 	%rd493, %rd475, %rd501;
	// begin inline asm
	cvta.to.global.u64 %rd492, %rd493;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r582,%r583,%r584,%r585}, [%rd492];
	// end inline asm
	mov.b32 	%f7001, %r582;
	mov.b32 	%f7002, %r583;
	mov.b32 	%f7003, %r584;
	mov.b32 	%f7004, %r585;
	add.s64 	%rd496, %rd493, 16;
	// begin inline asm
	cvta.to.global.u64 %rd495, %rd496;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r586,%r587,%r588,%r589}, [%rd495];
	// end inline asm
	mov.b32 	%f6997, %r586;
	mov.b32 	%f6998, %r587;
	mov.b32 	%f6999, %r588;
	mov.b32 	%f7000, %r589;
	add.s64 	%rd499, %rd493, 32;
	// begin inline asm
	cvta.to.global.u64 %rd498, %rd499;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r590,%r591,%r592,%r593}, [%rd498];
	// end inline asm
	mov.b32 	%f6993, %r590;
	mov.b32 	%f6994, %r591;
	mov.b32 	%f6995, %r592;
	mov.b32 	%f6996, %r593;
	setp.leu.ftz.f32 	%p38, %f434, 0f00000000;
	@%p38 bra 	$L__BB4_53;

	mov.f32 	%f3221, 0f3F800000;
	sub.ftz.f32 	%f3222, %f3221, %f434;
	mul.lo.s64 	%rd511, %rd35, 48;
	add.s64 	%rd512, %rd466, %rd511;
	add.s64 	%rd503, %rd512, 80;
	// begin inline asm
	cvta.to.global.u64 %rd502, %rd503;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r597,%r598,%r599,%r600}, [%rd502];
	// end inline asm
	mov.b32 	%f3223, %r597;
	mov.b32 	%f3224, %r598;
	mov.b32 	%f3225, %r599;
	mov.b32 	%f3226, %r600;
	mul.ftz.f32 	%f3227, %f434, %f3223;
	mul.ftz.f32 	%f3228, %f434, %f3224;
	mul.ftz.f32 	%f3229, %f434, %f3225;
	mul.ftz.f32 	%f3230, %f434, %f3226;
	fma.rn.ftz.f32 	%f7001, %f3222, %f7001, %f3227;
	fma.rn.ftz.f32 	%f7002, %f3222, %f7002, %f3228;
	fma.rn.ftz.f32 	%f7003, %f3222, %f7003, %f3229;
	fma.rn.ftz.f32 	%f7004, %f3222, %f7004, %f3230;
	add.s64 	%rd506, %rd512, 96;
	// begin inline asm
	cvta.to.global.u64 %rd505, %rd506;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r601,%r602,%r603,%r604}, [%rd505];
	// end inline asm
	mov.b32 	%f3231, %r601;
	mov.b32 	%f3232, %r602;
	mov.b32 	%f3233, %r603;
	mov.b32 	%f3234, %r604;
	mul.ftz.f32 	%f3235, %f434, %f3231;
	mul.ftz.f32 	%f3236, %f434, %f3232;
	mul.ftz.f32 	%f3237, %f434, %f3233;
	mul.ftz.f32 	%f3238, %f434, %f3234;
	fma.rn.ftz.f32 	%f6997, %f3222, %f6997, %f3235;
	fma.rn.ftz.f32 	%f6998, %f3222, %f6998, %f3236;
	fma.rn.ftz.f32 	%f6999, %f3222, %f6999, %f3237;
	fma.rn.ftz.f32 	%f7000, %f3222, %f7000, %f3238;
	add.s64 	%rd509, %rd512, 112;
	// begin inline asm
	cvta.to.global.u64 %rd508, %rd509;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r605,%r606,%r607,%r608}, [%rd508];
	// end inline asm
	mov.b32 	%f3239, %r605;
	mov.b32 	%f3240, %r606;
	mov.b32 	%f3241, %r607;
	mov.b32 	%f3242, %r608;
	mul.ftz.f32 	%f3243, %f434, %f3239;
	mul.ftz.f32 	%f3244, %f434, %f3240;
	mul.ftz.f32 	%f3245, %f434, %f3241;
	mul.ftz.f32 	%f3246, %f434, %f3242;
	fma.rn.ftz.f32 	%f6993, %f3222, %f6993, %f3243;
	fma.rn.ftz.f32 	%f6994, %f3222, %f6994, %f3244;
	fma.rn.ftz.f32 	%f6995, %f3222, %f6995, %f3245;
	fma.rn.ftz.f32 	%f6996, %f3222, %f6996, %f3246;
	bra.uni 	$L__BB4_53;

$L__BB4_42:
	mov.f32 	%f6993, 0f00000000;
	mov.f32 	%f6995, 0f3F800000;
	setp.eq.s32 	%p32, %r461, 4;
	@%p32 bra 	$L__BB4_45;

	setp.ne.s32 	%p33, %r461, 1;
	mov.f32 	%f6994, %f6993;
	mov.f32 	%f6996, %f6993;
	mov.f32 	%f6997, %f6993;
	mov.f32 	%f6998, %f6995;
	mov.f32 	%f6999, %f6993;
	mov.f32 	%f7000, %f6993;
	mov.f32 	%f7001, %f6995;
	mov.f32 	%f7002, %f6993;
	mov.f32 	%f7003, %f6993;
	mov.f32 	%f7004, %f6993;
	@%p33 bra 	$L__BB4_53;

	// begin inline asm
	call (%rd396), _optix_get_static_transform_from_handle, (%rd394);
	// end inline asm
	add.s64 	%rd1965, %rd396, 16;
	bra.uni 	$L__BB4_46;

$L__BB4_48:
	// begin inline asm
	call (%rd409), _optix_get_srt_motion_transform_from_handle, (%rd394);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd411, %rd409;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r475,%r476,%r477,%r478}, [%rd411];
	// end inline asm
	add.s64 	%rd415, %rd409, 16;
	// begin inline asm
	cvta.to.global.u64 %rd414, %rd415;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r479,%r480,%r481,%r482}, [%rd414];
	// end inline asm
	add.s64 	%rd418, %rd409, 32;
	// begin inline asm
	cvta.to.global.u64 %rd417, %rd418;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r483,%r484,%r485,%r486}, [%rd417];
	// end inline asm
	add.s64 	%rd421, %rd409, 48;
	// begin inline asm
	cvta.to.global.u64 %rd420, %rd421;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r487,%r488,%r489,%r490}, [%rd420];
	// end inline asm
	add.s64 	%rd424, %rd409, 64;
	// begin inline asm
	cvta.to.global.u64 %rd423, %rd424;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r491,%r492,%r493,%r494}, [%rd423];
	// end inline asm
	add.s64 	%rd427, %rd409, 80;
	// begin inline asm
	cvta.to.global.u64 %rd426, %rd427;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r495,%r496,%r497,%r498}, [%rd426];
	// end inline asm
	add.s64 	%rd430, %rd409, 96;
	// begin inline asm
	cvta.to.global.u64 %rd429, %rd430;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r499,%r500,%r501,%r502}, [%rd429];
	// end inline asm
	add.s64 	%rd433, %rd409, 112;
	// begin inline asm
	cvta.to.global.u64 %rd432, %rd433;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r503,%r504,%r505,%r506}, [%rd432];
	// end inline asm
	add.s64 	%rd436, %rd409, 128;
	// begin inline asm
	cvta.to.global.u64 %rd435, %rd436;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r507,%r508,%r509,%r510}, [%rd435];
	// end inline asm
	add.s64 	%rd439, %rd409, 144;
	// begin inline asm
	cvta.to.global.u64 %rd438, %rd439;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r511,%r512,%r513,%r514}, [%rd438];
	// end inline asm
	mov.b32 	%f3101, %r478;
	mov.b32 	%f3102, %r479;
	and.b32  	%r531, %r477, 65535;
	add.s32 	%r532, %r531, -1;
	cvt.rn.f32.s32 	%f3103, %r532;
	sub.ftz.f32 	%f3104, %f3086, %f3101;
	sub.ftz.f32 	%f3105, %f3102, %f3101;
	div.approx.ftz.f32 	%f3106, %f3104, %f3105;
	mul.ftz.f32 	%f3107, %f3106, %f3103;
	min.ftz.f32 	%f3108, %f3103, %f3107;
	mov.f32 	%f3109, 0f00000000;
	max.ftz.f32 	%f3110, %f3109, %f3108;
	setp.num.ftz.f32 	%p35, %f3110, %f3110;
	selp.f32 	%f3111, %f3110, 0f00000000, %p35;
	cvt.rmi.ftz.f32.f32 	%f3112, %f3111;
	add.ftz.f32 	%f3113, %f3103, 0fBF800000;
	min.ftz.f32 	%f3114, %f3112, %f3113;
	sub.ftz.f32 	%f373, %f3111, %f3114;
	cvt.rzi.ftz.s32.f32 	%r533, %f3114;
	mul.wide.s32 	%rd453, %r533, 64;
	add.s64 	%rd442, %rd418, %rd453;
	// begin inline asm
	cvta.to.global.u64 %rd441, %rd442;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r515,%r516,%r517,%r518}, [%rd441];
	// end inline asm
	mov.b32 	%f6977, %r515;
	mov.b32 	%f6978, %r516;
	mov.b32 	%f6979, %r517;
	mov.b32 	%f6980, %r518;
	add.s64 	%rd445, %rd442, 16;
	// begin inline asm
	cvta.to.global.u64 %rd444, %rd445;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r519,%r520,%r521,%r522}, [%rd444];
	// end inline asm
	mov.b32 	%f6981, %r519;
	mov.b32 	%f6982, %r520;
	mov.b32 	%f6983, %r521;
	mov.b32 	%f6984, %r522;
	add.s64 	%rd448, %rd442, 32;
	// begin inline asm
	cvta.to.global.u64 %rd447, %rd448;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r523,%r524,%r525,%r526}, [%rd447];
	// end inline asm
	mov.b32 	%f6985, %r523;
	mov.b32 	%f6986, %r524;
	mov.b32 	%f6987, %r525;
	mov.b32 	%f6988, %r526;
	add.s64 	%rd451, %rd442, 48;
	// begin inline asm
	cvta.to.global.u64 %rd450, %rd451;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r527,%r528,%r529,%r530}, [%rd450];
	// end inline asm
	mov.b32 	%f6989, %r527;
	mov.b32 	%f6990, %r528;
	mov.b32 	%f6991, %r529;
	mov.b32 	%f6992, %r530;
	setp.leu.ftz.f32 	%p36, %f373, 0f00000000;
	@%p36 bra 	$L__BB4_50;

	mov.f32 	%f3115, 0f3F800000;
	sub.ftz.f32 	%f3116, %f3115, %f373;
	add.s64 	%rd455, %rd442, 64;
	// begin inline asm
	cvta.to.global.u64 %rd454, %rd455;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r534,%r535,%r536,%r537}, [%rd454];
	// end inline asm
	mov.b32 	%f3117, %r534;
	mov.b32 	%f3118, %r535;
	mov.b32 	%f3119, %r536;
	mov.b32 	%f3120, %r537;
	mul.ftz.f32 	%f3121, %f373, %f3117;
	mul.ftz.f32 	%f3122, %f373, %f3118;
	mul.ftz.f32 	%f3123, %f373, %f3119;
	mul.ftz.f32 	%f3124, %f373, %f3120;
	fma.rn.ftz.f32 	%f6977, %f3116, %f6977, %f3121;
	fma.rn.ftz.f32 	%f6978, %f3116, %f6978, %f3122;
	fma.rn.ftz.f32 	%f6979, %f3116, %f6979, %f3123;
	fma.rn.ftz.f32 	%f6980, %f3116, %f6980, %f3124;
	add.s64 	%rd458, %rd442, 80;
	// begin inline asm
	cvta.to.global.u64 %rd457, %rd458;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r538,%r539,%r540,%r541}, [%rd457];
	// end inline asm
	mov.b32 	%f3125, %r538;
	mov.b32 	%f3126, %r539;
	mov.b32 	%f3127, %r540;
	mov.b32 	%f3128, %r541;
	mul.ftz.f32 	%f3129, %f373, %f3125;
	mul.ftz.f32 	%f3130, %f373, %f3126;
	mul.ftz.f32 	%f3131, %f373, %f3127;
	mul.ftz.f32 	%f3132, %f373, %f3128;
	fma.rn.ftz.f32 	%f6981, %f3116, %f6981, %f3129;
	fma.rn.ftz.f32 	%f6982, %f3116, %f6982, %f3130;
	fma.rn.ftz.f32 	%f6983, %f3116, %f6983, %f3131;
	fma.rn.ftz.f32 	%f6984, %f3116, %f6984, %f3132;
	add.s64 	%rd461, %rd442, 96;
	// begin inline asm
	cvta.to.global.u64 %rd460, %rd461;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r542,%r543,%r544,%r545}, [%rd460];
	// end inline asm
	mov.b32 	%f3133, %r542;
	mov.b32 	%f3134, %r543;
	mov.b32 	%f3135, %r544;
	mov.b32 	%f3136, %r545;
	mul.ftz.f32 	%f3137, %f373, %f3133;
	mul.ftz.f32 	%f3138, %f373, %f3134;
	mul.ftz.f32 	%f3139, %f373, %f3135;
	mul.ftz.f32 	%f3140, %f373, %f3136;
	fma.rn.ftz.f32 	%f6985, %f3116, %f6985, %f3137;
	fma.rn.ftz.f32 	%f3141, %f3116, %f6986, %f3138;
	fma.rn.ftz.f32 	%f3142, %f3116, %f6987, %f3139;
	fma.rn.ftz.f32 	%f3143, %f3116, %f6988, %f3140;
	add.s64 	%rd464, %rd442, 112;
	// begin inline asm
	cvta.to.global.u64 %rd463, %rd464;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r546,%r547,%r548,%r549}, [%rd463];
	// end inline asm
	mov.b32 	%f3144, %r546;
	mov.b32 	%f3145, %r547;
	mov.b32 	%f3146, %r548;
	mov.b32 	%f3147, %r549;
	mul.ftz.f32 	%f3148, %f373, %f3144;
	mul.ftz.f32 	%f3149, %f373, %f3145;
	mul.ftz.f32 	%f3150, %f373, %f3146;
	mul.ftz.f32 	%f3151, %f373, %f3147;
	fma.rn.ftz.f32 	%f3152, %f3116, %f6989, %f3148;
	fma.rn.ftz.f32 	%f6990, %f3116, %f6990, %f3149;
	fma.rn.ftz.f32 	%f6991, %f3116, %f6991, %f3150;
	fma.rn.ftz.f32 	%f6992, %f3116, %f6992, %f3151;
	mul.ftz.f32 	%f3153, %f3142, %f3142;
	fma.rn.ftz.f32 	%f3154, %f3141, %f3141, %f3153;
	fma.rn.ftz.f32 	%f3155, %f3143, %f3143, %f3154;
	fma.rn.ftz.f32 	%f3156, %f3152, %f3152, %f3155;
	rsqrt.approx.ftz.f32 	%f3157, %f3156;
	mul.ftz.f32 	%f6986, %f3141, %f3157;
	mul.ftz.f32 	%f6987, %f3142, %f3157;
	mul.ftz.f32 	%f6988, %f3143, %f3157;
	mul.ftz.f32 	%f6989, %f3157, %f3152;

$L__BB4_50:
	mul.ftz.f32 	%f3158, %f6987, %f6987;
	mul.ftz.f32 	%f3159, %f6986, %f6986;
	sub.ftz.f32 	%f3160, %f3159, %f3158;
	mul.ftz.f32 	%f3161, %f6988, %f6988;
	sub.ftz.f32 	%f3162, %f3160, %f3161;
	fma.rn.ftz.f32 	%f3163, %f6989, %f6989, %f3162;
	mul.ftz.f32 	%f3164, %f6988, %f6989;
	mul.ftz.f32 	%f3165, %f6986, %f6987;
	sub.ftz.f32 	%f3166, %f3165, %f3164;
	add.ftz.f32 	%f3167, %f3166, %f3166;
	mul.ftz.f32 	%f3168, %f6987, %f6989;
	mul.ftz.f32 	%f3169, %f6986, %f6988;
	add.ftz.f32 	%f3170, %f3169, %f3168;
	add.ftz.f32 	%f3171, %f3170, %f3170;
	add.ftz.f32 	%f3172, %f3165, %f3164;
	add.ftz.f32 	%f3173, %f3172, %f3172;
	sub.ftz.f32 	%f3174, %f3158, %f3159;
	sub.ftz.f32 	%f3175, %f3174, %f3161;
	fma.rn.ftz.f32 	%f3176, %f6989, %f6989, %f3175;
	mul.ftz.f32 	%f3177, %f6986, %f6989;
	mul.ftz.f32 	%f3178, %f6987, %f6988;
	sub.ftz.f32 	%f3179, %f3178, %f3177;
	add.ftz.f32 	%f3180, %f3179, %f3179;
	sub.ftz.f32 	%f3181, %f3169, %f3168;
	add.ftz.f32 	%f3182, %f3181, %f3181;
	add.ftz.f32 	%f3183, %f3178, %f3177;
	add.ftz.f32 	%f3184, %f3183, %f3183;
	neg.ftz.f32 	%f3185, %f3159;
	sub.ftz.f32 	%f3186, %f3185, %f3158;
	add.ftz.f32 	%f3187, %f3186, %f3161;
	fma.rn.ftz.f32 	%f3188, %f6989, %f6989, %f3187;
	mul.ftz.f32 	%f3189, %f6983, %f3167;
	fma.rn.ftz.f32 	%f3190, %f6980, %f3163, %f3189;
	fma.rn.ftz.f32 	%f3191, %f6985, %f3171, %f3190;
	add.ftz.f32 	%f7004, %f6990, %f3191;
	mul.ftz.f32 	%f3192, %f6980, %f3173;
	fma.rn.ftz.f32 	%f3193, %f6983, %f3176, %f3192;
	fma.rn.ftz.f32 	%f3194, %f6985, %f3180, %f3193;
	add.ftz.f32 	%f7000, %f6991, %f3194;
	mul.ftz.f32 	%f3195, %f6983, %f3184;
	fma.rn.ftz.f32 	%f3196, %f6980, %f3182, %f3195;
	fma.rn.ftz.f32 	%f3197, %f6985, %f3188, %f3196;
	add.ftz.f32 	%f6996, %f6992, %f3197;
	mul.ftz.f32 	%f3198, %f6982, %f3167;
	fma.rn.ftz.f32 	%f3199, %f6979, %f3163, %f3198;
	fma.rn.ftz.f32 	%f7003, %f6984, %f3171, %f3199;
	mul.ftz.f32 	%f3200, %f6979, %f3173;
	fma.rn.ftz.f32 	%f3201, %f6982, %f3176, %f3200;
	fma.rn.ftz.f32 	%f6999, %f6984, %f3180, %f3201;
	mul.ftz.f32 	%f3202, %f6982, %f3184;
	fma.rn.ftz.f32 	%f3203, %f6979, %f3182, %f3202;
	fma.rn.ftz.f32 	%f6995, %f6984, %f3188, %f3203;
	mul.ftz.f32 	%f3204, %f6981, %f3167;
	fma.rn.ftz.f32 	%f7002, %f6978, %f3163, %f3204;
	mul.ftz.f32 	%f3205, %f6978, %f3173;
	fma.rn.ftz.f32 	%f6998, %f6981, %f3176, %f3205;
	mul.ftz.f32 	%f3206, %f6981, %f3184;
	fma.rn.ftz.f32 	%f6994, %f6978, %f3182, %f3206;
	mul.ftz.f32 	%f7001, %f6977, %f3163;
	mul.ftz.f32 	%f6997, %f6977, %f3173;
	mul.ftz.f32 	%f6993, %f6977, %f3182;
	bra.uni 	$L__BB4_53;

$L__BB4_45:
	// begin inline asm
	call (%rd1965), _optix_get_instance_transform_from_handle, (%rd394);
	// end inline asm

$L__BB4_46:
	// begin inline asm
	cvta.to.global.u64 %rd400, %rd1965;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r463,%r464,%r465,%r466}, [%rd400];
	// end inline asm
	mov.b32 	%f7001, %r463;
	mov.b32 	%f7002, %r464;
	mov.b32 	%f7003, %r465;
	mov.b32 	%f7004, %r466;
	add.s64 	%rd404, %rd1965, 16;
	// begin inline asm
	cvta.to.global.u64 %rd403, %rd404;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r467,%r468,%r469,%r470}, [%rd403];
	// end inline asm
	mov.b32 	%f6997, %r467;
	mov.b32 	%f6998, %r468;
	mov.b32 	%f6999, %r469;
	mov.b32 	%f7000, %r470;
	add.s64 	%rd407, %rd1965, 32;
	// begin inline asm
	cvta.to.global.u64 %rd406, %rd407;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r471,%r472,%r473,%r474}, [%rd406];
	// end inline asm
	mov.b32 	%f6993, %r471;
	mov.b32 	%f6994, %r472;
	mov.b32 	%f6995, %r473;
	mov.b32 	%f6996, %r474;

$L__BB4_53:
	setp.eq.s32 	%p39, %r2500, %r459;
	@%p39 bra 	$L__BB4_55;

	mul.ftz.f32 	%f3247, %f6972, %f7002;
	fma.rn.ftz.f32 	%f3248, %f6968, %f7001, %f3247;
	fma.rn.ftz.f32 	%f471, %f6976, %f7003, %f3248;
	mul.ftz.f32 	%f3249, %f6971, %f7002;
	fma.rn.ftz.f32 	%f3250, %f6967, %f7001, %f3249;
	fma.rn.ftz.f32 	%f472, %f6975, %f7003, %f3250;
	mul.ftz.f32 	%f3251, %f6970, %f7002;
	fma.rn.ftz.f32 	%f3252, %f6966, %f7001, %f3251;
	fma.rn.ftz.f32 	%f473, %f6974, %f7003, %f3252;
	mul.ftz.f32 	%f3253, %f6969, %f7002;
	fma.rn.ftz.f32 	%f3254, %f6965, %f7001, %f3253;
	fma.rn.ftz.f32 	%f3255, %f6973, %f7003, %f3254;
	add.ftz.f32 	%f7004, %f7004, %f3255;
	mul.ftz.f32 	%f3256, %f6972, %f6998;
	fma.rn.ftz.f32 	%f3257, %f6968, %f6997, %f3256;
	fma.rn.ftz.f32 	%f475, %f6976, %f6999, %f3257;
	mul.ftz.f32 	%f3258, %f6971, %f6998;
	fma.rn.ftz.f32 	%f3259, %f6967, %f6997, %f3258;
	fma.rn.ftz.f32 	%f476, %f6975, %f6999, %f3259;
	mul.ftz.f32 	%f3260, %f6970, %f6998;
	fma.rn.ftz.f32 	%f3261, %f6966, %f6997, %f3260;
	fma.rn.ftz.f32 	%f477, %f6974, %f6999, %f3261;
	mul.ftz.f32 	%f3262, %f6969, %f6998;
	fma.rn.ftz.f32 	%f3263, %f6965, %f6997, %f3262;
	fma.rn.ftz.f32 	%f3264, %f6973, %f6999, %f3263;
	add.ftz.f32 	%f7000, %f7000, %f3264;
	mul.ftz.f32 	%f3265, %f6972, %f6994;
	fma.rn.ftz.f32 	%f3266, %f6968, %f6993, %f3265;
	fma.rn.ftz.f32 	%f479, %f6976, %f6995, %f3266;
	mul.ftz.f32 	%f3267, %f6971, %f6994;
	fma.rn.ftz.f32 	%f3268, %f6967, %f6993, %f3267;
	fma.rn.ftz.f32 	%f480, %f6975, %f6995, %f3268;
	mul.ftz.f32 	%f3269, %f6970, %f6994;
	fma.rn.ftz.f32 	%f3270, %f6966, %f6993, %f3269;
	fma.rn.ftz.f32 	%f481, %f6974, %f6995, %f3270;
	mul.ftz.f32 	%f3271, %f6969, %f6994;
	fma.rn.ftz.f32 	%f3272, %f6965, %f6993, %f3271;
	fma.rn.ftz.f32 	%f3273, %f6973, %f6995, %f3272;
	add.ftz.f32 	%f6996, %f6996, %f3273;
	mov.f32 	%f6993, %f479;
	mov.f32 	%f6994, %f480;
	mov.f32 	%f6995, %f481;
	mov.f32 	%f6997, %f475;
	mov.f32 	%f6998, %f476;
	mov.f32 	%f6999, %f477;
	mov.f32 	%f7001, %f471;
	mov.f32 	%f7002, %f472;
	mov.f32 	%f7003, %f473;

$L__BB4_55:
	setp.gt.s32 	%p40, %r2500, 1;
	mov.u32 	%r2500, %r460;
	mov.f32 	%f6965, %f7004;
	mov.f32 	%f6966, %f7003;
	mov.f32 	%f6967, %f7002;
	mov.f32 	%f6968, %f7001;
	mov.f32 	%f6969, %f7000;
	mov.f32 	%f6970, %f6999;
	mov.f32 	%f6971, %f6998;
	mov.f32 	%f6972, %f6997;
	mov.f32 	%f6973, %f6996;
	mov.f32 	%f6974, %f6995;
	mov.f32 	%f6975, %f6994;
	mov.f32 	%f6976, %f6993;
	@%p40 bra 	$L__BB4_41;

$L__BB4_56:
	mul.ftz.f32 	%f3274, %f7030, %f7002;
	fma.rn.ftz.f32 	%f3275, %f7029, %f7001, %f3274;
	fma.rn.ftz.f32 	%f3276, %f7031, %f7003, %f3275;
	mul.ftz.f32 	%f3277, %f7030, %f6998;
	fma.rn.ftz.f32 	%f3278, %f7029, %f6997, %f3277;
	fma.rn.ftz.f32 	%f3279, %f7031, %f6999, %f3278;
	mul.ftz.f32 	%f3280, %f7030, %f6994;
	fma.rn.ftz.f32 	%f3281, %f7029, %f6993, %f3280;
	fma.rn.ftz.f32 	%f3282, %f7031, %f6995, %f3281;
	add.ftz.f32 	%f7031, %f6996, %f3282;
	add.ftz.f32 	%f7030, %f7000, %f3279;
	add.ftz.f32 	%f7029, %f7004, %f3276;

$L__BB4_57:
	add.ftz.f32 	%f3283, %f2690, %f2691;
	mov.f32 	%f3284, 0f3F800000;
	sub.ftz.f32 	%f3285, %f3284, %f3283;
	mul.ftz.f32 	%f3286, %f2690, %f6962;
	fma.rn.ftz.f32 	%f3287, %f3285, %f6895, %f3286;
	mul.ftz.f32 	%f3288, %f2690, %f6963;
	fma.rn.ftz.f32 	%f3289, %f3285, %f6896, %f3288;
	mul.ftz.f32 	%f3290, %f2690, %f6964;
	fma.rn.ftz.f32 	%f3291, %f3285, %f6897, %f3290;
	fma.rn.ftz.f32 	%f516, %f2691, %f7029, %f3287;
	fma.rn.ftz.f32 	%f517, %f2691, %f7030, %f3289;
	fma.rn.ftz.f32 	%f518, %f2691, %f7031, %f3291;
	ld.f32 	%f3292, [%rd12+12];
	ld.f32 	%f3293, [%rd12+16];
	ld.f32 	%f3294, [%rd12+20];
	ld.f32 	%f3295, [%rd20+12];
	mul.ftz.f32 	%f3296, %f2690, %f3295;
	ld.f32 	%f3297, [%rd20+16];
	mul.ftz.f32 	%f3298, %f2690, %f3297;
	ld.f32 	%f3299, [%rd20+20];
	mul.ftz.f32 	%f3300, %f2690, %f3299;
	fma.rn.ftz.f32 	%f3301, %f3285, %f3292, %f3296;
	fma.rn.ftz.f32 	%f3302, %f3285, %f3293, %f3298;
	fma.rn.ftz.f32 	%f3303, %f3285, %f3294, %f3300;
	ld.f32 	%f3304, [%rd28+12];
	ld.f32 	%f3305, [%rd28+16];
	ld.f32 	%f3306, [%rd28+20];
	fma.rn.ftz.f32 	%f7087, %f2691, %f3304, %f3301;
	fma.rn.ftz.f32 	%f7088, %f2691, %f3305, %f3302;
	fma.rn.ftz.f32 	%f521, %f2691, %f3306, %f3303;
	ld.f32 	%f3307, [%rd12+24];
	ld.f32 	%f3308, [%rd12+28];
	ld.f32 	%f3309, [%rd12+32];
	ld.f32 	%f3310, [%rd20+24];
	mul.ftz.f32 	%f3311, %f2690, %f3310;
	ld.f32 	%f3312, [%rd20+28];
	mul.ftz.f32 	%f3313, %f2690, %f3312;
	ld.f32 	%f3314, [%rd20+32];
	mul.ftz.f32 	%f3315, %f2690, %f3314;
	fma.rn.ftz.f32 	%f3316, %f3285, %f3307, %f3311;
	fma.rn.ftz.f32 	%f3317, %f3285, %f3308, %f3313;
	fma.rn.ftz.f32 	%f3318, %f3285, %f3309, %f3315;
	ld.f32 	%f3319, [%rd28+24];
	ld.f32 	%f3320, [%rd28+28];
	ld.f32 	%f3321, [%rd28+32];
	fma.rn.ftz.f32 	%f7136, %f2691, %f3319, %f3316;
	fma.rn.ftz.f32 	%f7137, %f2691, %f3320, %f3317;
	fma.rn.ftz.f32 	%f524, %f2691, %f3321, %f3318;
	sub.ftz.f32 	%f3322, %f7029, %f6895;
	sub.ftz.f32 	%f3323, %f7030, %f6896;
	sub.ftz.f32 	%f3324, %f7031, %f6897;
	sub.ftz.f32 	%f3325, %f6963, %f6896;
	mul.ftz.f32 	%f3326, %f3325, %f3324;
	sub.ftz.f32 	%f3327, %f6964, %f6897;
	mul.ftz.f32 	%f3328, %f3327, %f3323;
	sub.ftz.f32 	%f525, %f3326, %f3328;
	mul.ftz.f32 	%f3329, %f3327, %f3322;
	sub.ftz.f32 	%f3330, %f6962, %f6895;
	mul.ftz.f32 	%f3331, %f3330, %f3324;
	sub.ftz.f32 	%f526, %f3329, %f3331;
	mul.ftz.f32 	%f3332, %f3330, %f3323;
	mul.ftz.f32 	%f3333, %f3325, %f3322;
	sub.ftz.f32 	%f527, %f3332, %f3333;
	ld.f32 	%f3334, [%rd12+36];
	ld.f32 	%f3335, [%rd12+40];
	ld.f32 	%f3336, [%rd20+36];
	mul.ftz.f32 	%f3337, %f2690, %f3336;
	ld.f32 	%f3338, [%rd20+40];
	mul.ftz.f32 	%f3339, %f2690, %f3338;
	fma.rn.ftz.f32 	%f3340, %f3285, %f3334, %f3337;
	fma.rn.ftz.f32 	%f3341, %f3285, %f3335, %f3339;
	ld.f32 	%f3342, [%rd28+36];
	ld.f32 	%f3343, [%rd28+40];
	fma.rn.ftz.f32 	%f528, %f2691, %f3342, %f3340;
	fma.rn.ftz.f32 	%f529, %f2691, %f3343, %f3341;
	// begin inline asm
	call (%r609), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p41, %r609, 0;
	@%p41 bra 	$L__BB4_77;

	// begin inline asm
	call (%r610), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f3344), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p42, %r610, 0;
	@%p42 bra 	$L__BB4_76;

	mov.u32 	%r2501, 0;

$L__BB4_60:
	.pragma "nounroll";
	// begin inline asm
	call (%rd513), _optix_get_transform_list_handle, (%r2501);
	// end inline asm
	// begin inline asm
	call (%r613), _optix_get_transform_type_from_handle, (%rd513);
	// end inline asm
	or.b32  	%r614, %r613, 1;
	setp.eq.s32 	%p43, %r614, 3;
	@%p43 bra 	$L__BB4_66;
	bra.uni 	$L__BB4_61;

$L__BB4_66:
	setp.eq.s32 	%p46, %r613, 2;
	@%p46 bra 	$L__BB4_70;
	bra.uni 	$L__BB4_67;

$L__BB4_70:
	// begin inline asm
	call (%rd585), _optix_get_matrix_motion_transform_from_handle, (%rd513);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd587, %rd585;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r702,%r703,%r704,%r705}, [%rd587];
	// end inline asm
	add.s64 	%rd591, %rd585, 16;
	// begin inline asm
	cvta.to.global.u64 %rd590, %rd591;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r706,%r707,%r708,%r709}, [%rd590];
	// end inline asm
	add.s64 	%rd594, %rd585, 32;
	// begin inline asm
	cvta.to.global.u64 %rd593, %rd594;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r710,%r711,%r712,%r713}, [%rd593];
	// end inline asm
	add.s64 	%rd597, %rd585, 48;
	// begin inline asm
	cvta.to.global.u64 %rd596, %rd597;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r714,%r715,%r716,%r717}, [%rd596];
	// end inline asm
	add.s64 	%rd600, %rd585, 64;
	// begin inline asm
	cvta.to.global.u64 %rd599, %rd600;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r718,%r719,%r720,%r721}, [%rd599];
	// end inline asm
	add.s64 	%rd603, %rd585, 80;
	// begin inline asm
	cvta.to.global.u64 %rd602, %rd603;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r722,%r723,%r724,%r725}, [%rd602];
	// end inline asm
	add.s64 	%rd606, %rd585, 96;
	// begin inline asm
	cvta.to.global.u64 %rd605, %rd606;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r726,%r727,%r728,%r729}, [%rd605];
	// end inline asm
	add.s64 	%rd609, %rd585, 112;
	// begin inline asm
	cvta.to.global.u64 %rd608, %rd609;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r730,%r731,%r732,%r733}, [%rd608];
	// end inline asm
	mov.b32 	%f3441, %r705;
	mov.b32 	%f3442, %r706;
	and.b32  	%r746, %r704, 65535;
	add.s32 	%r747, %r746, -1;
	cvt.rn.f32.s32 	%f3443, %r747;
	sub.ftz.f32 	%f3444, %f3344, %f3441;
	sub.ftz.f32 	%f3445, %f3442, %f3441;
	div.approx.ftz.f32 	%f3446, %f3444, %f3445;
	mul.ftz.f32 	%f3447, %f3446, %f3443;
	min.ftz.f32 	%f3448, %f3443, %f3447;
	mov.f32 	%f3449, 0f00000000;
	max.ftz.f32 	%f3450, %f3449, %f3448;
	setp.num.ftz.f32 	%p49, %f3450, %f3450;
	selp.f32 	%f3451, %f3450, 0f00000000, %p49;
	cvt.rmi.ftz.f32.f32 	%f3452, %f3451;
	add.ftz.f32 	%f3453, %f3443, 0fBF800000;
	min.ftz.f32 	%f3454, %f3452, %f3453;
	sub.ftz.f32 	%f589, %f3451, %f3454;
	cvt.rzi.ftz.s32.f32 	%r748, %f3454;
	cvt.s64.s32 	%rd42, %r748;
	mul.wide.s32 	%rd620, %r748, 48;
	add.s64 	%rd612, %rd594, %rd620;
	// begin inline asm
	cvta.to.global.u64 %rd611, %rd612;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r734,%r735,%r736,%r737}, [%rd611];
	// end inline asm
	mov.b32 	%f7057, %r734;
	mov.b32 	%f7058, %r735;
	mov.b32 	%f7059, %r736;
	add.s64 	%rd615, %rd612, 16;
	// begin inline asm
	cvta.to.global.u64 %rd614, %rd615;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r738,%r739,%r740,%r741}, [%rd614];
	// end inline asm
	mov.b32 	%f7054, %r738;
	mov.b32 	%f7055, %r739;
	mov.b32 	%f7056, %r740;
	add.s64 	%rd618, %rd612, 32;
	// begin inline asm
	cvta.to.global.u64 %rd617, %rd618;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r742,%r743,%r744,%r745}, [%rd617];
	// end inline asm
	mov.b32 	%f7051, %r742;
	mov.b32 	%f7052, %r743;
	mov.b32 	%f7053, %r744;
	setp.leu.ftz.f32 	%p50, %f589, 0f00000000;
	@%p50 bra 	$L__BB4_72;

	mov.f32 	%f3455, 0f3F800000;
	sub.ftz.f32 	%f3456, %f3455, %f589;
	mul.lo.s64 	%rd630, %rd42, 48;
	add.s64 	%rd631, %rd585, %rd630;
	add.s64 	%rd622, %rd631, 80;
	// begin inline asm
	cvta.to.global.u64 %rd621, %rd622;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r749,%r750,%r751,%r752}, [%rd621];
	// end inline asm
	mov.b32 	%f3457, %r749;
	mov.b32 	%f3458, %r750;
	mov.b32 	%f3459, %r751;
	mul.ftz.f32 	%f3460, %f589, %f3457;
	mul.ftz.f32 	%f3461, %f589, %f3458;
	mul.ftz.f32 	%f3462, %f589, %f3459;
	fma.rn.ftz.f32 	%f7057, %f3456, %f7057, %f3460;
	fma.rn.ftz.f32 	%f7058, %f3456, %f7058, %f3461;
	fma.rn.ftz.f32 	%f7059, %f3456, %f7059, %f3462;
	add.s64 	%rd625, %rd631, 96;
	// begin inline asm
	cvta.to.global.u64 %rd624, %rd625;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r753,%r754,%r755,%r756}, [%rd624];
	// end inline asm
	mov.b32 	%f3463, %r753;
	mov.b32 	%f3464, %r754;
	mov.b32 	%f3465, %r755;
	mul.ftz.f32 	%f3466, %f589, %f3463;
	mul.ftz.f32 	%f3467, %f589, %f3464;
	mul.ftz.f32 	%f3468, %f589, %f3465;
	fma.rn.ftz.f32 	%f7054, %f3456, %f7054, %f3466;
	fma.rn.ftz.f32 	%f7055, %f3456, %f7055, %f3467;
	fma.rn.ftz.f32 	%f7056, %f3456, %f7056, %f3468;
	add.s64 	%rd628, %rd631, 112;
	// begin inline asm
	cvta.to.global.u64 %rd627, %rd628;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r757,%r758,%r759,%r760}, [%rd627];
	// end inline asm
	mov.b32 	%f3469, %r757;
	mov.b32 	%f3470, %r758;
	mov.b32 	%f3471, %r759;
	mul.ftz.f32 	%f3472, %f589, %f3469;
	mul.ftz.f32 	%f3473, %f589, %f3470;
	mul.ftz.f32 	%f3474, %f589, %f3471;
	fma.rn.ftz.f32 	%f7051, %f3456, %f7051, %f3472;
	fma.rn.ftz.f32 	%f7052, %f3456, %f7052, %f3473;
	fma.rn.ftz.f32 	%f7053, %f3456, %f7053, %f3474;
	bra.uni 	$L__BB4_72;

$L__BB4_61:
	mov.f32 	%f7060, 0f00000000;
	mov.f32 	%f7062, 0f3F800000;
	setp.eq.s32 	%p44, %r613, 4;
	@%p44 bra 	$L__BB4_64;

	setp.ne.s32 	%p45, %r613, 1;
	mov.f32 	%f7061, %f7060;
	mov.f32 	%f7063, %f7060;
	mov.f32 	%f7064, %f7062;
	mov.f32 	%f7065, %f7060;
	mov.f32 	%f7066, %f7062;
	mov.f32 	%f7067, %f7060;
	mov.f32 	%f7068, %f7060;
	@%p45 bra 	$L__BB4_73;

	// begin inline asm
	call (%rd515), _optix_get_static_transform_from_handle, (%rd513);
	// end inline asm
	add.s64 	%rd1966, %rd515, 64;
	bra.uni 	$L__BB4_65;

$L__BB4_67:
	// begin inline asm
	call (%rd528), _optix_get_srt_motion_transform_from_handle, (%rd513);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd530, %rd528;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r627,%r628,%r629,%r630}, [%rd530];
	// end inline asm
	add.s64 	%rd534, %rd528, 16;
	// begin inline asm
	cvta.to.global.u64 %rd533, %rd534;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r631,%r632,%r633,%r634}, [%rd533];
	// end inline asm
	add.s64 	%rd537, %rd528, 32;
	// begin inline asm
	cvta.to.global.u64 %rd536, %rd537;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r635,%r636,%r637,%r638}, [%rd536];
	// end inline asm
	add.s64 	%rd540, %rd528, 48;
	// begin inline asm
	cvta.to.global.u64 %rd539, %rd540;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r639,%r640,%r641,%r642}, [%rd539];
	// end inline asm
	add.s64 	%rd543, %rd528, 64;
	// begin inline asm
	cvta.to.global.u64 %rd542, %rd543;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r643,%r644,%r645,%r646}, [%rd542];
	// end inline asm
	add.s64 	%rd546, %rd528, 80;
	// begin inline asm
	cvta.to.global.u64 %rd545, %rd546;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r647,%r648,%r649,%r650}, [%rd545];
	// end inline asm
	add.s64 	%rd549, %rd528, 96;
	// begin inline asm
	cvta.to.global.u64 %rd548, %rd549;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r651,%r652,%r653,%r654}, [%rd548];
	// end inline asm
	add.s64 	%rd552, %rd528, 112;
	// begin inline asm
	cvta.to.global.u64 %rd551, %rd552;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r655,%r656,%r657,%r658}, [%rd551];
	// end inline asm
	add.s64 	%rd555, %rd528, 128;
	// begin inline asm
	cvta.to.global.u64 %rd554, %rd555;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r659,%r660,%r661,%r662}, [%rd554];
	// end inline asm
	add.s64 	%rd558, %rd528, 144;
	// begin inline asm
	cvta.to.global.u64 %rd557, %rd558;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r663,%r664,%r665,%r666}, [%rd557];
	// end inline asm
	mov.b32 	%f3356, %r630;
	mov.b32 	%f3357, %r631;
	and.b32  	%r683, %r629, 65535;
	add.s32 	%r684, %r683, -1;
	cvt.rn.f32.s32 	%f3358, %r684;
	sub.ftz.f32 	%f3359, %f3344, %f3356;
	sub.ftz.f32 	%f3360, %f3357, %f3356;
	div.approx.ftz.f32 	%f3361, %f3359, %f3360;
	mul.ftz.f32 	%f3362, %f3361, %f3358;
	min.ftz.f32 	%f3363, %f3358, %f3362;
	mov.f32 	%f3364, 0f00000000;
	max.ftz.f32 	%f3365, %f3364, %f3363;
	setp.num.ftz.f32 	%p47, %f3365, %f3365;
	selp.f32 	%f3366, %f3365, 0f00000000, %p47;
	cvt.rmi.ftz.f32.f32 	%f3367, %f3366;
	add.ftz.f32 	%f3368, %f3358, 0fBF800000;
	min.ftz.f32 	%f3369, %f3367, %f3368;
	sub.ftz.f32 	%f549, %f3366, %f3369;
	cvt.rzi.ftz.s32.f32 	%r685, %f3369;
	mul.wide.s32 	%rd572, %r685, 64;
	add.s64 	%rd561, %rd537, %rd572;
	// begin inline asm
	cvta.to.global.u64 %rd560, %rd561;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r667,%r668,%r669,%r670}, [%rd560];
	// end inline asm
	mov.b32 	%f7041, %r667;
	mov.b32 	%f7042, %r668;
	mov.b32 	%f7043, %r669;
	add.s64 	%rd564, %rd561, 16;
	// begin inline asm
	cvta.to.global.u64 %rd563, %rd564;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r671,%r672,%r673,%r674}, [%rd563];
	// end inline asm
	mov.b32 	%f7044, %r671;
	mov.b32 	%f7045, %r672;
	mov.b32 	%f7046, %r674;
	add.s64 	%rd567, %rd561, 32;
	// begin inline asm
	cvta.to.global.u64 %rd566, %rd567;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r675,%r676,%r677,%r678}, [%rd566];
	// end inline asm
	mov.b32 	%f7047, %r676;
	mov.b32 	%f7048, %r677;
	mov.b32 	%f7049, %r678;
	add.s64 	%rd570, %rd561, 48;
	// begin inline asm
	cvta.to.global.u64 %rd569, %rd570;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r679,%r680,%r681,%r682}, [%rd569];
	// end inline asm
	mov.b32 	%f7050, %r679;
	setp.leu.ftz.f32 	%p48, %f549, 0f00000000;
	@%p48 bra 	$L__BB4_69;

	mov.f32 	%f3370, 0f3F800000;
	sub.ftz.f32 	%f3371, %f3370, %f549;
	add.s64 	%rd574, %rd561, 64;
	// begin inline asm
	cvta.to.global.u64 %rd573, %rd574;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r686,%r687,%r688,%r689}, [%rd573];
	// end inline asm
	mov.b32 	%f3372, %r686;
	mov.b32 	%f3373, %r687;
	mov.b32 	%f3374, %r688;
	mul.ftz.f32 	%f3375, %f549, %f3372;
	mul.ftz.f32 	%f3376, %f549, %f3373;
	mul.ftz.f32 	%f3377, %f549, %f3374;
	fma.rn.ftz.f32 	%f7041, %f3371, %f7041, %f3375;
	fma.rn.ftz.f32 	%f7042, %f3371, %f7042, %f3376;
	fma.rn.ftz.f32 	%f7043, %f3371, %f7043, %f3377;
	add.s64 	%rd577, %rd561, 80;
	// begin inline asm
	cvta.to.global.u64 %rd576, %rd577;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r690,%r691,%r692,%r693}, [%rd576];
	// end inline asm
	mov.b32 	%f3378, %r690;
	mov.b32 	%f3379, %r691;
	mov.b32 	%f3380, %r693;
	mul.ftz.f32 	%f3381, %f549, %f3378;
	mul.ftz.f32 	%f3382, %f549, %f3379;
	mul.ftz.f32 	%f3383, %f549, %f3380;
	fma.rn.ftz.f32 	%f7044, %f3371, %f7044, %f3381;
	fma.rn.ftz.f32 	%f7045, %f3371, %f7045, %f3382;
	fma.rn.ftz.f32 	%f7046, %f3371, %f7046, %f3383;
	add.s64 	%rd580, %rd561, 96;
	// begin inline asm
	cvta.to.global.u64 %rd579, %rd580;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r694,%r695,%r696,%r697}, [%rd579];
	// end inline asm
	mov.b32 	%f3384, %r695;
	mov.b32 	%f3385, %r696;
	mov.b32 	%f3386, %r697;
	mul.ftz.f32 	%f3387, %f549, %f3384;
	mul.ftz.f32 	%f3388, %f549, %f3385;
	mul.ftz.f32 	%f3389, %f549, %f3386;
	fma.rn.ftz.f32 	%f3390, %f3371, %f7047, %f3387;
	fma.rn.ftz.f32 	%f3391, %f3371, %f7048, %f3388;
	fma.rn.ftz.f32 	%f3392, %f3371, %f7049, %f3389;
	add.s64 	%rd583, %rd561, 112;
	// begin inline asm
	cvta.to.global.u64 %rd582, %rd583;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r698,%r699,%r700,%r701}, [%rd582];
	// end inline asm
	mov.b32 	%f3393, %r698;
	mul.ftz.f32 	%f3394, %f549, %f3393;
	fma.rn.ftz.f32 	%f3395, %f3371, %f7050, %f3394;
	mul.ftz.f32 	%f3396, %f3391, %f3391;
	fma.rn.ftz.f32 	%f3397, %f3390, %f3390, %f3396;
	fma.rn.ftz.f32 	%f3398, %f3392, %f3392, %f3397;
	fma.rn.ftz.f32 	%f3399, %f3395, %f3395, %f3398;
	rsqrt.approx.ftz.f32 	%f3400, %f3399;
	mul.ftz.f32 	%f7047, %f3390, %f3400;
	mul.ftz.f32 	%f7048, %f3391, %f3400;
	mul.ftz.f32 	%f7049, %f3392, %f3400;
	mul.ftz.f32 	%f7050, %f3400, %f3395;

$L__BB4_69:
	mul.ftz.f32 	%f3401, %f7048, %f7048;
	mul.ftz.f32 	%f3402, %f7047, %f7047;
	sub.ftz.f32 	%f3403, %f3402, %f3401;
	mul.ftz.f32 	%f3404, %f7049, %f7049;
	sub.ftz.f32 	%f3405, %f3403, %f3404;
	fma.rn.ftz.f32 	%f3406, %f7050, %f7050, %f3405;
	mul.ftz.f32 	%f3407, %f7049, %f7050;
	mul.ftz.f32 	%f3408, %f7047, %f7048;
	sub.ftz.f32 	%f3409, %f3408, %f3407;
	add.ftz.f32 	%f3410, %f3409, %f3409;
	mul.ftz.f32 	%f3411, %f7048, %f7050;
	mul.ftz.f32 	%f3412, %f7047, %f7049;
	add.ftz.f32 	%f3413, %f3412, %f3411;
	add.ftz.f32 	%f3414, %f3413, %f3413;
	add.ftz.f32 	%f3415, %f3408, %f3407;
	add.ftz.f32 	%f3416, %f3415, %f3415;
	sub.ftz.f32 	%f3417, %f3401, %f3402;
	sub.ftz.f32 	%f3418, %f3417, %f3404;
	fma.rn.ftz.f32 	%f3419, %f7050, %f7050, %f3418;
	mul.ftz.f32 	%f3420, %f7047, %f7050;
	mul.ftz.f32 	%f3421, %f7048, %f7049;
	sub.ftz.f32 	%f3422, %f3421, %f3420;
	add.ftz.f32 	%f3423, %f3422, %f3422;
	sub.ftz.f32 	%f3424, %f3412, %f3411;
	add.ftz.f32 	%f3425, %f3424, %f3424;
	add.ftz.f32 	%f3426, %f3421, %f3420;
	add.ftz.f32 	%f3427, %f3426, %f3426;
	neg.ftz.f32 	%f3428, %f3402;
	sub.ftz.f32 	%f3429, %f3428, %f3401;
	add.ftz.f32 	%f3430, %f3429, %f3404;
	fma.rn.ftz.f32 	%f3431, %f7050, %f7050, %f3430;
	mul.ftz.f32 	%f3432, %f7045, %f3410;
	fma.rn.ftz.f32 	%f3433, %f7043, %f3406, %f3432;
	fma.rn.ftz.f32 	%f7059, %f7046, %f3414, %f3433;
	mul.ftz.f32 	%f3434, %f7043, %f3416;
	fma.rn.ftz.f32 	%f3435, %f7045, %f3419, %f3434;
	fma.rn.ftz.f32 	%f7056, %f7046, %f3423, %f3435;
	mul.ftz.f32 	%f3436, %f7045, %f3427;
	fma.rn.ftz.f32 	%f3437, %f7043, %f3425, %f3436;
	fma.rn.ftz.f32 	%f7053, %f7046, %f3431, %f3437;
	mul.ftz.f32 	%f3438, %f7044, %f3410;
	fma.rn.ftz.f32 	%f7058, %f7042, %f3406, %f3438;
	mul.ftz.f32 	%f3439, %f7042, %f3416;
	fma.rn.ftz.f32 	%f7055, %f7044, %f3419, %f3439;
	mul.ftz.f32 	%f3440, %f7044, %f3427;
	fma.rn.ftz.f32 	%f7052, %f7042, %f3425, %f3440;
	mul.ftz.f32 	%f7057, %f7041, %f3406;
	mul.ftz.f32 	%f7054, %f7041, %f3416;
	mul.ftz.f32 	%f7051, %f7041, %f3425;

$L__BB4_72:
	mul.ftz.f32 	%f3475, %f7052, %f7056;
	mul.ftz.f32 	%f3476, %f7053, %f7055;
	sub.ftz.f32 	%f3477, %f3476, %f3475;
	mul.ftz.f32 	%f3478, %f7057, %f3477;
	mul.ftz.f32 	%f3479, %f7051, %f7056;
	mul.ftz.f32 	%f3480, %f7053, %f7054;
	sub.ftz.f32 	%f3481, %f3480, %f3479;
	mul.ftz.f32 	%f3482, %f3481, %f7058;
	sub.ftz.f32 	%f3483, %f3478, %f3482;
	mul.ftz.f32 	%f3484, %f7051, %f7055;
	mul.ftz.f32 	%f3485, %f7052, %f7054;
	sub.ftz.f32 	%f3486, %f3485, %f3484;
	fma.rn.ftz.f32 	%f3487, %f3486, %f7059, %f3483;
	rcp.approx.ftz.f32 	%f3488, %f3487;
	mul.ftz.f32 	%f7066, %f3477, %f3488;
	mul.ftz.f32 	%f3489, %f7053, %f7058;
	mul.ftz.f32 	%f3490, %f7052, %f7059;
	sub.ftz.f32 	%f3491, %f3490, %f3489;
	mul.ftz.f32 	%f7067, %f3491, %f3488;
	mul.ftz.f32 	%f3492, %f7055, %f7059;
	mul.ftz.f32 	%f3493, %f7056, %f7058;
	sub.ftz.f32 	%f3494, %f3493, %f3492;
	mul.ftz.f32 	%f7068, %f3494, %f3488;
	sub.ftz.f32 	%f3495, %f3479, %f3480;
	mul.ftz.f32 	%f7063, %f3495, %f3488;
	mul.ftz.f32 	%f3496, %f7051, %f7059;
	mul.ftz.f32 	%f3497, %f7053, %f7057;
	sub.ftz.f32 	%f3498, %f3497, %f3496;
	mul.ftz.f32 	%f7064, %f3498, %f3488;
	mul.ftz.f32 	%f3499, %f7056, %f7057;
	mul.ftz.f32 	%f3500, %f7054, %f7059;
	sub.ftz.f32 	%f3501, %f3500, %f3499;
	mul.ftz.f32 	%f7065, %f3501, %f3488;
	mul.ftz.f32 	%f7060, %f3486, %f3488;
	mul.ftz.f32 	%f3502, %f7052, %f7057;
	mul.ftz.f32 	%f3503, %f7051, %f7058;
	sub.ftz.f32 	%f3504, %f3503, %f3502;
	mul.ftz.f32 	%f7061, %f3504, %f3488;
	mul.ftz.f32 	%f3505, %f7054, %f7058;
	mul.ftz.f32 	%f3506, %f7055, %f7057;
	sub.ftz.f32 	%f3507, %f3506, %f3505;
	mul.ftz.f32 	%f7062, %f3507, %f3488;
	bra.uni 	$L__BB4_73;

$L__BB4_64:
	// begin inline asm
	call (%rd1966), _optix_get_instance_inverse_transform_from_handle, (%rd513);
	// end inline asm

$L__BB4_65:
	// begin inline asm
	cvta.to.global.u64 %rd519, %rd1966;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r615,%r616,%r617,%r618}, [%rd519];
	// end inline asm
	mov.b32 	%f7066, %r615;
	mov.b32 	%f7067, %r616;
	mov.b32 	%f7068, %r617;
	add.s64 	%rd523, %rd1966, 16;
	// begin inline asm
	cvta.to.global.u64 %rd522, %rd523;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r619,%r620,%r621,%r622}, [%rd522];
	// end inline asm
	mov.b32 	%f7063, %r619;
	mov.b32 	%f7064, %r620;
	mov.b32 	%f7065, %r621;
	add.s64 	%rd526, %rd1966, 32;
	// begin inline asm
	cvta.to.global.u64 %rd525, %rd526;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r623,%r624,%r625,%r626}, [%rd525];
	// end inline asm
	mov.b32 	%f7060, %r623;
	mov.b32 	%f7061, %r624;
	mov.b32 	%f7062, %r625;

$L__BB4_73:
	setp.eq.s32 	%p51, %r2501, 0;
	@%p51 bra 	$L__BB4_75;

	mul.ftz.f32 	%f3508, %f7037, %f7067;
	fma.rn.ftz.f32 	%f3509, %f7034, %f7066, %f3508;
	fma.rn.ftz.f32 	%f635, %f7040, %f7068, %f3509;
	mul.ftz.f32 	%f3510, %f7036, %f7067;
	fma.rn.ftz.f32 	%f3511, %f7033, %f7066, %f3510;
	fma.rn.ftz.f32 	%f636, %f7039, %f7068, %f3511;
	mul.ftz.f32 	%f3512, %f7035, %f7067;
	fma.rn.ftz.f32 	%f3513, %f7032, %f7066, %f3512;
	fma.rn.ftz.f32 	%f7068, %f7038, %f7068, %f3513;
	mul.ftz.f32 	%f3514, %f7037, %f7064;
	fma.rn.ftz.f32 	%f3515, %f7034, %f7063, %f3514;
	fma.rn.ftz.f32 	%f638, %f7040, %f7065, %f3515;
	mul.ftz.f32 	%f3516, %f7036, %f7064;
	fma.rn.ftz.f32 	%f3517, %f7033, %f7063, %f3516;
	fma.rn.ftz.f32 	%f639, %f7039, %f7065, %f3517;
	mul.ftz.f32 	%f3518, %f7035, %f7064;
	fma.rn.ftz.f32 	%f3519, %f7032, %f7063, %f3518;
	fma.rn.ftz.f32 	%f7065, %f7038, %f7065, %f3519;
	mul.ftz.f32 	%f3520, %f7037, %f7061;
	fma.rn.ftz.f32 	%f3521, %f7034, %f7060, %f3520;
	fma.rn.ftz.f32 	%f641, %f7040, %f7062, %f3521;
	mul.ftz.f32 	%f3522, %f7036, %f7061;
	fma.rn.ftz.f32 	%f3523, %f7033, %f7060, %f3522;
	fma.rn.ftz.f32 	%f642, %f7039, %f7062, %f3523;
	mul.ftz.f32 	%f3524, %f7035, %f7061;
	fma.rn.ftz.f32 	%f3525, %f7032, %f7060, %f3524;
	fma.rn.ftz.f32 	%f7062, %f7038, %f7062, %f3525;
	mov.f32 	%f7060, %f641;
	mov.f32 	%f7061, %f642;
	mov.f32 	%f7063, %f638;
	mov.f32 	%f7064, %f639;
	mov.f32 	%f7066, %f635;
	mov.f32 	%f7067, %f636;

$L__BB4_75:
	add.s32 	%r2501, %r2501, 1;
	setp.lt.u32 	%p52, %r2501, %r610;
	mov.f32 	%f7032, %f7068;
	mov.f32 	%f7033, %f7067;
	mov.f32 	%f7034, %f7066;
	mov.f32 	%f7035, %f7065;
	mov.f32 	%f7036, %f7064;
	mov.f32 	%f7037, %f7063;
	mov.f32 	%f7038, %f7062;
	mov.f32 	%f7039, %f7061;
	mov.f32 	%f7040, %f7060;
	@%p52 bra 	$L__BB4_60;

$L__BB4_76:
	mul.ftz.f32 	%f3526, %f7087, %f7066;
	fma.rn.ftz.f32 	%f3527, %f7088, %f7063, %f3526;
	mul.ftz.f32 	%f3528, %f7087, %f7067;
	fma.rn.ftz.f32 	%f3529, %f7088, %f7064, %f3528;
	mul.ftz.f32 	%f3530, %f7087, %f7068;
	fma.rn.ftz.f32 	%f3531, %f7088, %f7065, %f3530;
	fma.rn.ftz.f32 	%f7089, %f521, %f7062, %f3531;
	fma.rn.ftz.f32 	%f7088, %f521, %f7061, %f3529;
	fma.rn.ftz.f32 	%f7087, %f521, %f7060, %f3527;
	bra.uni 	$L__BB4_78;

$L__BB4_77:
	mov.f32 	%f7089, %f521;

$L__BB4_78:
	mul.ftz.f32 	%f3532, %f7088, %f7088;
	fma.rn.ftz.f32 	%f3533, %f7087, %f7087, %f3532;
	fma.rn.ftz.f32 	%f3534, %f7089, %f7089, %f3533;
	rsqrt.approx.ftz.f32 	%f3535, %f3534;
	mul.ftz.f32 	%f7141, %f7087, %f3535;
	mul.ftz.f32 	%f7140, %f7088, %f3535;
	mul.ftz.f32 	%f7139, %f7089, %f3535;
	// begin inline asm
	call (%r761), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p53, %r761, 0;
	@%p53 bra 	$L__BB4_97;

	// begin inline asm
	call (%r762), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f3536), _optix_get_ray_time, ();
	// end inline asm
	setp.lt.s32 	%p54, %r762, 1;
	@%p54 bra 	$L__BB4_96;

	mov.u32 	%r2502, %r762;

$L__BB4_81:
	.pragma "nounroll";
	add.s32 	%r763, %r2502, -1;
	// begin inline asm
	call (%rd632), _optix_get_transform_list_handle, (%r763);
	// end inline asm
	// begin inline asm
	call (%r764), _optix_get_transform_type_from_handle, (%rd632);
	// end inline asm
	or.b32  	%r765, %r764, 1;
	setp.eq.s32 	%p55, %r765, 3;
	@%p55 bra 	$L__BB4_87;
	bra.uni 	$L__BB4_82;

$L__BB4_87:
	setp.eq.s32 	%p58, %r764, 2;
	@%p58 bra 	$L__BB4_91;
	bra.uni 	$L__BB4_88;

$L__BB4_91:
	// begin inline asm
	call (%rd704), _optix_get_matrix_motion_transform_from_handle, (%rd632);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd706, %rd704;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r853,%r854,%r855,%r856}, [%rd706];
	// end inline asm
	add.s64 	%rd710, %rd704, 16;
	// begin inline asm
	cvta.to.global.u64 %rd709, %rd710;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r857,%r858,%r859,%r860}, [%rd709];
	// end inline asm
	add.s64 	%rd713, %rd704, 32;
	// begin inline asm
	cvta.to.global.u64 %rd712, %rd713;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r861,%r862,%r863,%r864}, [%rd712];
	// end inline asm
	add.s64 	%rd716, %rd704, 48;
	// begin inline asm
	cvta.to.global.u64 %rd715, %rd716;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r865,%r866,%r867,%r868}, [%rd715];
	// end inline asm
	add.s64 	%rd719, %rd704, 64;
	// begin inline asm
	cvta.to.global.u64 %rd718, %rd719;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r869,%r870,%r871,%r872}, [%rd718];
	// end inline asm
	add.s64 	%rd722, %rd704, 80;
	// begin inline asm
	cvta.to.global.u64 %rd721, %rd722;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r873,%r874,%r875,%r876}, [%rd721];
	// end inline asm
	add.s64 	%rd725, %rd704, 96;
	// begin inline asm
	cvta.to.global.u64 %rd724, %rd725;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r877,%r878,%r879,%r880}, [%rd724];
	// end inline asm
	add.s64 	%rd728, %rd704, 112;
	// begin inline asm
	cvta.to.global.u64 %rd727, %rd728;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r881,%r882,%r883,%r884}, [%rd727];
	// end inline asm
	mov.b32 	%f3633, %r856;
	mov.b32 	%f3634, %r857;
	and.b32  	%r897, %r855, 65535;
	add.s32 	%r898, %r897, -1;
	cvt.rn.f32.s32 	%f3635, %r898;
	sub.ftz.f32 	%f3636, %f3536, %f3633;
	sub.ftz.f32 	%f3637, %f3634, %f3633;
	div.approx.ftz.f32 	%f3638, %f3636, %f3637;
	mul.ftz.f32 	%f3639, %f3638, %f3635;
	min.ftz.f32 	%f3640, %f3635, %f3639;
	mov.f32 	%f3641, 0f00000000;
	max.ftz.f32 	%f3642, %f3641, %f3640;
	setp.num.ftz.f32 	%p61, %f3642, %f3642;
	selp.f32 	%f3643, %f3642, 0f00000000, %p61;
	cvt.rmi.ftz.f32.f32 	%f3644, %f3643;
	add.ftz.f32 	%f3645, %f3635, 0fBF800000;
	min.ftz.f32 	%f3646, %f3644, %f3645;
	sub.ftz.f32 	%f733, %f3643, %f3646;
	cvt.rzi.ftz.s32.f32 	%r899, %f3646;
	cvt.s64.s32 	%rd49, %r899;
	mul.wide.s32 	%rd739, %r899, 48;
	add.s64 	%rd731, %rd713, %rd739;
	// begin inline asm
	cvta.to.global.u64 %rd730, %rd731;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r885,%r886,%r887,%r888}, [%rd730];
	// end inline asm
	mov.b32 	%f7115, %r885;
	mov.b32 	%f7116, %r886;
	mov.b32 	%f7117, %r887;
	add.s64 	%rd734, %rd731, 16;
	// begin inline asm
	cvta.to.global.u64 %rd733, %rd734;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r889,%r890,%r891,%r892}, [%rd733];
	// end inline asm
	mov.b32 	%f7112, %r889;
	mov.b32 	%f7113, %r890;
	mov.b32 	%f7114, %r891;
	add.s64 	%rd737, %rd731, 32;
	// begin inline asm
	cvta.to.global.u64 %rd736, %rd737;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r893,%r894,%r895,%r896}, [%rd736];
	// end inline asm
	mov.b32 	%f7109, %r893;
	mov.b32 	%f7110, %r894;
	mov.b32 	%f7111, %r895;
	setp.leu.ftz.f32 	%p62, %f733, 0f00000000;
	@%p62 bra 	$L__BB4_93;

	mov.f32 	%f3647, 0f3F800000;
	sub.ftz.f32 	%f3648, %f3647, %f733;
	mul.lo.s64 	%rd749, %rd49, 48;
	add.s64 	%rd750, %rd704, %rd749;
	add.s64 	%rd741, %rd750, 80;
	// begin inline asm
	cvta.to.global.u64 %rd740, %rd741;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r900,%r901,%r902,%r903}, [%rd740];
	// end inline asm
	mov.b32 	%f3649, %r900;
	mov.b32 	%f3650, %r901;
	mov.b32 	%f3651, %r902;
	mul.ftz.f32 	%f3652, %f733, %f3649;
	mul.ftz.f32 	%f3653, %f733, %f3650;
	mul.ftz.f32 	%f3654, %f733, %f3651;
	fma.rn.ftz.f32 	%f7115, %f3648, %f7115, %f3652;
	fma.rn.ftz.f32 	%f7116, %f3648, %f7116, %f3653;
	fma.rn.ftz.f32 	%f7117, %f3648, %f7117, %f3654;
	add.s64 	%rd744, %rd750, 96;
	// begin inline asm
	cvta.to.global.u64 %rd743, %rd744;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r904,%r905,%r906,%r907}, [%rd743];
	// end inline asm
	mov.b32 	%f3655, %r904;
	mov.b32 	%f3656, %r905;
	mov.b32 	%f3657, %r906;
	mul.ftz.f32 	%f3658, %f733, %f3655;
	mul.ftz.f32 	%f3659, %f733, %f3656;
	mul.ftz.f32 	%f3660, %f733, %f3657;
	fma.rn.ftz.f32 	%f7112, %f3648, %f7112, %f3658;
	fma.rn.ftz.f32 	%f7113, %f3648, %f7113, %f3659;
	fma.rn.ftz.f32 	%f7114, %f3648, %f7114, %f3660;
	add.s64 	%rd747, %rd750, 112;
	// begin inline asm
	cvta.to.global.u64 %rd746, %rd747;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r908,%r909,%r910,%r911}, [%rd746];
	// end inline asm
	mov.b32 	%f3661, %r908;
	mov.b32 	%f3662, %r909;
	mov.b32 	%f3663, %r910;
	mul.ftz.f32 	%f3664, %f733, %f3661;
	mul.ftz.f32 	%f3665, %f733, %f3662;
	mul.ftz.f32 	%f3666, %f733, %f3663;
	fma.rn.ftz.f32 	%f7109, %f3648, %f7109, %f3664;
	fma.rn.ftz.f32 	%f7110, %f3648, %f7110, %f3665;
	fma.rn.ftz.f32 	%f7111, %f3648, %f7111, %f3666;
	bra.uni 	$L__BB4_93;

$L__BB4_82:
	mov.f32 	%f7109, 0f00000000;
	mov.f32 	%f7111, 0f3F800000;
	setp.eq.s32 	%p56, %r764, 4;
	@%p56 bra 	$L__BB4_85;

	setp.ne.s32 	%p57, %r764, 1;
	mov.f32 	%f7110, %f7109;
	mov.f32 	%f7112, %f7109;
	mov.f32 	%f7113, %f7111;
	mov.f32 	%f7114, %f7109;
	mov.f32 	%f7115, %f7111;
	mov.f32 	%f7116, %f7109;
	mov.f32 	%f7117, %f7109;
	@%p57 bra 	$L__BB4_93;

	// begin inline asm
	call (%rd634), _optix_get_static_transform_from_handle, (%rd632);
	// end inline asm
	add.s64 	%rd1967, %rd634, 16;
	bra.uni 	$L__BB4_86;

$L__BB4_88:
	// begin inline asm
	call (%rd647), _optix_get_srt_motion_transform_from_handle, (%rd632);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd649, %rd647;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r778,%r779,%r780,%r781}, [%rd649];
	// end inline asm
	add.s64 	%rd653, %rd647, 16;
	// begin inline asm
	cvta.to.global.u64 %rd652, %rd653;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r782,%r783,%r784,%r785}, [%rd652];
	// end inline asm
	add.s64 	%rd656, %rd647, 32;
	// begin inline asm
	cvta.to.global.u64 %rd655, %rd656;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r786,%r787,%r788,%r789}, [%rd655];
	// end inline asm
	add.s64 	%rd659, %rd647, 48;
	// begin inline asm
	cvta.to.global.u64 %rd658, %rd659;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r790,%r791,%r792,%r793}, [%rd658];
	// end inline asm
	add.s64 	%rd662, %rd647, 64;
	// begin inline asm
	cvta.to.global.u64 %rd661, %rd662;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r794,%r795,%r796,%r797}, [%rd661];
	// end inline asm
	add.s64 	%rd665, %rd647, 80;
	// begin inline asm
	cvta.to.global.u64 %rd664, %rd665;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r798,%r799,%r800,%r801}, [%rd664];
	// end inline asm
	add.s64 	%rd668, %rd647, 96;
	// begin inline asm
	cvta.to.global.u64 %rd667, %rd668;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r802,%r803,%r804,%r805}, [%rd667];
	// end inline asm
	add.s64 	%rd671, %rd647, 112;
	// begin inline asm
	cvta.to.global.u64 %rd670, %rd671;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r806,%r807,%r808,%r809}, [%rd670];
	// end inline asm
	add.s64 	%rd674, %rd647, 128;
	// begin inline asm
	cvta.to.global.u64 %rd673, %rd674;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r810,%r811,%r812,%r813}, [%rd673];
	// end inline asm
	add.s64 	%rd677, %rd647, 144;
	// begin inline asm
	cvta.to.global.u64 %rd676, %rd677;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r814,%r815,%r816,%r817}, [%rd676];
	// end inline asm
	mov.b32 	%f3548, %r781;
	mov.b32 	%f3549, %r782;
	and.b32  	%r834, %r780, 65535;
	add.s32 	%r835, %r834, -1;
	cvt.rn.f32.s32 	%f3550, %r835;
	sub.ftz.f32 	%f3551, %f3536, %f3548;
	sub.ftz.f32 	%f3552, %f3549, %f3548;
	div.approx.ftz.f32 	%f3553, %f3551, %f3552;
	mul.ftz.f32 	%f3554, %f3553, %f3550;
	min.ftz.f32 	%f3555, %f3550, %f3554;
	mov.f32 	%f3556, 0f00000000;
	max.ftz.f32 	%f3557, %f3556, %f3555;
	setp.num.ftz.f32 	%p59, %f3557, %f3557;
	selp.f32 	%f3558, %f3557, 0f00000000, %p59;
	cvt.rmi.ftz.f32.f32 	%f3559, %f3558;
	add.ftz.f32 	%f3560, %f3550, 0fBF800000;
	min.ftz.f32 	%f3561, %f3559, %f3560;
	sub.ftz.f32 	%f693, %f3558, %f3561;
	cvt.rzi.ftz.s32.f32 	%r836, %f3561;
	mul.wide.s32 	%rd691, %r836, 64;
	add.s64 	%rd680, %rd656, %rd691;
	// begin inline asm
	cvta.to.global.u64 %rd679, %rd680;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r818,%r819,%r820,%r821}, [%rd679];
	// end inline asm
	mov.b32 	%f7099, %r818;
	mov.b32 	%f7100, %r819;
	mov.b32 	%f7101, %r820;
	add.s64 	%rd683, %rd680, 16;
	// begin inline asm
	cvta.to.global.u64 %rd682, %rd683;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r822,%r823,%r824,%r825}, [%rd682];
	// end inline asm
	mov.b32 	%f7102, %r822;
	mov.b32 	%f7103, %r823;
	mov.b32 	%f7104, %r825;
	add.s64 	%rd686, %rd680, 32;
	// begin inline asm
	cvta.to.global.u64 %rd685, %rd686;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r826,%r827,%r828,%r829}, [%rd685];
	// end inline asm
	mov.b32 	%f7105, %r827;
	mov.b32 	%f7106, %r828;
	mov.b32 	%f7107, %r829;
	add.s64 	%rd689, %rd680, 48;
	// begin inline asm
	cvta.to.global.u64 %rd688, %rd689;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r830,%r831,%r832,%r833}, [%rd688];
	// end inline asm
	mov.b32 	%f7108, %r830;
	setp.leu.ftz.f32 	%p60, %f693, 0f00000000;
	@%p60 bra 	$L__BB4_90;

	mov.f32 	%f3562, 0f3F800000;
	sub.ftz.f32 	%f3563, %f3562, %f693;
	add.s64 	%rd693, %rd680, 64;
	// begin inline asm
	cvta.to.global.u64 %rd692, %rd693;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r837,%r838,%r839,%r840}, [%rd692];
	// end inline asm
	mov.b32 	%f3564, %r837;
	mov.b32 	%f3565, %r838;
	mov.b32 	%f3566, %r839;
	mul.ftz.f32 	%f3567, %f693, %f3564;
	mul.ftz.f32 	%f3568, %f693, %f3565;
	mul.ftz.f32 	%f3569, %f693, %f3566;
	fma.rn.ftz.f32 	%f7099, %f3563, %f7099, %f3567;
	fma.rn.ftz.f32 	%f7100, %f3563, %f7100, %f3568;
	fma.rn.ftz.f32 	%f7101, %f3563, %f7101, %f3569;
	add.s64 	%rd696, %rd680, 80;
	// begin inline asm
	cvta.to.global.u64 %rd695, %rd696;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r841,%r842,%r843,%r844}, [%rd695];
	// end inline asm
	mov.b32 	%f3570, %r841;
	mov.b32 	%f3571, %r842;
	mov.b32 	%f3572, %r844;
	mul.ftz.f32 	%f3573, %f693, %f3570;
	mul.ftz.f32 	%f3574, %f693, %f3571;
	mul.ftz.f32 	%f3575, %f693, %f3572;
	fma.rn.ftz.f32 	%f7102, %f3563, %f7102, %f3573;
	fma.rn.ftz.f32 	%f7103, %f3563, %f7103, %f3574;
	fma.rn.ftz.f32 	%f7104, %f3563, %f7104, %f3575;
	add.s64 	%rd699, %rd680, 96;
	// begin inline asm
	cvta.to.global.u64 %rd698, %rd699;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r845,%r846,%r847,%r848}, [%rd698];
	// end inline asm
	mov.b32 	%f3576, %r846;
	mov.b32 	%f3577, %r847;
	mov.b32 	%f3578, %r848;
	mul.ftz.f32 	%f3579, %f693, %f3576;
	mul.ftz.f32 	%f3580, %f693, %f3577;
	mul.ftz.f32 	%f3581, %f693, %f3578;
	fma.rn.ftz.f32 	%f3582, %f3563, %f7105, %f3579;
	fma.rn.ftz.f32 	%f3583, %f3563, %f7106, %f3580;
	fma.rn.ftz.f32 	%f3584, %f3563, %f7107, %f3581;
	add.s64 	%rd702, %rd680, 112;
	// begin inline asm
	cvta.to.global.u64 %rd701, %rd702;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r849,%r850,%r851,%r852}, [%rd701];
	// end inline asm
	mov.b32 	%f3585, %r849;
	mul.ftz.f32 	%f3586, %f693, %f3585;
	fma.rn.ftz.f32 	%f3587, %f3563, %f7108, %f3586;
	mul.ftz.f32 	%f3588, %f3583, %f3583;
	fma.rn.ftz.f32 	%f3589, %f3582, %f3582, %f3588;
	fma.rn.ftz.f32 	%f3590, %f3584, %f3584, %f3589;
	fma.rn.ftz.f32 	%f3591, %f3587, %f3587, %f3590;
	rsqrt.approx.ftz.f32 	%f3592, %f3591;
	mul.ftz.f32 	%f7105, %f3582, %f3592;
	mul.ftz.f32 	%f7106, %f3583, %f3592;
	mul.ftz.f32 	%f7107, %f3584, %f3592;
	mul.ftz.f32 	%f7108, %f3592, %f3587;

$L__BB4_90:
	mul.ftz.f32 	%f3593, %f7106, %f7106;
	mul.ftz.f32 	%f3594, %f7105, %f7105;
	sub.ftz.f32 	%f3595, %f3594, %f3593;
	mul.ftz.f32 	%f3596, %f7107, %f7107;
	sub.ftz.f32 	%f3597, %f3595, %f3596;
	fma.rn.ftz.f32 	%f3598, %f7108, %f7108, %f3597;
	mul.ftz.f32 	%f3599, %f7107, %f7108;
	mul.ftz.f32 	%f3600, %f7105, %f7106;
	sub.ftz.f32 	%f3601, %f3600, %f3599;
	add.ftz.f32 	%f3602, %f3601, %f3601;
	mul.ftz.f32 	%f3603, %f7106, %f7108;
	mul.ftz.f32 	%f3604, %f7105, %f7107;
	add.ftz.f32 	%f3605, %f3604, %f3603;
	add.ftz.f32 	%f3606, %f3605, %f3605;
	add.ftz.f32 	%f3607, %f3600, %f3599;
	add.ftz.f32 	%f3608, %f3607, %f3607;
	sub.ftz.f32 	%f3609, %f3593, %f3594;
	sub.ftz.f32 	%f3610, %f3609, %f3596;
	fma.rn.ftz.f32 	%f3611, %f7108, %f7108, %f3610;
	mul.ftz.f32 	%f3612, %f7105, %f7108;
	mul.ftz.f32 	%f3613, %f7106, %f7107;
	sub.ftz.f32 	%f3614, %f3613, %f3612;
	add.ftz.f32 	%f3615, %f3614, %f3614;
	sub.ftz.f32 	%f3616, %f3604, %f3603;
	add.ftz.f32 	%f3617, %f3616, %f3616;
	add.ftz.f32 	%f3618, %f3613, %f3612;
	add.ftz.f32 	%f3619, %f3618, %f3618;
	neg.ftz.f32 	%f3620, %f3594;
	sub.ftz.f32 	%f3621, %f3620, %f3593;
	add.ftz.f32 	%f3622, %f3621, %f3596;
	fma.rn.ftz.f32 	%f3623, %f7108, %f7108, %f3622;
	mul.ftz.f32 	%f3624, %f7103, %f3602;
	fma.rn.ftz.f32 	%f3625, %f7101, %f3598, %f3624;
	fma.rn.ftz.f32 	%f7117, %f7104, %f3606, %f3625;
	mul.ftz.f32 	%f3626, %f7101, %f3608;
	fma.rn.ftz.f32 	%f3627, %f7103, %f3611, %f3626;
	fma.rn.ftz.f32 	%f7114, %f7104, %f3615, %f3627;
	mul.ftz.f32 	%f3628, %f7103, %f3619;
	fma.rn.ftz.f32 	%f3629, %f7101, %f3617, %f3628;
	fma.rn.ftz.f32 	%f7111, %f7104, %f3623, %f3629;
	mul.ftz.f32 	%f3630, %f7102, %f3602;
	fma.rn.ftz.f32 	%f7116, %f7100, %f3598, %f3630;
	mul.ftz.f32 	%f3631, %f7100, %f3608;
	fma.rn.ftz.f32 	%f7113, %f7102, %f3611, %f3631;
	mul.ftz.f32 	%f3632, %f7102, %f3619;
	fma.rn.ftz.f32 	%f7110, %f7100, %f3617, %f3632;
	mul.ftz.f32 	%f7115, %f7099, %f3598;
	mul.ftz.f32 	%f7112, %f7099, %f3608;
	mul.ftz.f32 	%f7109, %f7099, %f3617;
	bra.uni 	$L__BB4_93;

$L__BB4_85:
	// begin inline asm
	call (%rd1967), _optix_get_instance_transform_from_handle, (%rd632);
	// end inline asm

$L__BB4_86:
	// begin inline asm
	cvta.to.global.u64 %rd638, %rd1967;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r766,%r767,%r768,%r769}, [%rd638];
	// end inline asm
	mov.b32 	%f7115, %r766;
	mov.b32 	%f7116, %r767;
	mov.b32 	%f7117, %r768;
	add.s64 	%rd642, %rd1967, 16;
	// begin inline asm
	cvta.to.global.u64 %rd641, %rd642;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r770,%r771,%r772,%r773}, [%rd641];
	// end inline asm
	mov.b32 	%f7112, %r770;
	mov.b32 	%f7113, %r771;
	mov.b32 	%f7114, %r772;
	add.s64 	%rd645, %rd1967, 32;
	// begin inline asm
	cvta.to.global.u64 %rd644, %rd645;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r774,%r775,%r776,%r777}, [%rd644];
	// end inline asm
	mov.b32 	%f7109, %r774;
	mov.b32 	%f7110, %r775;
	mov.b32 	%f7111, %r776;

$L__BB4_93:
	setp.eq.s32 	%p63, %r2502, %r762;
	@%p63 bra 	$L__BB4_95;

	mul.ftz.f32 	%f3667, %f7095, %f7116;
	fma.rn.ftz.f32 	%f3668, %f7092, %f7115, %f3667;
	fma.rn.ftz.f32 	%f761, %f7098, %f7117, %f3668;
	mul.ftz.f32 	%f3669, %f7094, %f7116;
	fma.rn.ftz.f32 	%f3670, %f7091, %f7115, %f3669;
	fma.rn.ftz.f32 	%f762, %f7097, %f7117, %f3670;
	mul.ftz.f32 	%f3671, %f7093, %f7116;
	fma.rn.ftz.f32 	%f3672, %f7090, %f7115, %f3671;
	fma.rn.ftz.f32 	%f7117, %f7096, %f7117, %f3672;
	mul.ftz.f32 	%f3673, %f7095, %f7113;
	fma.rn.ftz.f32 	%f3674, %f7092, %f7112, %f3673;
	fma.rn.ftz.f32 	%f764, %f7098, %f7114, %f3674;
	mul.ftz.f32 	%f3675, %f7094, %f7113;
	fma.rn.ftz.f32 	%f3676, %f7091, %f7112, %f3675;
	fma.rn.ftz.f32 	%f765, %f7097, %f7114, %f3676;
	mul.ftz.f32 	%f3677, %f7093, %f7113;
	fma.rn.ftz.f32 	%f3678, %f7090, %f7112, %f3677;
	fma.rn.ftz.f32 	%f7114, %f7096, %f7114, %f3678;
	mul.ftz.f32 	%f3679, %f7095, %f7110;
	fma.rn.ftz.f32 	%f3680, %f7092, %f7109, %f3679;
	fma.rn.ftz.f32 	%f767, %f7098, %f7111, %f3680;
	mul.ftz.f32 	%f3681, %f7094, %f7110;
	fma.rn.ftz.f32 	%f3682, %f7091, %f7109, %f3681;
	fma.rn.ftz.f32 	%f768, %f7097, %f7111, %f3682;
	mul.ftz.f32 	%f3683, %f7093, %f7110;
	fma.rn.ftz.f32 	%f3684, %f7090, %f7109, %f3683;
	fma.rn.ftz.f32 	%f7111, %f7096, %f7111, %f3684;
	mov.f32 	%f7109, %f767;
	mov.f32 	%f7110, %f768;
	mov.f32 	%f7112, %f764;
	mov.f32 	%f7113, %f765;
	mov.f32 	%f7115, %f761;
	mov.f32 	%f7116, %f762;

$L__BB4_95:
	setp.gt.s32 	%p64, %r2502, 1;
	mov.u32 	%r2502, %r763;
	mov.f32 	%f7090, %f7117;
	mov.f32 	%f7091, %f7116;
	mov.f32 	%f7092, %f7115;
	mov.f32 	%f7093, %f7114;
	mov.f32 	%f7094, %f7113;
	mov.f32 	%f7095, %f7112;
	mov.f32 	%f7096, %f7111;
	mov.f32 	%f7097, %f7110;
	mov.f32 	%f7098, %f7109;
	@%p64 bra 	$L__BB4_81;

$L__BB4_96:
	mul.ftz.f32 	%f3685, %f7137, %f7116;
	fma.rn.ftz.f32 	%f3686, %f7136, %f7115, %f3685;
	mul.ftz.f32 	%f3687, %f7137, %f7113;
	fma.rn.ftz.f32 	%f3688, %f7136, %f7112, %f3687;
	mul.ftz.f32 	%f3689, %f7137, %f7110;
	fma.rn.ftz.f32 	%f3690, %f7136, %f7109, %f3689;
	fma.rn.ftz.f32 	%f7138, %f524, %f7111, %f3690;
	fma.rn.ftz.f32 	%f7137, %f524, %f7114, %f3688;
	fma.rn.ftz.f32 	%f7136, %f524, %f7117, %f3686;
	bra.uni 	$L__BB4_98;

$L__BB4_97:
	mov.f32 	%f7138, %f524;

$L__BB4_98:
	mul.ftz.f32 	%f3691, %f7137, %f7137;
	fma.rn.ftz.f32 	%f3692, %f7136, %f7136, %f3691;
	fma.rn.ftz.f32 	%f3693, %f7138, %f7138, %f3692;
	rsqrt.approx.ftz.f32 	%f3694, %f3693;
	mul.ftz.f32 	%f7147, %f7136, %f3694;
	mul.ftz.f32 	%f7146, %f7137, %f3694;
	mul.ftz.f32 	%f7145, %f7138, %f3694;
	mul.ftz.f32 	%f3695, %f526, %f526;
	fma.rn.ftz.f32 	%f3696, %f525, %f525, %f3695;
	fma.rn.ftz.f32 	%f3697, %f527, %f527, %f3696;
	rsqrt.approx.ftz.f32 	%f3698, %f3697;
	mul.ftz.f32 	%f800, %f525, %f3698;
	mul.ftz.f32 	%f801, %f526, %f3698;
	mul.ftz.f32 	%f802, %f527, %f3698;
	abs.ftz.f32 	%f3699, %f7141;
	setp.geu.ftz.f32 	%p65, %f3699, 0f7F800000;
	mov.u16 	%rs9, 0;
	@%p65 bra 	$L__BB4_101;

	abs.ftz.f32 	%f3700, %f7140;
	setp.geu.ftz.f32 	%p66, %f3700, 0f7F800000;
	@%p66 bra 	$L__BB4_101;

	abs.ftz.f32 	%f3701, %f7139;
	setp.lt.ftz.f32 	%p67, %f3701, 0f7F800000;
	selp.u16 	%rs9, 1, 0, %p67;

$L__BB4_101:
	setp.ne.s16 	%p68, %rs9, 0;
	@%p68 bra 	$L__BB4_103;

	ld.global.f32 	%f7141, [_Z19computeSurfacePointRKN6shared20GeometryInstanceDataEjffRK9Point3D_TIfEPS4_P10Vector3D_TIfLb1EEPS8_IfLb0EESA_P9Point2D_TIfEPf$366];
	ld.global.f32 	%f7140, [_Z19computeSurfacePointRKN6shared20GeometryInstanceDataEjffRK9Point3D_TIfEPS4_P10Vector3D_TIfLb1EEPS8_IfLb0EESA_P9Point2D_TIfEPf$366+4];
	ld.global.f32 	%f7139, [_Z19computeSurfacePointRKN6shared20GeometryInstanceDataEjffRK9Point3D_TIfEPS4_P10Vector3D_TIfLb1EEPS8_IfLb0EESA_P9Point2D_TIfEPf$366+8];
	ld.global.f32 	%f7147, [_Z19computeSurfacePointRKN6shared20GeometryInstanceDataEjffRK9Point3D_TIfEPS4_P10Vector3D_TIfLb1EEPS8_IfLb0EESA_P9Point2D_TIfEPf$367];
	ld.global.f32 	%f7146, [_Z19computeSurfacePointRKN6shared20GeometryInstanceDataEjffRK9Point3D_TIfEPS4_P10Vector3D_TIfLb1EEPS8_IfLb0EESA_P9Point2D_TIfEPf$367+4];
	ld.global.f32 	%f7145, [_Z19computeSurfacePointRKN6shared20GeometryInstanceDataEjffRK9Point3D_TIfEPS4_P10Vector3D_TIfLb1EEPS8_IfLb0EESA_P9Point2D_TIfEPf$367+8];

$L__BB4_103:
	abs.ftz.f32 	%f3702, %f7147;
	setp.geu.ftz.f32 	%p69, %f3702, 0f7F800000;
	mov.u16 	%rs10, 0;
	@%p69 bra 	$L__BB4_106;

	abs.ftz.f32 	%f3703, %f7146;
	setp.geu.ftz.f32 	%p70, %f3703, 0f7F800000;
	@%p70 bra 	$L__BB4_106;

	abs.ftz.f32 	%f3704, %f7145;
	setp.lt.ftz.f32 	%p71, %f3704, 0f7F800000;
	selp.u16 	%rs10, 1, 0, %p71;

$L__BB4_106:
	setp.ne.s16 	%p72, %rs10, 0;
	@%p72 bra 	$L__BB4_108;

	setp.ge.ftz.f32 	%p73, %f7139, 0f00000000;
	selp.f32 	%f3705, 0f3F800000, 0fBF800000, %p73;
	mov.f32 	%f3706, 0fBF800000;
	add.ftz.f32 	%f3707, %f7139, %f3705;
	div.approx.ftz.f32 	%f3708, %f3706, %f3707;
	mul.ftz.f32 	%f3709, %f7140, %f7141;
	mul.ftz.f32 	%f3710, %f3709, %f3708;
	mul.ftz.f32 	%f3711, %f3705, %f7141;
	mul.ftz.f32 	%f3712, %f7141, %f3711;
	fma.rn.ftz.f32 	%f7147, %f3712, %f3708, 0f3F800000;
	mul.ftz.f32 	%f7146, %f3705, %f3710;
	neg.ftz.f32 	%f7145, %f3711;

$L__BB4_108:
	// begin inline asm
	call (%f3713), _optix_get_world_ray_direction_x, ();
	// end inline asm
	// begin inline asm
	call (%f3714), _optix_get_world_ray_direction_y, ();
	// end inline asm
	// begin inline asm
	call (%f3715), _optix_get_world_ray_direction_z, ();
	// end inline asm
	mul.ftz.f32 	%f3716, %f3714, %f3714;
	fma.rn.ftz.f32 	%f3717, %f3713, %f3713, %f3716;
	fma.rn.ftz.f32 	%f3718, %f3715, %f3715, %f3717;
	rsqrt.approx.ftz.f32 	%f3719, %f3718;
	mul.ftz.f32 	%f3720, %f3713, %f3719;
	neg.ftz.f32 	%f3721, %f3720;
	mul.ftz.f32 	%f3722, %f3714, %f3719;
	mul.ftz.f32 	%f3723, %f3715, %f3719;
	mul.ftz.f32 	%f3724, %f800, %f3721;
	mul.ftz.f32 	%f3725, %f801, %f3722;
	sub.ftz.f32 	%f3726, %f3724, %f3725;
	mul.ftz.f32 	%f3727, %f802, %f3723;
	sub.ftz.f32 	%f3728, %f3726, %f3727;
	setp.ge.ftz.f32 	%p74, %f3728, 0f00000000;
	selp.f32 	%f3729, 0f3F800000, 0fBF800000, %p74;
	mul.ftz.f32 	%f3730, %f7139, %f7146;
	mul.ftz.f32 	%f3731, %f7140, %f7145;
	sub.ftz.f32 	%f821, %f3731, %f3730;
	mul.ftz.f32 	%f3732, %f7141, %f7145;
	mul.ftz.f32 	%f3733, %f7139, %f7147;
	sub.ftz.f32 	%f822, %f3733, %f3732;
	mul.ftz.f32 	%f3734, %f7140, %f7147;
	mul.ftz.f32 	%f3735, %f7141, %f7146;
	sub.ftz.f32 	%f823, %f3735, %f3734;
	mul.ftz.f32 	%f3736, %f800, %f3729;
	mul.ftz.f32 	%f3737, %f801, %f3729;
	mul.ftz.f32 	%f3738, %f802, %f3729;
	mul.ftz.f32 	%f3739, %f3736, 0f43800000;
	cvt.rzi.ftz.s32.f32 	%r912, %f3739;
	mul.ftz.f32 	%f3740, %f3737, 0f43800000;
	cvt.rzi.ftz.s32.f32 	%r913, %f3740;
	mul.ftz.f32 	%f3741, %f3738, 0f43800000;
	cvt.rzi.ftz.s32.f32 	%r914, %f3741;
	setp.lt.ftz.f32 	%p75, %f516, 0f00000000;
	selp.b32 	%r915, -1, 1, %p75;
	mov.b32 	%r916, %f516;
	mad.lo.s32 	%r917, %r912, %r915, %r916;
	mov.b32 	%f3742, %r917;
	setp.lt.ftz.f32 	%p76, %f517, 0f00000000;
	selp.b32 	%r918, -1, 1, %p76;
	mov.b32 	%r919, %f517;
	mad.lo.s32 	%r920, %r913, %r918, %r919;
	mov.b32 	%f3743, %r920;
	setp.lt.ftz.f32 	%p77, %f518, 0f00000000;
	selp.b32 	%r921, -1, 1, %p77;
	mov.b32 	%r922, %f518;
	mad.lo.s32 	%r923, %r914, %r921, %r922;
	mov.b32 	%f3744, %r923;
	fma.rn.ftz.f32 	%f3745, %f3736, 0f37800000, %f516;
	fma.rn.ftz.f32 	%f3746, %f3737, 0f37800000, %f517;
	fma.rn.ftz.f32 	%f3747, %f3738, 0f37800000, %f518;
	abs.ftz.f32 	%f3748, %f516;
	setp.lt.ftz.f32 	%p78, %f3748, 0f3D000000;
	selp.f32 	%f824, %f3745, %f3742, %p78;
	abs.ftz.f32 	%f3749, %f517;
	setp.lt.ftz.f32 	%p79, %f3749, 0f3D000000;
	selp.f32 	%f825, %f3746, %f3743, %p79;
	abs.ftz.f32 	%f3750, %f518;
	setp.lt.ftz.f32 	%p80, %f3750, 0f3D000000;
	selp.f32 	%f826, %f3747, %f3744, %p80;
	mul.ftz.f32 	%f3751, %f7147, %f3721;
	mul.ftz.f32 	%f3752, %f7146, %f3722;
	sub.ftz.f32 	%f3753, %f3751, %f3752;
	mul.ftz.f32 	%f3754, %f7145, %f3723;
	sub.ftz.f32 	%f827, %f3753, %f3754;
	mul.ftz.f32 	%f3755, %f821, %f3721;
	mul.ftz.f32 	%f3756, %f822, %f3722;
	sub.ftz.f32 	%f3757, %f3755, %f3756;
	mul.ftz.f32 	%f3758, %f823, %f3723;
	sub.ftz.f32 	%f828, %f3757, %f3758;
	mul.ftz.f32 	%f3759, %f7141, %f3721;
	mul.ftz.f32 	%f3760, %f7140, %f3722;
	sub.ftz.f32 	%f3761, %f3759, %f3760;
	mul.ftz.f32 	%f3762, %f7139, %f3723;
	sub.ftz.f32 	%f829, %f3761, %f3762;
	ld.u32 	%r924, [%rd6+52];
	and.b32  	%r925, %r924, 1073741823;
	setp.ne.s32 	%p81, %r925, 1;
	mul.lo.s64 	%rd751, %rd5, 216;
	add.s64 	%rd752, %rd4, %rd751;
	add.s64 	%rd50, %rd752, 64;
	@%p81 bra 	$L__BB4_110;

	st.f32 	[%rd7+12], %f824;
	st.f32 	[%rd7+16], %f825;
	st.f32 	[%rd7+20], %f826;
	ld.global.f32 	%f3763, [%rd50];
	ld.global.f32 	%f3764, [%rd50+16];
	mul.ftz.f32 	%f3765, %f825, %f3764;
	fma.rn.ftz.f32 	%f3766, %f824, %f3763, %f3765;
	ld.global.f32 	%f3767, [%rd50+32];
	fma.rn.ftz.f32 	%f3768, %f826, %f3767, %f3766;
	ld.global.f32 	%f3769, [%rd50+48];
	add.ftz.f32 	%f3770, %f3769, %f3768;
	ld.global.f32 	%f3771, [%rd50+4];
	ld.global.f32 	%f3772, [%rd50+20];
	mul.ftz.f32 	%f3773, %f825, %f3772;
	fma.rn.ftz.f32 	%f3774, %f824, %f3771, %f3773;
	ld.global.f32 	%f3775, [%rd50+36];
	fma.rn.ftz.f32 	%f3776, %f826, %f3775, %f3774;
	ld.global.f32 	%f3777, [%rd50+52];
	add.ftz.f32 	%f3778, %f3777, %f3776;
	ld.global.f32 	%f3779, [%rd50+8];
	ld.global.f32 	%f3780, [%rd50+24];
	mul.ftz.f32 	%f3781, %f825, %f3780;
	fma.rn.ftz.f32 	%f3782, %f824, %f3779, %f3781;
	ld.global.f32 	%f3783, [%rd50+40];
	fma.rn.ftz.f32 	%f3784, %f826, %f3783, %f3782;
	ld.global.f32 	%f3785, [%rd50+56];
	add.ftz.f32 	%f3786, %f3785, %f3784;
	st.f32 	[%rd7+24], %f3770;
	st.f32 	[%rd7+28], %f3778;
	st.f32 	[%rd7+32], %f3786;
	st.f32 	[%rd7+36], %f7141;
	st.f32 	[%rd7+40], %f7140;
	st.f32 	[%rd7+44], %f7139;
	st.f32 	[%rd7+48], %f528;
	st.f32 	[%rd7+52], %f529;

$L__BB4_110:
	ld.const.u64 	%rd1958, [plp+336];
	cvta.to.global.u64 	%rd1957, %rd1958;
	ld.const.v2.u32 	{%r926, %r927}, [plp+216];
	mov.b32 	%f830, %r927;
	mul.lo.s64 	%rd753, %rd2, 272;
	add.s64 	%rd51, %rd1957, %rd753;
	ld.global.u64 	%rd754, [%rd51];
	mov.f32 	%f3787, 0f00000000;
	tex.level.2d.v4.f32.f32 	{%f831, %f832, %f833, %f834}, [%rd754, {%f528, %f529}], %f3787;
	ld.global.u64 	%rd52, [%rd51+16];
	tex.level.2d.v4.f32.f32 	{%f3788, %f3789, %f3790, %f3791}, [%rd52, {%f528, %f529}], %f3787;
	ld.global.u64 	%rd755, [%rd51+8];
	tex.level.2d.v4.f32.f32 	{%f3792, %f3793, %f3794, %f3795}, [%rd755, {%f528, %f529}], %f3787;
	ld.global.u64 	%rd756, [%rd51+32];
	tex.level.2d.v4.f32.f32 	{%f3796, %f835, %f3797, %f3798}, [%rd756, {%f528, %f529}], %f3787;
	ld.global.u64 	%rd53, [%rd51+120];
	tex.level.2d.v4.f32.f32 	{%f3799, %f3800, %f3801, %f3802}, [%rd53, {%f528, %f529}], %f3787;
	ld.global.u64 	%rd757, [%rd51+128];
	tex.level.2d.v4.f32.f32 	{%f3803, %f3804, %f3805, %f3806}, [%rd757, {%f528, %f529}], %f3787;
	ld.global.u64 	%rd758, [%rd51+136];
	tex.level.2d.v4.f32.f32 	{%f3807, %f3808, %f3809, %f3810}, [%rd758, {%f528, %f529}], %f3787;
	ld.global.u64 	%rd759, [%rd51+160];
	tex.level.2d.v4.f32.f32 	{%f836, %f837, %f838, %f839}, [%rd759, {%f528, %f529}], %f3787;
	ld.global.u64 	%rd760, [%rd51+168];
	tex.level.2d.v4.f32.f32 	{%f840, %f841, %f842, %f843}, [%rd760, {%f528, %f529}], %f3787;
	and.b32  	%r27, %r926, 2;
	ld.global.u32 	%r930, [%rd51+268];
	setp.eq.s32 	%p82, %r930, 0;
	setp.lt.ftz.f32 	%p83, %f834, 0f3F000000;
	setp.lt.ftz.f32 	%p84, %f3799, 0f3DCCCCCD;
	selp.f32 	%f3811, 0f00000000, %f3799, %p84;
	selp.f32 	%f3812, 0f3F800000, %f3811, %p83;
	mov.f32 	%f3813, 0f3F800000;
	selp.f32 	%f3814, %f3799, %f3812, %p82;
	and.b32  	%r931, %r926, 1;
	setp.eq.b32 	%p85, %r931, 1;
	selp.f32 	%f844, 0f00000000, %f3788, %p85;
	selp.f32 	%f3815, 0f3A83126F, %f3792, %p85;
	mov.f32 	%f3816, 0f3A83126F;
	selp.f32 	%f845, 0f3F800000, %f3814, %p85;
	selp.f32 	%f846, 0f3F800000, %f3803, %p85;
	ld.const.f32 	%f3817, [plp+224];
	selp.f32 	%f847, %f3817, %f3807, %p85;
	max.ftz.f32 	%f3818, %f3815, %f3816;
	min.ftz.f32 	%f848, %f3818, %f3813;
	mul.ftz.f32 	%f3819, %f3815, %f3815;
	mov.f32 	%f3820, 0f3727C5AC;
	max.ftz.f32 	%f3821, %f3819, %f3820;
	min.ftz.f32 	%f7148, %f3821, %f3813;
	setp.leu.ftz.f32 	%p86, %f835, 0f00000000;
	mov.f32 	%f7149, %f7148;
	@%p86 bra 	$L__BB4_112;

	max.ftz.f32 	%f3823, %f835, %f3787;
	mov.f32 	%f3824, 0f3F7AE148;
	min.ftz.f32 	%f3825, %f3823, %f3824;
	sub.ftz.f32 	%f3827, %f3813, %f3825;
	sqrt.approx.ftz.f32 	%f3828, %f3827;
	div.approx.ftz.f32 	%f3829, %f7148, %f3828;
	min.ftz.f32 	%f850, %f3829, %f3813;
	mul.ftz.f32 	%f7149, %f7148, %f3828;
	mov.f32 	%f7148, %f850;

$L__BB4_112:
	cvt.rn.f32.u64 	%f3830, %rd53;
	setp.leu.ftz.f32 	%p88, %f3830, 0f3F666666;
	mov.pred 	%p345, 0;
	@%p88 bra 	$L__BB4_114;

	cvt.rn.f32.u64 	%f3831, %rd52;
	setp.le.ftz.f32 	%p345, %f3831, 0f00000000;

$L__BB4_114:
	mul.ftz.f32 	%f854, %f836, %f840;
	setp.leu.ftz.f32 	%p89, %f854, 0f00000000;
	mul.ftz.f32 	%f855, %f837, %f840;
	setp.leu.ftz.f32 	%p90, %f855, 0f00000000;
	and.pred  	%p91, %p89, %p90;
	mul.ftz.f32 	%f856, %f838, %f840;
	setp.leu.ftz.f32 	%p92, %f856, 0f00000000;
	and.pred  	%p93, %p92, %p91;
	@%p93 bra 	$L__BB4_190;

	ld.u32 	%r28, [%rd6+52];
	and.b32  	%r932, %r28, 1073741823;
	setp.eq.s32 	%p94, %r932, 1;
	@%p94 bra 	$L__BB4_189;
	bra.uni 	$L__BB4_116;

$L__BB4_189:
	ld.f32 	%f4518, [%rd6];
	ld.f32 	%f4519, [%rd6+4];
	ld.f32 	%f4520, [%rd6+8];
	ld.f32 	%f4521, [%rd6+12];
	fma.rn.ftz.f32 	%f4522, %f854, %f4518, %f4521;
	st.f32 	[%rd6+12], %f4522;
	ld.f32 	%f4523, [%rd6+16];
	fma.rn.ftz.f32 	%f4524, %f855, %f4519, %f4523;
	st.f32 	[%rd6+16], %f4524;
	ld.f32 	%f4525, [%rd6+20];
	fma.rn.ftz.f32 	%f4526, %f856, %f4520, %f4525;
	st.f32 	[%rd6+20], %f4526;
	bra.uni 	$L__BB4_190;

$L__BB4_116:
	ld.const.u32 	%r933, [plp+284];
	and.b32  	%r934, %r933, 1;
	setp.eq.b32 	%p95, %r934, 1;
	setp.gt.s32 	%p96, %r28, -1;
	and.pred  	%p97, %p95, %p96;
	@%p97 bra 	$L__BB4_118;
	bra.uni 	$L__BB4_117;

$L__BB4_118:
	ld.global.u32 	%r935, [%rd50+144];
	and.b32  	%r936, %r935, 1;
	setp.eq.b32 	%p98, %r936, 1;
	mov.pred 	%p99, 0;
	xor.pred  	%p100, %p98, %p99;
	not.pred 	%p101, %p100;
	@%p101 bra 	$L__BB4_188;
	bra.uni 	$L__BB4_119;

$L__BB4_188:
	ld.f32 	%f4509, [%rd6];
	ld.f32 	%f4510, [%rd6+4];
	ld.f32 	%f4511, [%rd6+8];
	ld.f32 	%f4512, [%rd6+12];
	fma.rn.ftz.f32 	%f4513, %f854, %f4509, %f4512;
	st.f32 	[%rd6+12], %f4513;
	ld.f32 	%f4514, [%rd6+16];
	fma.rn.ftz.f32 	%f4515, %f855, %f4510, %f4514;
	st.f32 	[%rd6+16], %f4515;
	ld.f32 	%f4516, [%rd6+20];
	fma.rn.ftz.f32 	%f4517, %f856, %f4511, %f4516;
	st.f32 	[%rd6+20], %f4517;
	bra.uni 	$L__BB4_190;

$L__BB4_117:
	ld.f32 	%f3832, [%rd6];
	ld.f32 	%f3833, [%rd6+4];
	ld.f32 	%f3834, [%rd6+8];
	ld.f32 	%f3835, [%rd6+12];
	fma.rn.ftz.f32 	%f3836, %f854, %f3832, %f3835;
	st.f32 	[%rd6+12], %f3836;
	ld.f32 	%f3837, [%rd6+16];
	fma.rn.ftz.f32 	%f3838, %f855, %f3833, %f3837;
	st.f32 	[%rd6+16], %f3838;
	ld.f32 	%f3839, [%rd6+20];
	fma.rn.ftz.f32 	%f3840, %f856, %f3834, %f3839;
	st.f32 	[%rd6+20], %f3840;
	bra.uni 	$L__BB4_190;

$L__BB4_119:
	cvt.u32.u64 	%r938, %rd10;
	ld.global.u64 	%rd761, [%rd9+16];
	mul.wide.s32 	%rd762, %r938, 12;
	add.s64 	%rd763, %rd761, %rd762;
	ld.u32 	%r939, [%rd763];
	ld.u32 	%r29, [%rd763+4];
	ld.u32 	%r30, [%rd763+8];
	ld.global.u64 	%rd54, [%rd9];
	mul.wide.u32 	%rd764, %r939, 44;
	add.s64 	%rd765, %rd54, %rd764;
	ld.f32 	%f7214, [%rd765];
	ld.f32 	%f7215, [%rd765+4];
	ld.f32 	%f7216, [%rd765+8];
	// begin inline asm
	call (%r937), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p102, %r937, 0;
	@%p102 bra 	$L__BB4_139;

	// begin inline asm
	call (%r940), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f3841), _optix_get_ray_time, ();
	// end inline asm
	setp.lt.s32 	%p103, %r940, 1;
	@%p103 bra 	$L__BB4_138;

	mov.u32 	%r2503, %r940;

$L__BB4_122:
	.pragma "nounroll";
	add.s32 	%r941, %r2503, -1;
	// begin inline asm
	call (%rd766), _optix_get_transform_list_handle, (%r941);
	// end inline asm
	// begin inline asm
	call (%r942), _optix_get_transform_type_from_handle, (%rd766);
	// end inline asm
	or.b32  	%r943, %r942, 1;
	setp.eq.s32 	%p104, %r943, 3;
	@%p104 bra 	$L__BB4_129;
	bra.uni 	$L__BB4_123;

$L__BB4_129:
	setp.eq.s32 	%p108, %r942, 2;
	@%p108 bra 	$L__BB4_133;
	bra.uni 	$L__BB4_130;

$L__BB4_133:
	// begin inline asm
	call (%rd838), _optix_get_matrix_motion_transform_from_handle, (%rd766);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd840, %rd838;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1031,%r1032,%r1033,%r1034}, [%rd840];
	// end inline asm
	add.s64 	%rd844, %rd838, 16;
	// begin inline asm
	cvta.to.global.u64 %rd843, %rd844;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1035,%r1036,%r1037,%r1038}, [%rd843];
	// end inline asm
	add.s64 	%rd847, %rd838, 32;
	// begin inline asm
	cvta.to.global.u64 %rd846, %rd847;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1039,%r1040,%r1041,%r1042}, [%rd846];
	// end inline asm
	add.s64 	%rd850, %rd838, 48;
	// begin inline asm
	cvta.to.global.u64 %rd849, %rd850;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1043,%r1044,%r1045,%r1046}, [%rd849];
	// end inline asm
	add.s64 	%rd853, %rd838, 64;
	// begin inline asm
	cvta.to.global.u64 %rd852, %rd853;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1047,%r1048,%r1049,%r1050}, [%rd852];
	// end inline asm
	add.s64 	%rd856, %rd838, 80;
	// begin inline asm
	cvta.to.global.u64 %rd855, %rd856;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1051,%r1052,%r1053,%r1054}, [%rd855];
	// end inline asm
	add.s64 	%rd859, %rd838, 96;
	// begin inline asm
	cvta.to.global.u64 %rd858, %rd859;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1055,%r1056,%r1057,%r1058}, [%rd858];
	// end inline asm
	add.s64 	%rd862, %rd838, 112;
	// begin inline asm
	cvta.to.global.u64 %rd861, %rd862;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1059,%r1060,%r1061,%r1062}, [%rd861];
	// end inline asm
	mov.b32 	%f3962, %r1034;
	mov.b32 	%f3963, %r1035;
	and.b32  	%r1075, %r1033, 65535;
	add.s32 	%r1076, %r1075, -1;
	cvt.rn.f32.s32 	%f3964, %r1076;
	sub.ftz.f32 	%f3965, %f3841, %f3962;
	sub.ftz.f32 	%f3966, %f3963, %f3962;
	div.approx.ftz.f32 	%f3967, %f3965, %f3966;
	mul.ftz.f32 	%f3968, %f3967, %f3964;
	min.ftz.f32 	%f3969, %f3964, %f3968;
	mov.f32 	%f3970, 0f00000000;
	max.ftz.f32 	%f3971, %f3970, %f3969;
	setp.num.ftz.f32 	%p111, %f3971, %f3971;
	selp.f32 	%f3972, %f3971, 0f00000000, %p111;
	cvt.rmi.ftz.f32.f32 	%f3973, %f3972;
	add.ftz.f32 	%f3974, %f3964, 0fBF800000;
	min.ftz.f32 	%f3975, %f3973, %f3974;
	sub.ftz.f32 	%f946, %f3972, %f3975;
	cvt.rzi.ftz.s32.f32 	%r1077, %f3975;
	cvt.s64.s32 	%rd61, %r1077;
	mul.wide.s32 	%rd873, %r1077, 48;
	add.s64 	%rd865, %rd847, %rd873;
	// begin inline asm
	cvta.to.global.u64 %rd864, %rd865;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1063,%r1064,%r1065,%r1066}, [%rd864];
	// end inline asm
	mov.b32 	%f7186, %r1063;
	mov.b32 	%f7187, %r1064;
	mov.b32 	%f7188, %r1065;
	mov.b32 	%f7189, %r1066;
	add.s64 	%rd868, %rd865, 16;
	// begin inline asm
	cvta.to.global.u64 %rd867, %rd868;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1067,%r1068,%r1069,%r1070}, [%rd867];
	// end inline asm
	mov.b32 	%f7182, %r1067;
	mov.b32 	%f7183, %r1068;
	mov.b32 	%f7184, %r1069;
	mov.b32 	%f7185, %r1070;
	add.s64 	%rd871, %rd865, 32;
	// begin inline asm
	cvta.to.global.u64 %rd870, %rd871;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1071,%r1072,%r1073,%r1074}, [%rd870];
	// end inline asm
	mov.b32 	%f7178, %r1071;
	mov.b32 	%f7179, %r1072;
	mov.b32 	%f7180, %r1073;
	mov.b32 	%f7181, %r1074;
	setp.leu.ftz.f32 	%p112, %f946, 0f00000000;
	@%p112 bra 	$L__BB4_135;

	mov.f32 	%f3976, 0f3F800000;
	sub.ftz.f32 	%f3977, %f3976, %f946;
	mul.lo.s64 	%rd883, %rd61, 48;
	add.s64 	%rd884, %rd838, %rd883;
	add.s64 	%rd875, %rd884, 80;
	// begin inline asm
	cvta.to.global.u64 %rd874, %rd875;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1078,%r1079,%r1080,%r1081}, [%rd874];
	// end inline asm
	mov.b32 	%f3978, %r1078;
	mov.b32 	%f3979, %r1079;
	mov.b32 	%f3980, %r1080;
	mov.b32 	%f3981, %r1081;
	mul.ftz.f32 	%f3982, %f946, %f3978;
	mul.ftz.f32 	%f3983, %f946, %f3979;
	mul.ftz.f32 	%f3984, %f946, %f3980;
	mul.ftz.f32 	%f3985, %f946, %f3981;
	fma.rn.ftz.f32 	%f7186, %f3977, %f7186, %f3982;
	fma.rn.ftz.f32 	%f7187, %f3977, %f7187, %f3983;
	fma.rn.ftz.f32 	%f7188, %f3977, %f7188, %f3984;
	fma.rn.ftz.f32 	%f7189, %f3977, %f7189, %f3985;
	add.s64 	%rd878, %rd884, 96;
	// begin inline asm
	cvta.to.global.u64 %rd877, %rd878;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1082,%r1083,%r1084,%r1085}, [%rd877];
	// end inline asm
	mov.b32 	%f3986, %r1082;
	mov.b32 	%f3987, %r1083;
	mov.b32 	%f3988, %r1084;
	mov.b32 	%f3989, %r1085;
	mul.ftz.f32 	%f3990, %f946, %f3986;
	mul.ftz.f32 	%f3991, %f946, %f3987;
	mul.ftz.f32 	%f3992, %f946, %f3988;
	mul.ftz.f32 	%f3993, %f946, %f3989;
	fma.rn.ftz.f32 	%f7182, %f3977, %f7182, %f3990;
	fma.rn.ftz.f32 	%f7183, %f3977, %f7183, %f3991;
	fma.rn.ftz.f32 	%f7184, %f3977, %f7184, %f3992;
	fma.rn.ftz.f32 	%f7185, %f3977, %f7185, %f3993;
	add.s64 	%rd881, %rd884, 112;
	// begin inline asm
	cvta.to.global.u64 %rd880, %rd881;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1086,%r1087,%r1088,%r1089}, [%rd880];
	// end inline asm
	mov.b32 	%f3994, %r1086;
	mov.b32 	%f3995, %r1087;
	mov.b32 	%f3996, %r1088;
	mov.b32 	%f3997, %r1089;
	mul.ftz.f32 	%f3998, %f946, %f3994;
	mul.ftz.f32 	%f3999, %f946, %f3995;
	mul.ftz.f32 	%f4000, %f946, %f3996;
	mul.ftz.f32 	%f4001, %f946, %f3997;
	fma.rn.ftz.f32 	%f7178, %f3977, %f7178, %f3998;
	fma.rn.ftz.f32 	%f7179, %f3977, %f7179, %f3999;
	fma.rn.ftz.f32 	%f7180, %f3977, %f7180, %f4000;
	fma.rn.ftz.f32 	%f7181, %f3977, %f7181, %f4001;
	bra.uni 	$L__BB4_135;

$L__BB4_123:
	mov.f32 	%f7178, 0f00000000;
	mov.f32 	%f7180, 0f3F800000;
	setp.eq.s32 	%p105, %r942, 4;
	@%p105 bra 	$L__BB4_125;

	setp.ne.s32 	%p106, %r942, 1;
	mov.f32 	%f7179, %f7178;
	mov.f32 	%f7181, %f7178;
	mov.f32 	%f7182, %f7178;
	mov.f32 	%f7183, %f7180;
	mov.f32 	%f7184, %f7178;
	mov.f32 	%f7185, %f7178;
	mov.f32 	%f7186, %f7180;
	mov.f32 	%f7187, %f7178;
	mov.f32 	%f7188, %f7178;
	mov.f32 	%f7189, %f7178;
	@%p106 bra 	$L__BB4_135;

$L__BB4_125:
	@%p105 bra 	$L__BB4_127;
	bra.uni 	$L__BB4_126;

$L__BB4_127:
	// begin inline asm
	call (%rd1968), _optix_get_instance_transform_from_handle, (%rd766);
	// end inline asm
	bra.uni 	$L__BB4_128;

$L__BB4_130:
	// begin inline asm
	call (%rd781), _optix_get_srt_motion_transform_from_handle, (%rd766);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd783, %rd781;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r956,%r957,%r958,%r959}, [%rd783];
	// end inline asm
	add.s64 	%rd787, %rd781, 16;
	// begin inline asm
	cvta.to.global.u64 %rd786, %rd787;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r960,%r961,%r962,%r963}, [%rd786];
	// end inline asm
	add.s64 	%rd790, %rd781, 32;
	// begin inline asm
	cvta.to.global.u64 %rd789, %rd790;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r964,%r965,%r966,%r967}, [%rd789];
	// end inline asm
	add.s64 	%rd793, %rd781, 48;
	// begin inline asm
	cvta.to.global.u64 %rd792, %rd793;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r968,%r969,%r970,%r971}, [%rd792];
	// end inline asm
	add.s64 	%rd796, %rd781, 64;
	// begin inline asm
	cvta.to.global.u64 %rd795, %rd796;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r972,%r973,%r974,%r975}, [%rd795];
	// end inline asm
	add.s64 	%rd799, %rd781, 80;
	// begin inline asm
	cvta.to.global.u64 %rd798, %rd799;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r976,%r977,%r978,%r979}, [%rd798];
	// end inline asm
	add.s64 	%rd802, %rd781, 96;
	// begin inline asm
	cvta.to.global.u64 %rd801, %rd802;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r980,%r981,%r982,%r983}, [%rd801];
	// end inline asm
	add.s64 	%rd805, %rd781, 112;
	// begin inline asm
	cvta.to.global.u64 %rd804, %rd805;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r984,%r985,%r986,%r987}, [%rd804];
	// end inline asm
	add.s64 	%rd808, %rd781, 128;
	// begin inline asm
	cvta.to.global.u64 %rd807, %rd808;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r988,%r989,%r990,%r991}, [%rd807];
	// end inline asm
	add.s64 	%rd811, %rd781, 144;
	// begin inline asm
	cvta.to.global.u64 %rd810, %rd811;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r992,%r993,%r994,%r995}, [%rd810];
	// end inline asm
	mov.b32 	%f3856, %r959;
	mov.b32 	%f3857, %r960;
	and.b32  	%r1012, %r958, 65535;
	add.s32 	%r1013, %r1012, -1;
	cvt.rn.f32.s32 	%f3858, %r1013;
	sub.ftz.f32 	%f3859, %f3841, %f3856;
	sub.ftz.f32 	%f3860, %f3857, %f3856;
	div.approx.ftz.f32 	%f3861, %f3859, %f3860;
	mul.ftz.f32 	%f3862, %f3861, %f3858;
	min.ftz.f32 	%f3863, %f3858, %f3862;
	mov.f32 	%f3864, 0f00000000;
	max.ftz.f32 	%f3865, %f3864, %f3863;
	setp.num.ftz.f32 	%p109, %f3865, %f3865;
	selp.f32 	%f3866, %f3865, 0f00000000, %p109;
	cvt.rmi.ftz.f32.f32 	%f3867, %f3866;
	add.ftz.f32 	%f3868, %f3858, 0fBF800000;
	min.ftz.f32 	%f3869, %f3867, %f3868;
	sub.ftz.f32 	%f885, %f3866, %f3869;
	cvt.rzi.ftz.s32.f32 	%r1014, %f3869;
	mul.wide.s32 	%rd825, %r1014, 64;
	add.s64 	%rd814, %rd790, %rd825;
	// begin inline asm
	cvta.to.global.u64 %rd813, %rd814;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r996,%r997,%r998,%r999}, [%rd813];
	// end inline asm
	mov.b32 	%f7162, %r996;
	mov.b32 	%f7163, %r997;
	mov.b32 	%f7164, %r998;
	mov.b32 	%f7165, %r999;
	add.s64 	%rd817, %rd814, 16;
	// begin inline asm
	cvta.to.global.u64 %rd816, %rd817;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1000,%r1001,%r1002,%r1003}, [%rd816];
	// end inline asm
	mov.b32 	%f7166, %r1000;
	mov.b32 	%f7167, %r1001;
	mov.b32 	%f7168, %r1002;
	mov.b32 	%f7169, %r1003;
	add.s64 	%rd820, %rd814, 32;
	// begin inline asm
	cvta.to.global.u64 %rd819, %rd820;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1004,%r1005,%r1006,%r1007}, [%rd819];
	// end inline asm
	mov.b32 	%f7170, %r1004;
	mov.b32 	%f7171, %r1005;
	mov.b32 	%f7172, %r1006;
	mov.b32 	%f7173, %r1007;
	add.s64 	%rd823, %rd814, 48;
	// begin inline asm
	cvta.to.global.u64 %rd822, %rd823;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1008,%r1009,%r1010,%r1011}, [%rd822];
	// end inline asm
	mov.b32 	%f7174, %r1008;
	mov.b32 	%f7175, %r1009;
	mov.b32 	%f7176, %r1010;
	mov.b32 	%f7177, %r1011;
	setp.leu.ftz.f32 	%p110, %f885, 0f00000000;
	@%p110 bra 	$L__BB4_132;

	mov.f32 	%f3870, 0f3F800000;
	sub.ftz.f32 	%f3871, %f3870, %f885;
	add.s64 	%rd827, %rd814, 64;
	// begin inline asm
	cvta.to.global.u64 %rd826, %rd827;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1015,%r1016,%r1017,%r1018}, [%rd826];
	// end inline asm
	mov.b32 	%f3872, %r1015;
	mov.b32 	%f3873, %r1016;
	mov.b32 	%f3874, %r1017;
	mov.b32 	%f3875, %r1018;
	mul.ftz.f32 	%f3876, %f885, %f3872;
	mul.ftz.f32 	%f3877, %f885, %f3873;
	mul.ftz.f32 	%f3878, %f885, %f3874;
	mul.ftz.f32 	%f3879, %f885, %f3875;
	fma.rn.ftz.f32 	%f7162, %f3871, %f7162, %f3876;
	fma.rn.ftz.f32 	%f7163, %f3871, %f7163, %f3877;
	fma.rn.ftz.f32 	%f7164, %f3871, %f7164, %f3878;
	fma.rn.ftz.f32 	%f7165, %f3871, %f7165, %f3879;
	add.s64 	%rd830, %rd814, 80;
	// begin inline asm
	cvta.to.global.u64 %rd829, %rd830;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1019,%r1020,%r1021,%r1022}, [%rd829];
	// end inline asm
	mov.b32 	%f3880, %r1019;
	mov.b32 	%f3881, %r1020;
	mov.b32 	%f3882, %r1021;
	mov.b32 	%f3883, %r1022;
	mul.ftz.f32 	%f3884, %f885, %f3880;
	mul.ftz.f32 	%f3885, %f885, %f3881;
	mul.ftz.f32 	%f3886, %f885, %f3882;
	mul.ftz.f32 	%f3887, %f885, %f3883;
	fma.rn.ftz.f32 	%f7166, %f3871, %f7166, %f3884;
	fma.rn.ftz.f32 	%f7167, %f3871, %f7167, %f3885;
	fma.rn.ftz.f32 	%f7168, %f3871, %f7168, %f3886;
	fma.rn.ftz.f32 	%f7169, %f3871, %f7169, %f3887;
	add.s64 	%rd833, %rd814, 96;
	// begin inline asm
	cvta.to.global.u64 %rd832, %rd833;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1023,%r1024,%r1025,%r1026}, [%rd832];
	// end inline asm
	mov.b32 	%f3888, %r1023;
	mov.b32 	%f3889, %r1024;
	mov.b32 	%f3890, %r1025;
	mov.b32 	%f3891, %r1026;
	mul.ftz.f32 	%f3892, %f885, %f3888;
	mul.ftz.f32 	%f3893, %f885, %f3889;
	mul.ftz.f32 	%f3894, %f885, %f3890;
	mul.ftz.f32 	%f3895, %f885, %f3891;
	fma.rn.ftz.f32 	%f7170, %f3871, %f7170, %f3892;
	fma.rn.ftz.f32 	%f3896, %f3871, %f7171, %f3893;
	fma.rn.ftz.f32 	%f3897, %f3871, %f7172, %f3894;
	fma.rn.ftz.f32 	%f3898, %f3871, %f7173, %f3895;
	add.s64 	%rd836, %rd814, 112;
	// begin inline asm
	cvta.to.global.u64 %rd835, %rd836;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1027,%r1028,%r1029,%r1030}, [%rd835];
	// end inline asm
	mov.b32 	%f3899, %r1027;
	mov.b32 	%f3900, %r1028;
	mov.b32 	%f3901, %r1029;
	mov.b32 	%f3902, %r1030;
	mul.ftz.f32 	%f3903, %f885, %f3899;
	mul.ftz.f32 	%f3904, %f885, %f3900;
	mul.ftz.f32 	%f3905, %f885, %f3901;
	mul.ftz.f32 	%f3906, %f885, %f3902;
	fma.rn.ftz.f32 	%f3907, %f3871, %f7174, %f3903;
	fma.rn.ftz.f32 	%f7175, %f3871, %f7175, %f3904;
	fma.rn.ftz.f32 	%f7176, %f3871, %f7176, %f3905;
	fma.rn.ftz.f32 	%f7177, %f3871, %f7177, %f3906;
	mul.ftz.f32 	%f3908, %f3897, %f3897;
	fma.rn.ftz.f32 	%f3909, %f3896, %f3896, %f3908;
	fma.rn.ftz.f32 	%f3910, %f3898, %f3898, %f3909;
	fma.rn.ftz.f32 	%f3911, %f3907, %f3907, %f3910;
	rsqrt.approx.ftz.f32 	%f3912, %f3911;
	mul.ftz.f32 	%f7171, %f3896, %f3912;
	mul.ftz.f32 	%f7172, %f3897, %f3912;
	mul.ftz.f32 	%f7173, %f3898, %f3912;
	mul.ftz.f32 	%f7174, %f3912, %f3907;

$L__BB4_132:
	mul.ftz.f32 	%f3913, %f7172, %f7172;
	mul.ftz.f32 	%f3914, %f7171, %f7171;
	sub.ftz.f32 	%f3915, %f3914, %f3913;
	mul.ftz.f32 	%f3916, %f7173, %f7173;
	sub.ftz.f32 	%f3917, %f3915, %f3916;
	fma.rn.ftz.f32 	%f3918, %f7174, %f7174, %f3917;
	mul.ftz.f32 	%f3919, %f7173, %f7174;
	mul.ftz.f32 	%f3920, %f7171, %f7172;
	sub.ftz.f32 	%f3921, %f3920, %f3919;
	add.ftz.f32 	%f3922, %f3921, %f3921;
	mul.ftz.f32 	%f3923, %f7172, %f7174;
	mul.ftz.f32 	%f3924, %f7171, %f7173;
	add.ftz.f32 	%f3925, %f3924, %f3923;
	add.ftz.f32 	%f3926, %f3925, %f3925;
	add.ftz.f32 	%f3927, %f3920, %f3919;
	add.ftz.f32 	%f3928, %f3927, %f3927;
	sub.ftz.f32 	%f3929, %f3913, %f3914;
	sub.ftz.f32 	%f3930, %f3929, %f3916;
	fma.rn.ftz.f32 	%f3931, %f7174, %f7174, %f3930;
	mul.ftz.f32 	%f3932, %f7171, %f7174;
	mul.ftz.f32 	%f3933, %f7172, %f7173;
	sub.ftz.f32 	%f3934, %f3933, %f3932;
	add.ftz.f32 	%f3935, %f3934, %f3934;
	sub.ftz.f32 	%f3936, %f3924, %f3923;
	add.ftz.f32 	%f3937, %f3936, %f3936;
	add.ftz.f32 	%f3938, %f3933, %f3932;
	add.ftz.f32 	%f3939, %f3938, %f3938;
	neg.ftz.f32 	%f3940, %f3914;
	sub.ftz.f32 	%f3941, %f3940, %f3913;
	add.ftz.f32 	%f3942, %f3941, %f3916;
	fma.rn.ftz.f32 	%f3943, %f7174, %f7174, %f3942;
	mul.ftz.f32 	%f3944, %f7168, %f3922;
	fma.rn.ftz.f32 	%f3945, %f7165, %f3918, %f3944;
	fma.rn.ftz.f32 	%f3946, %f7170, %f3926, %f3945;
	add.ftz.f32 	%f7189, %f7175, %f3946;
	mul.ftz.f32 	%f3947, %f7165, %f3928;
	fma.rn.ftz.f32 	%f3948, %f7168, %f3931, %f3947;
	fma.rn.ftz.f32 	%f3949, %f7170, %f3935, %f3948;
	add.ftz.f32 	%f7185, %f7176, %f3949;
	mul.ftz.f32 	%f3950, %f7168, %f3939;
	fma.rn.ftz.f32 	%f3951, %f7165, %f3937, %f3950;
	fma.rn.ftz.f32 	%f3952, %f7170, %f3943, %f3951;
	add.ftz.f32 	%f7181, %f7177, %f3952;
	mul.ftz.f32 	%f3953, %f7167, %f3922;
	fma.rn.ftz.f32 	%f3954, %f7164, %f3918, %f3953;
	fma.rn.ftz.f32 	%f7188, %f7169, %f3926, %f3954;
	mul.ftz.f32 	%f3955, %f7164, %f3928;
	fma.rn.ftz.f32 	%f3956, %f7167, %f3931, %f3955;
	fma.rn.ftz.f32 	%f7184, %f7169, %f3935, %f3956;
	mul.ftz.f32 	%f3957, %f7167, %f3939;
	fma.rn.ftz.f32 	%f3958, %f7164, %f3937, %f3957;
	fma.rn.ftz.f32 	%f7180, %f7169, %f3943, %f3958;
	mul.ftz.f32 	%f3959, %f7166, %f3922;
	fma.rn.ftz.f32 	%f7187, %f7163, %f3918, %f3959;
	mul.ftz.f32 	%f3960, %f7163, %f3928;
	fma.rn.ftz.f32 	%f7183, %f7166, %f3931, %f3960;
	mul.ftz.f32 	%f3961, %f7166, %f3939;
	fma.rn.ftz.f32 	%f7179, %f7163, %f3937, %f3961;
	mul.ftz.f32 	%f7186, %f7162, %f3918;
	mul.ftz.f32 	%f7182, %f7162, %f3928;
	mul.ftz.f32 	%f7178, %f7162, %f3937;
	bra.uni 	$L__BB4_135;

$L__BB4_126:
	// begin inline asm
	call (%rd768), _optix_get_static_transform_from_handle, (%rd766);
	// end inline asm
	add.s64 	%rd1968, %rd768, 16;

$L__BB4_128:
	// begin inline asm
	cvta.to.global.u64 %rd772, %rd1968;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r944,%r945,%r946,%r947}, [%rd772];
	// end inline asm
	mov.b32 	%f7186, %r944;
	mov.b32 	%f7187, %r945;
	mov.b32 	%f7188, %r946;
	mov.b32 	%f7189, %r947;
	add.s64 	%rd776, %rd1968, 16;
	// begin inline asm
	cvta.to.global.u64 %rd775, %rd776;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r948,%r949,%r950,%r951}, [%rd775];
	// end inline asm
	mov.b32 	%f7182, %r948;
	mov.b32 	%f7183, %r949;
	mov.b32 	%f7184, %r950;
	mov.b32 	%f7185, %r951;
	add.s64 	%rd779, %rd1968, 32;
	// begin inline asm
	cvta.to.global.u64 %rd778, %rd779;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r952,%r953,%r954,%r955}, [%rd778];
	// end inline asm
	mov.b32 	%f7178, %r952;
	mov.b32 	%f7179, %r953;
	mov.b32 	%f7180, %r954;
	mov.b32 	%f7181, %r955;

$L__BB4_135:
	setp.eq.s32 	%p113, %r2503, %r940;
	@%p113 bra 	$L__BB4_137;

	mul.ftz.f32 	%f4002, %f7157, %f7187;
	fma.rn.ftz.f32 	%f4003, %f7153, %f7186, %f4002;
	fma.rn.ftz.f32 	%f983, %f7161, %f7188, %f4003;
	mul.ftz.f32 	%f4004, %f7156, %f7187;
	fma.rn.ftz.f32 	%f4005, %f7152, %f7186, %f4004;
	fma.rn.ftz.f32 	%f984, %f7160, %f7188, %f4005;
	mul.ftz.f32 	%f4006, %f7155, %f7187;
	fma.rn.ftz.f32 	%f4007, %f7151, %f7186, %f4006;
	fma.rn.ftz.f32 	%f985, %f7159, %f7188, %f4007;
	mul.ftz.f32 	%f4008, %f7154, %f7187;
	fma.rn.ftz.f32 	%f4009, %f7150, %f7186, %f4008;
	fma.rn.ftz.f32 	%f4010, %f7158, %f7188, %f4009;
	add.ftz.f32 	%f7189, %f7189, %f4010;
	mul.ftz.f32 	%f4011, %f7157, %f7183;
	fma.rn.ftz.f32 	%f4012, %f7153, %f7182, %f4011;
	fma.rn.ftz.f32 	%f987, %f7161, %f7184, %f4012;
	mul.ftz.f32 	%f4013, %f7156, %f7183;
	fma.rn.ftz.f32 	%f4014, %f7152, %f7182, %f4013;
	fma.rn.ftz.f32 	%f988, %f7160, %f7184, %f4014;
	mul.ftz.f32 	%f4015, %f7155, %f7183;
	fma.rn.ftz.f32 	%f4016, %f7151, %f7182, %f4015;
	fma.rn.ftz.f32 	%f989, %f7159, %f7184, %f4016;
	mul.ftz.f32 	%f4017, %f7154, %f7183;
	fma.rn.ftz.f32 	%f4018, %f7150, %f7182, %f4017;
	fma.rn.ftz.f32 	%f4019, %f7158, %f7184, %f4018;
	add.ftz.f32 	%f7185, %f7185, %f4019;
	mul.ftz.f32 	%f4020, %f7157, %f7179;
	fma.rn.ftz.f32 	%f4021, %f7153, %f7178, %f4020;
	fma.rn.ftz.f32 	%f991, %f7161, %f7180, %f4021;
	mul.ftz.f32 	%f4022, %f7156, %f7179;
	fma.rn.ftz.f32 	%f4023, %f7152, %f7178, %f4022;
	fma.rn.ftz.f32 	%f992, %f7160, %f7180, %f4023;
	mul.ftz.f32 	%f4024, %f7155, %f7179;
	fma.rn.ftz.f32 	%f4025, %f7151, %f7178, %f4024;
	fma.rn.ftz.f32 	%f993, %f7159, %f7180, %f4025;
	mul.ftz.f32 	%f4026, %f7154, %f7179;
	fma.rn.ftz.f32 	%f4027, %f7150, %f7178, %f4026;
	fma.rn.ftz.f32 	%f4028, %f7158, %f7180, %f4027;
	add.ftz.f32 	%f7181, %f7181, %f4028;
	mov.f32 	%f7178, %f991;
	mov.f32 	%f7179, %f992;
	mov.f32 	%f7180, %f993;
	mov.f32 	%f7182, %f987;
	mov.f32 	%f7183, %f988;
	mov.f32 	%f7184, %f989;
	mov.f32 	%f7186, %f983;
	mov.f32 	%f7187, %f984;
	mov.f32 	%f7188, %f985;

$L__BB4_137:
	setp.gt.s32 	%p114, %r2503, 1;
	mov.u32 	%r2503, %r941;
	mov.f32 	%f7150, %f7189;
	mov.f32 	%f7151, %f7188;
	mov.f32 	%f7152, %f7187;
	mov.f32 	%f7153, %f7186;
	mov.f32 	%f7154, %f7185;
	mov.f32 	%f7155, %f7184;
	mov.f32 	%f7156, %f7183;
	mov.f32 	%f7157, %f7182;
	mov.f32 	%f7158, %f7181;
	mov.f32 	%f7159, %f7180;
	mov.f32 	%f7160, %f7179;
	mov.f32 	%f7161, %f7178;
	@%p114 bra 	$L__BB4_122;

$L__BB4_138:
	mul.ftz.f32 	%f4029, %f7215, %f7187;
	fma.rn.ftz.f32 	%f4030, %f7214, %f7186, %f4029;
	fma.rn.ftz.f32 	%f4031, %f7216, %f7188, %f4030;
	mul.ftz.f32 	%f4032, %f7215, %f7183;
	fma.rn.ftz.f32 	%f4033, %f7214, %f7182, %f4032;
	fma.rn.ftz.f32 	%f4034, %f7216, %f7184, %f4033;
	mul.ftz.f32 	%f4035, %f7215, %f7179;
	fma.rn.ftz.f32 	%f4036, %f7214, %f7178, %f4035;
	fma.rn.ftz.f32 	%f4037, %f7216, %f7180, %f4036;
	add.ftz.f32 	%f7216, %f7181, %f4037;
	add.ftz.f32 	%f7215, %f7185, %f4034;
	add.ftz.f32 	%f7214, %f7189, %f4031;

$L__BB4_139:
	mul.wide.u32 	%rd885, %r29, 44;
	add.s64 	%rd886, %rd54, %rd885;
	ld.f32 	%f7281, [%rd886];
	ld.f32 	%f7282, [%rd886+4];
	ld.f32 	%f7283, [%rd886+8];
	// begin inline asm
	call (%r1090), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p115, %r1090, 0;
	@%p115 bra 	$L__BB4_159;

	// begin inline asm
	call (%r1091), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f4038), _optix_get_ray_time, ();
	// end inline asm
	setp.lt.s32 	%p116, %r1091, 1;
	@%p116 bra 	$L__BB4_158;

	mov.u32 	%r2504, %r1091;

$L__BB4_142:
	.pragma "nounroll";
	add.s32 	%r1092, %r2504, -1;
	// begin inline asm
	call (%rd887), _optix_get_transform_list_handle, (%r1092);
	// end inline asm
	// begin inline asm
	call (%r1093), _optix_get_transform_type_from_handle, (%rd887);
	// end inline asm
	or.b32  	%r1094, %r1093, 1;
	setp.eq.s32 	%p117, %r1094, 3;
	@%p117 bra 	$L__BB4_149;
	bra.uni 	$L__BB4_143;

$L__BB4_149:
	setp.eq.s32 	%p121, %r1093, 2;
	@%p121 bra 	$L__BB4_153;
	bra.uni 	$L__BB4_150;

$L__BB4_153:
	// begin inline asm
	call (%rd959), _optix_get_matrix_motion_transform_from_handle, (%rd887);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd961, %rd959;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1182,%r1183,%r1184,%r1185}, [%rd961];
	// end inline asm
	add.s64 	%rd965, %rd959, 16;
	// begin inline asm
	cvta.to.global.u64 %rd964, %rd965;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1186,%r1187,%r1188,%r1189}, [%rd964];
	// end inline asm
	add.s64 	%rd968, %rd959, 32;
	// begin inline asm
	cvta.to.global.u64 %rd967, %rd968;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1190,%r1191,%r1192,%r1193}, [%rd967];
	// end inline asm
	add.s64 	%rd971, %rd959, 48;
	// begin inline asm
	cvta.to.global.u64 %rd970, %rd971;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1194,%r1195,%r1196,%r1197}, [%rd970];
	// end inline asm
	add.s64 	%rd974, %rd959, 64;
	// begin inline asm
	cvta.to.global.u64 %rd973, %rd974;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1198,%r1199,%r1200,%r1201}, [%rd973];
	// end inline asm
	add.s64 	%rd977, %rd959, 80;
	// begin inline asm
	cvta.to.global.u64 %rd976, %rd977;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1202,%r1203,%r1204,%r1205}, [%rd976];
	// end inline asm
	add.s64 	%rd980, %rd959, 96;
	// begin inline asm
	cvta.to.global.u64 %rd979, %rd980;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1206,%r1207,%r1208,%r1209}, [%rd979];
	// end inline asm
	add.s64 	%rd983, %rd959, 112;
	// begin inline asm
	cvta.to.global.u64 %rd982, %rd983;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1210,%r1211,%r1212,%r1213}, [%rd982];
	// end inline asm
	mov.b32 	%f4159, %r1185;
	mov.b32 	%f4160, %r1186;
	and.b32  	%r1226, %r1184, 65535;
	add.s32 	%r1227, %r1226, -1;
	cvt.rn.f32.s32 	%f4161, %r1227;
	sub.ftz.f32 	%f4162, %f4038, %f4159;
	sub.ftz.f32 	%f4163, %f4160, %f4159;
	div.approx.ftz.f32 	%f4164, %f4162, %f4163;
	mul.ftz.f32 	%f4165, %f4164, %f4161;
	min.ftz.f32 	%f4166, %f4161, %f4165;
	mov.f32 	%f4167, 0f00000000;
	max.ftz.f32 	%f4168, %f4167, %f4166;
	setp.num.ftz.f32 	%p124, %f4168, %f4168;
	selp.f32 	%f4169, %f4168, 0f00000000, %p124;
	cvt.rmi.ftz.f32.f32 	%f4170, %f4169;
	add.ftz.f32 	%f4171, %f4161, 0fBF800000;
	min.ftz.f32 	%f4172, %f4170, %f4171;
	sub.ftz.f32 	%f1117, %f4169, %f4172;
	cvt.rzi.ftz.s32.f32 	%r1228, %f4172;
	cvt.s64.s32 	%rd68, %r1228;
	mul.wide.s32 	%rd994, %r1228, 48;
	add.s64 	%rd986, %rd968, %rd994;
	// begin inline asm
	cvta.to.global.u64 %rd985, %rd986;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1214,%r1215,%r1216,%r1217}, [%rd985];
	// end inline asm
	mov.b32 	%f7253, %r1214;
	mov.b32 	%f7254, %r1215;
	mov.b32 	%f7255, %r1216;
	mov.b32 	%f7256, %r1217;
	add.s64 	%rd989, %rd986, 16;
	// begin inline asm
	cvta.to.global.u64 %rd988, %rd989;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1218,%r1219,%r1220,%r1221}, [%rd988];
	// end inline asm
	mov.b32 	%f7249, %r1218;
	mov.b32 	%f7250, %r1219;
	mov.b32 	%f7251, %r1220;
	mov.b32 	%f7252, %r1221;
	add.s64 	%rd992, %rd986, 32;
	// begin inline asm
	cvta.to.global.u64 %rd991, %rd992;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1222,%r1223,%r1224,%r1225}, [%rd991];
	// end inline asm
	mov.b32 	%f7245, %r1222;
	mov.b32 	%f7246, %r1223;
	mov.b32 	%f7247, %r1224;
	mov.b32 	%f7248, %r1225;
	setp.leu.ftz.f32 	%p125, %f1117, 0f00000000;
	@%p125 bra 	$L__BB4_155;

	mov.f32 	%f4173, 0f3F800000;
	sub.ftz.f32 	%f4174, %f4173, %f1117;
	mul.lo.s64 	%rd1004, %rd68, 48;
	add.s64 	%rd1005, %rd959, %rd1004;
	add.s64 	%rd996, %rd1005, 80;
	// begin inline asm
	cvta.to.global.u64 %rd995, %rd996;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1229,%r1230,%r1231,%r1232}, [%rd995];
	// end inline asm
	mov.b32 	%f4175, %r1229;
	mov.b32 	%f4176, %r1230;
	mov.b32 	%f4177, %r1231;
	mov.b32 	%f4178, %r1232;
	mul.ftz.f32 	%f4179, %f1117, %f4175;
	mul.ftz.f32 	%f4180, %f1117, %f4176;
	mul.ftz.f32 	%f4181, %f1117, %f4177;
	mul.ftz.f32 	%f4182, %f1117, %f4178;
	fma.rn.ftz.f32 	%f7253, %f4174, %f7253, %f4179;
	fma.rn.ftz.f32 	%f7254, %f4174, %f7254, %f4180;
	fma.rn.ftz.f32 	%f7255, %f4174, %f7255, %f4181;
	fma.rn.ftz.f32 	%f7256, %f4174, %f7256, %f4182;
	add.s64 	%rd999, %rd1005, 96;
	// begin inline asm
	cvta.to.global.u64 %rd998, %rd999;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1233,%r1234,%r1235,%r1236}, [%rd998];
	// end inline asm
	mov.b32 	%f4183, %r1233;
	mov.b32 	%f4184, %r1234;
	mov.b32 	%f4185, %r1235;
	mov.b32 	%f4186, %r1236;
	mul.ftz.f32 	%f4187, %f1117, %f4183;
	mul.ftz.f32 	%f4188, %f1117, %f4184;
	mul.ftz.f32 	%f4189, %f1117, %f4185;
	mul.ftz.f32 	%f4190, %f1117, %f4186;
	fma.rn.ftz.f32 	%f7249, %f4174, %f7249, %f4187;
	fma.rn.ftz.f32 	%f7250, %f4174, %f7250, %f4188;
	fma.rn.ftz.f32 	%f7251, %f4174, %f7251, %f4189;
	fma.rn.ftz.f32 	%f7252, %f4174, %f7252, %f4190;
	add.s64 	%rd1002, %rd1005, 112;
	// begin inline asm
	cvta.to.global.u64 %rd1001, %rd1002;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1237,%r1238,%r1239,%r1240}, [%rd1001];
	// end inline asm
	mov.b32 	%f4191, %r1237;
	mov.b32 	%f4192, %r1238;
	mov.b32 	%f4193, %r1239;
	mov.b32 	%f4194, %r1240;
	mul.ftz.f32 	%f4195, %f1117, %f4191;
	mul.ftz.f32 	%f4196, %f1117, %f4192;
	mul.ftz.f32 	%f4197, %f1117, %f4193;
	mul.ftz.f32 	%f4198, %f1117, %f4194;
	fma.rn.ftz.f32 	%f7245, %f4174, %f7245, %f4195;
	fma.rn.ftz.f32 	%f7246, %f4174, %f7246, %f4196;
	fma.rn.ftz.f32 	%f7247, %f4174, %f7247, %f4197;
	fma.rn.ftz.f32 	%f7248, %f4174, %f7248, %f4198;
	bra.uni 	$L__BB4_155;

$L__BB4_143:
	mov.f32 	%f7245, 0f00000000;
	mov.f32 	%f7247, 0f3F800000;
	setp.eq.s32 	%p118, %r1093, 4;
	@%p118 bra 	$L__BB4_145;

	setp.ne.s32 	%p119, %r1093, 1;
	mov.f32 	%f7246, %f7245;
	mov.f32 	%f7248, %f7245;
	mov.f32 	%f7249, %f7245;
	mov.f32 	%f7250, %f7247;
	mov.f32 	%f7251, %f7245;
	mov.f32 	%f7252, %f7245;
	mov.f32 	%f7253, %f7247;
	mov.f32 	%f7254, %f7245;
	mov.f32 	%f7255, %f7245;
	mov.f32 	%f7256, %f7245;
	@%p119 bra 	$L__BB4_155;

$L__BB4_145:
	@%p118 bra 	$L__BB4_147;
	bra.uni 	$L__BB4_146;

$L__BB4_147:
	// begin inline asm
	call (%rd1969), _optix_get_instance_transform_from_handle, (%rd887);
	// end inline asm
	bra.uni 	$L__BB4_148;

$L__BB4_150:
	// begin inline asm
	call (%rd902), _optix_get_srt_motion_transform_from_handle, (%rd887);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd904, %rd902;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1107,%r1108,%r1109,%r1110}, [%rd904];
	// end inline asm
	add.s64 	%rd908, %rd902, 16;
	// begin inline asm
	cvta.to.global.u64 %rd907, %rd908;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1111,%r1112,%r1113,%r1114}, [%rd907];
	// end inline asm
	add.s64 	%rd911, %rd902, 32;
	// begin inline asm
	cvta.to.global.u64 %rd910, %rd911;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1115,%r1116,%r1117,%r1118}, [%rd910];
	// end inline asm
	add.s64 	%rd914, %rd902, 48;
	// begin inline asm
	cvta.to.global.u64 %rd913, %rd914;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1119,%r1120,%r1121,%r1122}, [%rd913];
	// end inline asm
	add.s64 	%rd917, %rd902, 64;
	// begin inline asm
	cvta.to.global.u64 %rd916, %rd917;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1123,%r1124,%r1125,%r1126}, [%rd916];
	// end inline asm
	add.s64 	%rd920, %rd902, 80;
	// begin inline asm
	cvta.to.global.u64 %rd919, %rd920;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1127,%r1128,%r1129,%r1130}, [%rd919];
	// end inline asm
	add.s64 	%rd923, %rd902, 96;
	// begin inline asm
	cvta.to.global.u64 %rd922, %rd923;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1131,%r1132,%r1133,%r1134}, [%rd922];
	// end inline asm
	add.s64 	%rd926, %rd902, 112;
	// begin inline asm
	cvta.to.global.u64 %rd925, %rd926;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1135,%r1136,%r1137,%r1138}, [%rd925];
	// end inline asm
	add.s64 	%rd929, %rd902, 128;
	// begin inline asm
	cvta.to.global.u64 %rd928, %rd929;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1139,%r1140,%r1141,%r1142}, [%rd928];
	// end inline asm
	add.s64 	%rd932, %rd902, 144;
	// begin inline asm
	cvta.to.global.u64 %rd931, %rd932;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1143,%r1144,%r1145,%r1146}, [%rd931];
	// end inline asm
	mov.b32 	%f4053, %r1110;
	mov.b32 	%f4054, %r1111;
	and.b32  	%r1163, %r1109, 65535;
	add.s32 	%r1164, %r1163, -1;
	cvt.rn.f32.s32 	%f4055, %r1164;
	sub.ftz.f32 	%f4056, %f4038, %f4053;
	sub.ftz.f32 	%f4057, %f4054, %f4053;
	div.approx.ftz.f32 	%f4058, %f4056, %f4057;
	mul.ftz.f32 	%f4059, %f4058, %f4055;
	min.ftz.f32 	%f4060, %f4055, %f4059;
	mov.f32 	%f4061, 0f00000000;
	max.ftz.f32 	%f4062, %f4061, %f4060;
	setp.num.ftz.f32 	%p122, %f4062, %f4062;
	selp.f32 	%f4063, %f4062, 0f00000000, %p122;
	cvt.rmi.ftz.f32.f32 	%f4064, %f4063;
	add.ftz.f32 	%f4065, %f4055, 0fBF800000;
	min.ftz.f32 	%f4066, %f4064, %f4065;
	sub.ftz.f32 	%f1056, %f4063, %f4066;
	cvt.rzi.ftz.s32.f32 	%r1165, %f4066;
	mul.wide.s32 	%rd946, %r1165, 64;
	add.s64 	%rd935, %rd911, %rd946;
	// begin inline asm
	cvta.to.global.u64 %rd934, %rd935;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1147,%r1148,%r1149,%r1150}, [%rd934];
	// end inline asm
	mov.b32 	%f7229, %r1147;
	mov.b32 	%f7230, %r1148;
	mov.b32 	%f7231, %r1149;
	mov.b32 	%f7232, %r1150;
	add.s64 	%rd938, %rd935, 16;
	// begin inline asm
	cvta.to.global.u64 %rd937, %rd938;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1151,%r1152,%r1153,%r1154}, [%rd937];
	// end inline asm
	mov.b32 	%f7233, %r1151;
	mov.b32 	%f7234, %r1152;
	mov.b32 	%f7235, %r1153;
	mov.b32 	%f7236, %r1154;
	add.s64 	%rd941, %rd935, 32;
	// begin inline asm
	cvta.to.global.u64 %rd940, %rd941;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1155,%r1156,%r1157,%r1158}, [%rd940];
	// end inline asm
	mov.b32 	%f7237, %r1155;
	mov.b32 	%f7238, %r1156;
	mov.b32 	%f7239, %r1157;
	mov.b32 	%f7240, %r1158;
	add.s64 	%rd944, %rd935, 48;
	// begin inline asm
	cvta.to.global.u64 %rd943, %rd944;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1159,%r1160,%r1161,%r1162}, [%rd943];
	// end inline asm
	mov.b32 	%f7241, %r1159;
	mov.b32 	%f7242, %r1160;
	mov.b32 	%f7243, %r1161;
	mov.b32 	%f7244, %r1162;
	setp.leu.ftz.f32 	%p123, %f1056, 0f00000000;
	@%p123 bra 	$L__BB4_152;

	mov.f32 	%f4067, 0f3F800000;
	sub.ftz.f32 	%f4068, %f4067, %f1056;
	add.s64 	%rd948, %rd935, 64;
	// begin inline asm
	cvta.to.global.u64 %rd947, %rd948;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1166,%r1167,%r1168,%r1169}, [%rd947];
	// end inline asm
	mov.b32 	%f4069, %r1166;
	mov.b32 	%f4070, %r1167;
	mov.b32 	%f4071, %r1168;
	mov.b32 	%f4072, %r1169;
	mul.ftz.f32 	%f4073, %f1056, %f4069;
	mul.ftz.f32 	%f4074, %f1056, %f4070;
	mul.ftz.f32 	%f4075, %f1056, %f4071;
	mul.ftz.f32 	%f4076, %f1056, %f4072;
	fma.rn.ftz.f32 	%f7229, %f4068, %f7229, %f4073;
	fma.rn.ftz.f32 	%f7230, %f4068, %f7230, %f4074;
	fma.rn.ftz.f32 	%f7231, %f4068, %f7231, %f4075;
	fma.rn.ftz.f32 	%f7232, %f4068, %f7232, %f4076;
	add.s64 	%rd951, %rd935, 80;
	// begin inline asm
	cvta.to.global.u64 %rd950, %rd951;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1170,%r1171,%r1172,%r1173}, [%rd950];
	// end inline asm
	mov.b32 	%f4077, %r1170;
	mov.b32 	%f4078, %r1171;
	mov.b32 	%f4079, %r1172;
	mov.b32 	%f4080, %r1173;
	mul.ftz.f32 	%f4081, %f1056, %f4077;
	mul.ftz.f32 	%f4082, %f1056, %f4078;
	mul.ftz.f32 	%f4083, %f1056, %f4079;
	mul.ftz.f32 	%f4084, %f1056, %f4080;
	fma.rn.ftz.f32 	%f7233, %f4068, %f7233, %f4081;
	fma.rn.ftz.f32 	%f7234, %f4068, %f7234, %f4082;
	fma.rn.ftz.f32 	%f7235, %f4068, %f7235, %f4083;
	fma.rn.ftz.f32 	%f7236, %f4068, %f7236, %f4084;
	add.s64 	%rd954, %rd935, 96;
	// begin inline asm
	cvta.to.global.u64 %rd953, %rd954;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1174,%r1175,%r1176,%r1177}, [%rd953];
	// end inline asm
	mov.b32 	%f4085, %r1174;
	mov.b32 	%f4086, %r1175;
	mov.b32 	%f4087, %r1176;
	mov.b32 	%f4088, %r1177;
	mul.ftz.f32 	%f4089, %f1056, %f4085;
	mul.ftz.f32 	%f4090, %f1056, %f4086;
	mul.ftz.f32 	%f4091, %f1056, %f4087;
	mul.ftz.f32 	%f4092, %f1056, %f4088;
	fma.rn.ftz.f32 	%f7237, %f4068, %f7237, %f4089;
	fma.rn.ftz.f32 	%f4093, %f4068, %f7238, %f4090;
	fma.rn.ftz.f32 	%f4094, %f4068, %f7239, %f4091;
	fma.rn.ftz.f32 	%f4095, %f4068, %f7240, %f4092;
	add.s64 	%rd957, %rd935, 112;
	// begin inline asm
	cvta.to.global.u64 %rd956, %rd957;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1178,%r1179,%r1180,%r1181}, [%rd956];
	// end inline asm
	mov.b32 	%f4096, %r1178;
	mov.b32 	%f4097, %r1179;
	mov.b32 	%f4098, %r1180;
	mov.b32 	%f4099, %r1181;
	mul.ftz.f32 	%f4100, %f1056, %f4096;
	mul.ftz.f32 	%f4101, %f1056, %f4097;
	mul.ftz.f32 	%f4102, %f1056, %f4098;
	mul.ftz.f32 	%f4103, %f1056, %f4099;
	fma.rn.ftz.f32 	%f4104, %f4068, %f7241, %f4100;
	fma.rn.ftz.f32 	%f7242, %f4068, %f7242, %f4101;
	fma.rn.ftz.f32 	%f7243, %f4068, %f7243, %f4102;
	fma.rn.ftz.f32 	%f7244, %f4068, %f7244, %f4103;
	mul.ftz.f32 	%f4105, %f4094, %f4094;
	fma.rn.ftz.f32 	%f4106, %f4093, %f4093, %f4105;
	fma.rn.ftz.f32 	%f4107, %f4095, %f4095, %f4106;
	fma.rn.ftz.f32 	%f4108, %f4104, %f4104, %f4107;
	rsqrt.approx.ftz.f32 	%f4109, %f4108;
	mul.ftz.f32 	%f7238, %f4093, %f4109;
	mul.ftz.f32 	%f7239, %f4094, %f4109;
	mul.ftz.f32 	%f7240, %f4095, %f4109;
	mul.ftz.f32 	%f7241, %f4109, %f4104;

$L__BB4_152:
	mul.ftz.f32 	%f4110, %f7239, %f7239;
	mul.ftz.f32 	%f4111, %f7238, %f7238;
	sub.ftz.f32 	%f4112, %f4111, %f4110;
	mul.ftz.f32 	%f4113, %f7240, %f7240;
	sub.ftz.f32 	%f4114, %f4112, %f4113;
	fma.rn.ftz.f32 	%f4115, %f7241, %f7241, %f4114;
	mul.ftz.f32 	%f4116, %f7240, %f7241;
	mul.ftz.f32 	%f4117, %f7238, %f7239;
	sub.ftz.f32 	%f4118, %f4117, %f4116;
	add.ftz.f32 	%f4119, %f4118, %f4118;
	mul.ftz.f32 	%f4120, %f7239, %f7241;
	mul.ftz.f32 	%f4121, %f7238, %f7240;
	add.ftz.f32 	%f4122, %f4121, %f4120;
	add.ftz.f32 	%f4123, %f4122, %f4122;
	add.ftz.f32 	%f4124, %f4117, %f4116;
	add.ftz.f32 	%f4125, %f4124, %f4124;
	sub.ftz.f32 	%f4126, %f4110, %f4111;
	sub.ftz.f32 	%f4127, %f4126, %f4113;
	fma.rn.ftz.f32 	%f4128, %f7241, %f7241, %f4127;
	mul.ftz.f32 	%f4129, %f7238, %f7241;
	mul.ftz.f32 	%f4130, %f7239, %f7240;
	sub.ftz.f32 	%f4131, %f4130, %f4129;
	add.ftz.f32 	%f4132, %f4131, %f4131;
	sub.ftz.f32 	%f4133, %f4121, %f4120;
	add.ftz.f32 	%f4134, %f4133, %f4133;
	add.ftz.f32 	%f4135, %f4130, %f4129;
	add.ftz.f32 	%f4136, %f4135, %f4135;
	neg.ftz.f32 	%f4137, %f4111;
	sub.ftz.f32 	%f4138, %f4137, %f4110;
	add.ftz.f32 	%f4139, %f4138, %f4113;
	fma.rn.ftz.f32 	%f4140, %f7241, %f7241, %f4139;
	mul.ftz.f32 	%f4141, %f7235, %f4119;
	fma.rn.ftz.f32 	%f4142, %f7232, %f4115, %f4141;
	fma.rn.ftz.f32 	%f4143, %f7237, %f4123, %f4142;
	add.ftz.f32 	%f7256, %f7242, %f4143;
	mul.ftz.f32 	%f4144, %f7232, %f4125;
	fma.rn.ftz.f32 	%f4145, %f7235, %f4128, %f4144;
	fma.rn.ftz.f32 	%f4146, %f7237, %f4132, %f4145;
	add.ftz.f32 	%f7252, %f7243, %f4146;
	mul.ftz.f32 	%f4147, %f7235, %f4136;
	fma.rn.ftz.f32 	%f4148, %f7232, %f4134, %f4147;
	fma.rn.ftz.f32 	%f4149, %f7237, %f4140, %f4148;
	add.ftz.f32 	%f7248, %f7244, %f4149;
	mul.ftz.f32 	%f4150, %f7234, %f4119;
	fma.rn.ftz.f32 	%f4151, %f7231, %f4115, %f4150;
	fma.rn.ftz.f32 	%f7255, %f7236, %f4123, %f4151;
	mul.ftz.f32 	%f4152, %f7231, %f4125;
	fma.rn.ftz.f32 	%f4153, %f7234, %f4128, %f4152;
	fma.rn.ftz.f32 	%f7251, %f7236, %f4132, %f4153;
	mul.ftz.f32 	%f4154, %f7234, %f4136;
	fma.rn.ftz.f32 	%f4155, %f7231, %f4134, %f4154;
	fma.rn.ftz.f32 	%f7247, %f7236, %f4140, %f4155;
	mul.ftz.f32 	%f4156, %f7233, %f4119;
	fma.rn.ftz.f32 	%f7254, %f7230, %f4115, %f4156;
	mul.ftz.f32 	%f4157, %f7230, %f4125;
	fma.rn.ftz.f32 	%f7250, %f7233, %f4128, %f4157;
	mul.ftz.f32 	%f4158, %f7233, %f4136;
	fma.rn.ftz.f32 	%f7246, %f7230, %f4134, %f4158;
	mul.ftz.f32 	%f7253, %f7229, %f4115;
	mul.ftz.f32 	%f7249, %f7229, %f4125;
	mul.ftz.f32 	%f7245, %f7229, %f4134;
	bra.uni 	$L__BB4_155;

$L__BB4_146:
	// begin inline asm
	call (%rd889), _optix_get_static_transform_from_handle, (%rd887);
	// end inline asm
	add.s64 	%rd1969, %rd889, 16;

$L__BB4_148:
	// begin inline asm
	cvta.to.global.u64 %rd893, %rd1969;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1095,%r1096,%r1097,%r1098}, [%rd893];
	// end inline asm
	mov.b32 	%f7253, %r1095;
	mov.b32 	%f7254, %r1096;
	mov.b32 	%f7255, %r1097;
	mov.b32 	%f7256, %r1098;
	add.s64 	%rd897, %rd1969, 16;
	// begin inline asm
	cvta.to.global.u64 %rd896, %rd897;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1099,%r1100,%r1101,%r1102}, [%rd896];
	// end inline asm
	mov.b32 	%f7249, %r1099;
	mov.b32 	%f7250, %r1100;
	mov.b32 	%f7251, %r1101;
	mov.b32 	%f7252, %r1102;
	add.s64 	%rd900, %rd1969, 32;
	// begin inline asm
	cvta.to.global.u64 %rd899, %rd900;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1103,%r1104,%r1105,%r1106}, [%rd899];
	// end inline asm
	mov.b32 	%f7245, %r1103;
	mov.b32 	%f7246, %r1104;
	mov.b32 	%f7247, %r1105;
	mov.b32 	%f7248, %r1106;

$L__BB4_155:
	setp.eq.s32 	%p126, %r2504, %r1091;
	@%p126 bra 	$L__BB4_157;

	mul.ftz.f32 	%f4199, %f7224, %f7254;
	fma.rn.ftz.f32 	%f4200, %f7220, %f7253, %f4199;
	fma.rn.ftz.f32 	%f1154, %f7228, %f7255, %f4200;
	mul.ftz.f32 	%f4201, %f7223, %f7254;
	fma.rn.ftz.f32 	%f4202, %f7219, %f7253, %f4201;
	fma.rn.ftz.f32 	%f1155, %f7227, %f7255, %f4202;
	mul.ftz.f32 	%f4203, %f7222, %f7254;
	fma.rn.ftz.f32 	%f4204, %f7218, %f7253, %f4203;
	fma.rn.ftz.f32 	%f1156, %f7226, %f7255, %f4204;
	mul.ftz.f32 	%f4205, %f7221, %f7254;
	fma.rn.ftz.f32 	%f4206, %f7217, %f7253, %f4205;
	fma.rn.ftz.f32 	%f4207, %f7225, %f7255, %f4206;
	add.ftz.f32 	%f7256, %f7256, %f4207;
	mul.ftz.f32 	%f4208, %f7224, %f7250;
	fma.rn.ftz.f32 	%f4209, %f7220, %f7249, %f4208;
	fma.rn.ftz.f32 	%f1158, %f7228, %f7251, %f4209;
	mul.ftz.f32 	%f4210, %f7223, %f7250;
	fma.rn.ftz.f32 	%f4211, %f7219, %f7249, %f4210;
	fma.rn.ftz.f32 	%f1159, %f7227, %f7251, %f4211;
	mul.ftz.f32 	%f4212, %f7222, %f7250;
	fma.rn.ftz.f32 	%f4213, %f7218, %f7249, %f4212;
	fma.rn.ftz.f32 	%f1160, %f7226, %f7251, %f4213;
	mul.ftz.f32 	%f4214, %f7221, %f7250;
	fma.rn.ftz.f32 	%f4215, %f7217, %f7249, %f4214;
	fma.rn.ftz.f32 	%f4216, %f7225, %f7251, %f4215;
	add.ftz.f32 	%f7252, %f7252, %f4216;
	mul.ftz.f32 	%f4217, %f7224, %f7246;
	fma.rn.ftz.f32 	%f4218, %f7220, %f7245, %f4217;
	fma.rn.ftz.f32 	%f1162, %f7228, %f7247, %f4218;
	mul.ftz.f32 	%f4219, %f7223, %f7246;
	fma.rn.ftz.f32 	%f4220, %f7219, %f7245, %f4219;
	fma.rn.ftz.f32 	%f1163, %f7227, %f7247, %f4220;
	mul.ftz.f32 	%f4221, %f7222, %f7246;
	fma.rn.ftz.f32 	%f4222, %f7218, %f7245, %f4221;
	fma.rn.ftz.f32 	%f1164, %f7226, %f7247, %f4222;
	mul.ftz.f32 	%f4223, %f7221, %f7246;
	fma.rn.ftz.f32 	%f4224, %f7217, %f7245, %f4223;
	fma.rn.ftz.f32 	%f4225, %f7225, %f7247, %f4224;
	add.ftz.f32 	%f7248, %f7248, %f4225;
	mov.f32 	%f7245, %f1162;
	mov.f32 	%f7246, %f1163;
	mov.f32 	%f7247, %f1164;
	mov.f32 	%f7249, %f1158;
	mov.f32 	%f7250, %f1159;
	mov.f32 	%f7251, %f1160;
	mov.f32 	%f7253, %f1154;
	mov.f32 	%f7254, %f1155;
	mov.f32 	%f7255, %f1156;

$L__BB4_157:
	setp.gt.s32 	%p127, %r2504, 1;
	mov.u32 	%r2504, %r1092;
	mov.f32 	%f7217, %f7256;
	mov.f32 	%f7218, %f7255;
	mov.f32 	%f7219, %f7254;
	mov.f32 	%f7220, %f7253;
	mov.f32 	%f7221, %f7252;
	mov.f32 	%f7222, %f7251;
	mov.f32 	%f7223, %f7250;
	mov.f32 	%f7224, %f7249;
	mov.f32 	%f7225, %f7248;
	mov.f32 	%f7226, %f7247;
	mov.f32 	%f7227, %f7246;
	mov.f32 	%f7228, %f7245;
	@%p127 bra 	$L__BB4_142;

$L__BB4_158:
	mul.ftz.f32 	%f4226, %f7282, %f7254;
	fma.rn.ftz.f32 	%f4227, %f7281, %f7253, %f4226;
	fma.rn.ftz.f32 	%f4228, %f7283, %f7255, %f4227;
	mul.ftz.f32 	%f4229, %f7282, %f7250;
	fma.rn.ftz.f32 	%f4230, %f7281, %f7249, %f4229;
	fma.rn.ftz.f32 	%f4231, %f7283, %f7251, %f4230;
	mul.ftz.f32 	%f4232, %f7282, %f7246;
	fma.rn.ftz.f32 	%f4233, %f7281, %f7245, %f4232;
	fma.rn.ftz.f32 	%f4234, %f7283, %f7247, %f4233;
	add.ftz.f32 	%f7283, %f7248, %f4234;
	add.ftz.f32 	%f7282, %f7252, %f4231;
	add.ftz.f32 	%f7281, %f7256, %f4228;

$L__BB4_159:
	mul.wide.u32 	%rd1006, %r30, 44;
	add.s64 	%rd1007, %rd54, %rd1006;
	ld.f32 	%f7348, [%rd1007];
	ld.f32 	%f7349, [%rd1007+4];
	ld.f32 	%f7350, [%rd1007+8];
	// begin inline asm
	call (%r1241), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p128, %r1241, 0;
	@%p128 bra 	$L__BB4_179;

	// begin inline asm
	call (%r1242), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f4235), _optix_get_ray_time, ();
	// end inline asm
	setp.lt.s32 	%p129, %r1242, 1;
	@%p129 bra 	$L__BB4_178;

	mov.u32 	%r2505, %r1242;

$L__BB4_162:
	.pragma "nounroll";
	add.s32 	%r1243, %r2505, -1;
	// begin inline asm
	call (%rd1008), _optix_get_transform_list_handle, (%r1243);
	// end inline asm
	// begin inline asm
	call (%r1244), _optix_get_transform_type_from_handle, (%rd1008);
	// end inline asm
	or.b32  	%r1245, %r1244, 1;
	setp.eq.s32 	%p130, %r1245, 3;
	@%p130 bra 	$L__BB4_169;
	bra.uni 	$L__BB4_163;

$L__BB4_169:
	setp.eq.s32 	%p134, %r1244, 2;
	@%p134 bra 	$L__BB4_173;
	bra.uni 	$L__BB4_170;

$L__BB4_173:
	// begin inline asm
	call (%rd1080), _optix_get_matrix_motion_transform_from_handle, (%rd1008);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd1082, %rd1080;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1333,%r1334,%r1335,%r1336}, [%rd1082];
	// end inline asm
	add.s64 	%rd1086, %rd1080, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1085, %rd1086;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1337,%r1338,%r1339,%r1340}, [%rd1085];
	// end inline asm
	add.s64 	%rd1089, %rd1080, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1088, %rd1089;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1341,%r1342,%r1343,%r1344}, [%rd1088];
	// end inline asm
	add.s64 	%rd1092, %rd1080, 48;
	// begin inline asm
	cvta.to.global.u64 %rd1091, %rd1092;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1345,%r1346,%r1347,%r1348}, [%rd1091];
	// end inline asm
	add.s64 	%rd1095, %rd1080, 64;
	// begin inline asm
	cvta.to.global.u64 %rd1094, %rd1095;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1349,%r1350,%r1351,%r1352}, [%rd1094];
	// end inline asm
	add.s64 	%rd1098, %rd1080, 80;
	// begin inline asm
	cvta.to.global.u64 %rd1097, %rd1098;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1353,%r1354,%r1355,%r1356}, [%rd1097];
	// end inline asm
	add.s64 	%rd1101, %rd1080, 96;
	// begin inline asm
	cvta.to.global.u64 %rd1100, %rd1101;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1357,%r1358,%r1359,%r1360}, [%rd1100];
	// end inline asm
	add.s64 	%rd1104, %rd1080, 112;
	// begin inline asm
	cvta.to.global.u64 %rd1103, %rd1104;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1361,%r1362,%r1363,%r1364}, [%rd1103];
	// end inline asm
	mov.b32 	%f4356, %r1336;
	mov.b32 	%f4357, %r1337;
	and.b32  	%r1377, %r1335, 65535;
	add.s32 	%r1378, %r1377, -1;
	cvt.rn.f32.s32 	%f4358, %r1378;
	sub.ftz.f32 	%f4359, %f4235, %f4356;
	sub.ftz.f32 	%f4360, %f4357, %f4356;
	div.approx.ftz.f32 	%f4361, %f4359, %f4360;
	mul.ftz.f32 	%f4362, %f4361, %f4358;
	min.ftz.f32 	%f4363, %f4358, %f4362;
	mov.f32 	%f4364, 0f00000000;
	max.ftz.f32 	%f4365, %f4364, %f4363;
	setp.num.ftz.f32 	%p137, %f4365, %f4365;
	selp.f32 	%f4366, %f4365, 0f00000000, %p137;
	cvt.rmi.ftz.f32.f32 	%f4367, %f4366;
	add.ftz.f32 	%f4368, %f4358, 0fBF800000;
	min.ftz.f32 	%f4369, %f4367, %f4368;
	sub.ftz.f32 	%f1288, %f4366, %f4369;
	cvt.rzi.ftz.s32.f32 	%r1379, %f4369;
	cvt.s64.s32 	%rd75, %r1379;
	mul.wide.s32 	%rd1115, %r1379, 48;
	add.s64 	%rd1107, %rd1089, %rd1115;
	// begin inline asm
	cvta.to.global.u64 %rd1106, %rd1107;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1365,%r1366,%r1367,%r1368}, [%rd1106];
	// end inline asm
	mov.b32 	%f7320, %r1365;
	mov.b32 	%f7321, %r1366;
	mov.b32 	%f7322, %r1367;
	mov.b32 	%f7323, %r1368;
	add.s64 	%rd1110, %rd1107, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1109, %rd1110;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1369,%r1370,%r1371,%r1372}, [%rd1109];
	// end inline asm
	mov.b32 	%f7316, %r1369;
	mov.b32 	%f7317, %r1370;
	mov.b32 	%f7318, %r1371;
	mov.b32 	%f7319, %r1372;
	add.s64 	%rd1113, %rd1107, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1112, %rd1113;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1373,%r1374,%r1375,%r1376}, [%rd1112];
	// end inline asm
	mov.b32 	%f7312, %r1373;
	mov.b32 	%f7313, %r1374;
	mov.b32 	%f7314, %r1375;
	mov.b32 	%f7315, %r1376;
	setp.leu.ftz.f32 	%p138, %f1288, 0f00000000;
	@%p138 bra 	$L__BB4_175;

	mov.f32 	%f4370, 0f3F800000;
	sub.ftz.f32 	%f4371, %f4370, %f1288;
	mul.lo.s64 	%rd1125, %rd75, 48;
	add.s64 	%rd1126, %rd1080, %rd1125;
	add.s64 	%rd1117, %rd1126, 80;
	// begin inline asm
	cvta.to.global.u64 %rd1116, %rd1117;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1380,%r1381,%r1382,%r1383}, [%rd1116];
	// end inline asm
	mov.b32 	%f4372, %r1380;
	mov.b32 	%f4373, %r1381;
	mov.b32 	%f4374, %r1382;
	mov.b32 	%f4375, %r1383;
	mul.ftz.f32 	%f4376, %f1288, %f4372;
	mul.ftz.f32 	%f4377, %f1288, %f4373;
	mul.ftz.f32 	%f4378, %f1288, %f4374;
	mul.ftz.f32 	%f4379, %f1288, %f4375;
	fma.rn.ftz.f32 	%f7320, %f4371, %f7320, %f4376;
	fma.rn.ftz.f32 	%f7321, %f4371, %f7321, %f4377;
	fma.rn.ftz.f32 	%f7322, %f4371, %f7322, %f4378;
	fma.rn.ftz.f32 	%f7323, %f4371, %f7323, %f4379;
	add.s64 	%rd1120, %rd1126, 96;
	// begin inline asm
	cvta.to.global.u64 %rd1119, %rd1120;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1384,%r1385,%r1386,%r1387}, [%rd1119];
	// end inline asm
	mov.b32 	%f4380, %r1384;
	mov.b32 	%f4381, %r1385;
	mov.b32 	%f4382, %r1386;
	mov.b32 	%f4383, %r1387;
	mul.ftz.f32 	%f4384, %f1288, %f4380;
	mul.ftz.f32 	%f4385, %f1288, %f4381;
	mul.ftz.f32 	%f4386, %f1288, %f4382;
	mul.ftz.f32 	%f4387, %f1288, %f4383;
	fma.rn.ftz.f32 	%f7316, %f4371, %f7316, %f4384;
	fma.rn.ftz.f32 	%f7317, %f4371, %f7317, %f4385;
	fma.rn.ftz.f32 	%f7318, %f4371, %f7318, %f4386;
	fma.rn.ftz.f32 	%f7319, %f4371, %f7319, %f4387;
	add.s64 	%rd1123, %rd1126, 112;
	// begin inline asm
	cvta.to.global.u64 %rd1122, %rd1123;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1388,%r1389,%r1390,%r1391}, [%rd1122];
	// end inline asm
	mov.b32 	%f4388, %r1388;
	mov.b32 	%f4389, %r1389;
	mov.b32 	%f4390, %r1390;
	mov.b32 	%f4391, %r1391;
	mul.ftz.f32 	%f4392, %f1288, %f4388;
	mul.ftz.f32 	%f4393, %f1288, %f4389;
	mul.ftz.f32 	%f4394, %f1288, %f4390;
	mul.ftz.f32 	%f4395, %f1288, %f4391;
	fma.rn.ftz.f32 	%f7312, %f4371, %f7312, %f4392;
	fma.rn.ftz.f32 	%f7313, %f4371, %f7313, %f4393;
	fma.rn.ftz.f32 	%f7314, %f4371, %f7314, %f4394;
	fma.rn.ftz.f32 	%f7315, %f4371, %f7315, %f4395;
	bra.uni 	$L__BB4_175;

$L__BB4_163:
	mov.f32 	%f7312, 0f00000000;
	mov.f32 	%f7314, 0f3F800000;
	setp.eq.s32 	%p131, %r1244, 4;
	@%p131 bra 	$L__BB4_165;

	setp.ne.s32 	%p132, %r1244, 1;
	mov.f32 	%f7313, %f7312;
	mov.f32 	%f7315, %f7312;
	mov.f32 	%f7316, %f7312;
	mov.f32 	%f7317, %f7314;
	mov.f32 	%f7318, %f7312;
	mov.f32 	%f7319, %f7312;
	mov.f32 	%f7320, %f7314;
	mov.f32 	%f7321, %f7312;
	mov.f32 	%f7322, %f7312;
	mov.f32 	%f7323, %f7312;
	@%p132 bra 	$L__BB4_175;

$L__BB4_165:
	@%p131 bra 	$L__BB4_167;
	bra.uni 	$L__BB4_166;

$L__BB4_167:
	// begin inline asm
	call (%rd1970), _optix_get_instance_transform_from_handle, (%rd1008);
	// end inline asm
	bra.uni 	$L__BB4_168;

$L__BB4_170:
	// begin inline asm
	call (%rd1023), _optix_get_srt_motion_transform_from_handle, (%rd1008);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd1025, %rd1023;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1258,%r1259,%r1260,%r1261}, [%rd1025];
	// end inline asm
	add.s64 	%rd1029, %rd1023, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1028, %rd1029;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1262,%r1263,%r1264,%r1265}, [%rd1028];
	// end inline asm
	add.s64 	%rd1032, %rd1023, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1031, %rd1032;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1266,%r1267,%r1268,%r1269}, [%rd1031];
	// end inline asm
	add.s64 	%rd1035, %rd1023, 48;
	// begin inline asm
	cvta.to.global.u64 %rd1034, %rd1035;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1270,%r1271,%r1272,%r1273}, [%rd1034];
	// end inline asm
	add.s64 	%rd1038, %rd1023, 64;
	// begin inline asm
	cvta.to.global.u64 %rd1037, %rd1038;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1274,%r1275,%r1276,%r1277}, [%rd1037];
	// end inline asm
	add.s64 	%rd1041, %rd1023, 80;
	// begin inline asm
	cvta.to.global.u64 %rd1040, %rd1041;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1278,%r1279,%r1280,%r1281}, [%rd1040];
	// end inline asm
	add.s64 	%rd1044, %rd1023, 96;
	// begin inline asm
	cvta.to.global.u64 %rd1043, %rd1044;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1282,%r1283,%r1284,%r1285}, [%rd1043];
	// end inline asm
	add.s64 	%rd1047, %rd1023, 112;
	// begin inline asm
	cvta.to.global.u64 %rd1046, %rd1047;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1286,%r1287,%r1288,%r1289}, [%rd1046];
	// end inline asm
	add.s64 	%rd1050, %rd1023, 128;
	// begin inline asm
	cvta.to.global.u64 %rd1049, %rd1050;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1290,%r1291,%r1292,%r1293}, [%rd1049];
	// end inline asm
	add.s64 	%rd1053, %rd1023, 144;
	// begin inline asm
	cvta.to.global.u64 %rd1052, %rd1053;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1294,%r1295,%r1296,%r1297}, [%rd1052];
	// end inline asm
	mov.b32 	%f4250, %r1261;
	mov.b32 	%f4251, %r1262;
	and.b32  	%r1314, %r1260, 65535;
	add.s32 	%r1315, %r1314, -1;
	cvt.rn.f32.s32 	%f4252, %r1315;
	sub.ftz.f32 	%f4253, %f4235, %f4250;
	sub.ftz.f32 	%f4254, %f4251, %f4250;
	div.approx.ftz.f32 	%f4255, %f4253, %f4254;
	mul.ftz.f32 	%f4256, %f4255, %f4252;
	min.ftz.f32 	%f4257, %f4252, %f4256;
	mov.f32 	%f4258, 0f00000000;
	max.ftz.f32 	%f4259, %f4258, %f4257;
	setp.num.ftz.f32 	%p135, %f4259, %f4259;
	selp.f32 	%f4260, %f4259, 0f00000000, %p135;
	cvt.rmi.ftz.f32.f32 	%f4261, %f4260;
	add.ftz.f32 	%f4262, %f4252, 0fBF800000;
	min.ftz.f32 	%f4263, %f4261, %f4262;
	sub.ftz.f32 	%f1227, %f4260, %f4263;
	cvt.rzi.ftz.s32.f32 	%r1316, %f4263;
	mul.wide.s32 	%rd1067, %r1316, 64;
	add.s64 	%rd1056, %rd1032, %rd1067;
	// begin inline asm
	cvta.to.global.u64 %rd1055, %rd1056;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1298,%r1299,%r1300,%r1301}, [%rd1055];
	// end inline asm
	mov.b32 	%f7296, %r1298;
	mov.b32 	%f7297, %r1299;
	mov.b32 	%f7298, %r1300;
	mov.b32 	%f7299, %r1301;
	add.s64 	%rd1059, %rd1056, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1058, %rd1059;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1302,%r1303,%r1304,%r1305}, [%rd1058];
	// end inline asm
	mov.b32 	%f7300, %r1302;
	mov.b32 	%f7301, %r1303;
	mov.b32 	%f7302, %r1304;
	mov.b32 	%f7303, %r1305;
	add.s64 	%rd1062, %rd1056, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1061, %rd1062;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1306,%r1307,%r1308,%r1309}, [%rd1061];
	// end inline asm
	mov.b32 	%f7304, %r1306;
	mov.b32 	%f7305, %r1307;
	mov.b32 	%f7306, %r1308;
	mov.b32 	%f7307, %r1309;
	add.s64 	%rd1065, %rd1056, 48;
	// begin inline asm
	cvta.to.global.u64 %rd1064, %rd1065;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1310,%r1311,%r1312,%r1313}, [%rd1064];
	// end inline asm
	mov.b32 	%f7308, %r1310;
	mov.b32 	%f7309, %r1311;
	mov.b32 	%f7310, %r1312;
	mov.b32 	%f7311, %r1313;
	setp.leu.ftz.f32 	%p136, %f1227, 0f00000000;
	@%p136 bra 	$L__BB4_172;

	mov.f32 	%f4264, 0f3F800000;
	sub.ftz.f32 	%f4265, %f4264, %f1227;
	add.s64 	%rd1069, %rd1056, 64;
	// begin inline asm
	cvta.to.global.u64 %rd1068, %rd1069;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1317,%r1318,%r1319,%r1320}, [%rd1068];
	// end inline asm
	mov.b32 	%f4266, %r1317;
	mov.b32 	%f4267, %r1318;
	mov.b32 	%f4268, %r1319;
	mov.b32 	%f4269, %r1320;
	mul.ftz.f32 	%f4270, %f1227, %f4266;
	mul.ftz.f32 	%f4271, %f1227, %f4267;
	mul.ftz.f32 	%f4272, %f1227, %f4268;
	mul.ftz.f32 	%f4273, %f1227, %f4269;
	fma.rn.ftz.f32 	%f7296, %f4265, %f7296, %f4270;
	fma.rn.ftz.f32 	%f7297, %f4265, %f7297, %f4271;
	fma.rn.ftz.f32 	%f7298, %f4265, %f7298, %f4272;
	fma.rn.ftz.f32 	%f7299, %f4265, %f7299, %f4273;
	add.s64 	%rd1072, %rd1056, 80;
	// begin inline asm
	cvta.to.global.u64 %rd1071, %rd1072;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1321,%r1322,%r1323,%r1324}, [%rd1071];
	// end inline asm
	mov.b32 	%f4274, %r1321;
	mov.b32 	%f4275, %r1322;
	mov.b32 	%f4276, %r1323;
	mov.b32 	%f4277, %r1324;
	mul.ftz.f32 	%f4278, %f1227, %f4274;
	mul.ftz.f32 	%f4279, %f1227, %f4275;
	mul.ftz.f32 	%f4280, %f1227, %f4276;
	mul.ftz.f32 	%f4281, %f1227, %f4277;
	fma.rn.ftz.f32 	%f7300, %f4265, %f7300, %f4278;
	fma.rn.ftz.f32 	%f7301, %f4265, %f7301, %f4279;
	fma.rn.ftz.f32 	%f7302, %f4265, %f7302, %f4280;
	fma.rn.ftz.f32 	%f7303, %f4265, %f7303, %f4281;
	add.s64 	%rd1075, %rd1056, 96;
	// begin inline asm
	cvta.to.global.u64 %rd1074, %rd1075;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1325,%r1326,%r1327,%r1328}, [%rd1074];
	// end inline asm
	mov.b32 	%f4282, %r1325;
	mov.b32 	%f4283, %r1326;
	mov.b32 	%f4284, %r1327;
	mov.b32 	%f4285, %r1328;
	mul.ftz.f32 	%f4286, %f1227, %f4282;
	mul.ftz.f32 	%f4287, %f1227, %f4283;
	mul.ftz.f32 	%f4288, %f1227, %f4284;
	mul.ftz.f32 	%f4289, %f1227, %f4285;
	fma.rn.ftz.f32 	%f7304, %f4265, %f7304, %f4286;
	fma.rn.ftz.f32 	%f4290, %f4265, %f7305, %f4287;
	fma.rn.ftz.f32 	%f4291, %f4265, %f7306, %f4288;
	fma.rn.ftz.f32 	%f4292, %f4265, %f7307, %f4289;
	add.s64 	%rd1078, %rd1056, 112;
	// begin inline asm
	cvta.to.global.u64 %rd1077, %rd1078;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1329,%r1330,%r1331,%r1332}, [%rd1077];
	// end inline asm
	mov.b32 	%f4293, %r1329;
	mov.b32 	%f4294, %r1330;
	mov.b32 	%f4295, %r1331;
	mov.b32 	%f4296, %r1332;
	mul.ftz.f32 	%f4297, %f1227, %f4293;
	mul.ftz.f32 	%f4298, %f1227, %f4294;
	mul.ftz.f32 	%f4299, %f1227, %f4295;
	mul.ftz.f32 	%f4300, %f1227, %f4296;
	fma.rn.ftz.f32 	%f4301, %f4265, %f7308, %f4297;
	fma.rn.ftz.f32 	%f7309, %f4265, %f7309, %f4298;
	fma.rn.ftz.f32 	%f7310, %f4265, %f7310, %f4299;
	fma.rn.ftz.f32 	%f7311, %f4265, %f7311, %f4300;
	mul.ftz.f32 	%f4302, %f4291, %f4291;
	fma.rn.ftz.f32 	%f4303, %f4290, %f4290, %f4302;
	fma.rn.ftz.f32 	%f4304, %f4292, %f4292, %f4303;
	fma.rn.ftz.f32 	%f4305, %f4301, %f4301, %f4304;
	rsqrt.approx.ftz.f32 	%f4306, %f4305;
	mul.ftz.f32 	%f7305, %f4290, %f4306;
	mul.ftz.f32 	%f7306, %f4291, %f4306;
	mul.ftz.f32 	%f7307, %f4292, %f4306;
	mul.ftz.f32 	%f7308, %f4306, %f4301;

$L__BB4_172:
	mul.ftz.f32 	%f4307, %f7306, %f7306;
	mul.ftz.f32 	%f4308, %f7305, %f7305;
	sub.ftz.f32 	%f4309, %f4308, %f4307;
	mul.ftz.f32 	%f4310, %f7307, %f7307;
	sub.ftz.f32 	%f4311, %f4309, %f4310;
	fma.rn.ftz.f32 	%f4312, %f7308, %f7308, %f4311;
	mul.ftz.f32 	%f4313, %f7307, %f7308;
	mul.ftz.f32 	%f4314, %f7305, %f7306;
	sub.ftz.f32 	%f4315, %f4314, %f4313;
	add.ftz.f32 	%f4316, %f4315, %f4315;
	mul.ftz.f32 	%f4317, %f7306, %f7308;
	mul.ftz.f32 	%f4318, %f7305, %f7307;
	add.ftz.f32 	%f4319, %f4318, %f4317;
	add.ftz.f32 	%f4320, %f4319, %f4319;
	add.ftz.f32 	%f4321, %f4314, %f4313;
	add.ftz.f32 	%f4322, %f4321, %f4321;
	sub.ftz.f32 	%f4323, %f4307, %f4308;
	sub.ftz.f32 	%f4324, %f4323, %f4310;
	fma.rn.ftz.f32 	%f4325, %f7308, %f7308, %f4324;
	mul.ftz.f32 	%f4326, %f7305, %f7308;
	mul.ftz.f32 	%f4327, %f7306, %f7307;
	sub.ftz.f32 	%f4328, %f4327, %f4326;
	add.ftz.f32 	%f4329, %f4328, %f4328;
	sub.ftz.f32 	%f4330, %f4318, %f4317;
	add.ftz.f32 	%f4331, %f4330, %f4330;
	add.ftz.f32 	%f4332, %f4327, %f4326;
	add.ftz.f32 	%f4333, %f4332, %f4332;
	neg.ftz.f32 	%f4334, %f4308;
	sub.ftz.f32 	%f4335, %f4334, %f4307;
	add.ftz.f32 	%f4336, %f4335, %f4310;
	fma.rn.ftz.f32 	%f4337, %f7308, %f7308, %f4336;
	mul.ftz.f32 	%f4338, %f7302, %f4316;
	fma.rn.ftz.f32 	%f4339, %f7299, %f4312, %f4338;
	fma.rn.ftz.f32 	%f4340, %f7304, %f4320, %f4339;
	add.ftz.f32 	%f7323, %f7309, %f4340;
	mul.ftz.f32 	%f4341, %f7299, %f4322;
	fma.rn.ftz.f32 	%f4342, %f7302, %f4325, %f4341;
	fma.rn.ftz.f32 	%f4343, %f7304, %f4329, %f4342;
	add.ftz.f32 	%f7319, %f7310, %f4343;
	mul.ftz.f32 	%f4344, %f7302, %f4333;
	fma.rn.ftz.f32 	%f4345, %f7299, %f4331, %f4344;
	fma.rn.ftz.f32 	%f4346, %f7304, %f4337, %f4345;
	add.ftz.f32 	%f7315, %f7311, %f4346;
	mul.ftz.f32 	%f4347, %f7301, %f4316;
	fma.rn.ftz.f32 	%f4348, %f7298, %f4312, %f4347;
	fma.rn.ftz.f32 	%f7322, %f7303, %f4320, %f4348;
	mul.ftz.f32 	%f4349, %f7298, %f4322;
	fma.rn.ftz.f32 	%f4350, %f7301, %f4325, %f4349;
	fma.rn.ftz.f32 	%f7318, %f7303, %f4329, %f4350;
	mul.ftz.f32 	%f4351, %f7301, %f4333;
	fma.rn.ftz.f32 	%f4352, %f7298, %f4331, %f4351;
	fma.rn.ftz.f32 	%f7314, %f7303, %f4337, %f4352;
	mul.ftz.f32 	%f4353, %f7300, %f4316;
	fma.rn.ftz.f32 	%f7321, %f7297, %f4312, %f4353;
	mul.ftz.f32 	%f4354, %f7297, %f4322;
	fma.rn.ftz.f32 	%f7317, %f7300, %f4325, %f4354;
	mul.ftz.f32 	%f4355, %f7300, %f4333;
	fma.rn.ftz.f32 	%f7313, %f7297, %f4331, %f4355;
	mul.ftz.f32 	%f7320, %f7296, %f4312;
	mul.ftz.f32 	%f7316, %f7296, %f4322;
	mul.ftz.f32 	%f7312, %f7296, %f4331;
	bra.uni 	$L__BB4_175;

$L__BB4_166:
	// begin inline asm
	call (%rd1010), _optix_get_static_transform_from_handle, (%rd1008);
	// end inline asm
	add.s64 	%rd1970, %rd1010, 16;

$L__BB4_168:
	// begin inline asm
	cvta.to.global.u64 %rd1014, %rd1970;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1246,%r1247,%r1248,%r1249}, [%rd1014];
	// end inline asm
	mov.b32 	%f7320, %r1246;
	mov.b32 	%f7321, %r1247;
	mov.b32 	%f7322, %r1248;
	mov.b32 	%f7323, %r1249;
	add.s64 	%rd1018, %rd1970, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1017, %rd1018;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1250,%r1251,%r1252,%r1253}, [%rd1017];
	// end inline asm
	mov.b32 	%f7316, %r1250;
	mov.b32 	%f7317, %r1251;
	mov.b32 	%f7318, %r1252;
	mov.b32 	%f7319, %r1253;
	add.s64 	%rd1021, %rd1970, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1020, %rd1021;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1254,%r1255,%r1256,%r1257}, [%rd1020];
	// end inline asm
	mov.b32 	%f7312, %r1254;
	mov.b32 	%f7313, %r1255;
	mov.b32 	%f7314, %r1256;
	mov.b32 	%f7315, %r1257;

$L__BB4_175:
	setp.eq.s32 	%p139, %r2505, %r1242;
	@%p139 bra 	$L__BB4_177;

	mul.ftz.f32 	%f4396, %f7291, %f7321;
	fma.rn.ftz.f32 	%f4397, %f7287, %f7320, %f4396;
	fma.rn.ftz.f32 	%f1325, %f7295, %f7322, %f4397;
	mul.ftz.f32 	%f4398, %f7290, %f7321;
	fma.rn.ftz.f32 	%f4399, %f7286, %f7320, %f4398;
	fma.rn.ftz.f32 	%f1326, %f7294, %f7322, %f4399;
	mul.ftz.f32 	%f4400, %f7289, %f7321;
	fma.rn.ftz.f32 	%f4401, %f7285, %f7320, %f4400;
	fma.rn.ftz.f32 	%f1327, %f7293, %f7322, %f4401;
	mul.ftz.f32 	%f4402, %f7288, %f7321;
	fma.rn.ftz.f32 	%f4403, %f7284, %f7320, %f4402;
	fma.rn.ftz.f32 	%f4404, %f7292, %f7322, %f4403;
	add.ftz.f32 	%f7323, %f7323, %f4404;
	mul.ftz.f32 	%f4405, %f7291, %f7317;
	fma.rn.ftz.f32 	%f4406, %f7287, %f7316, %f4405;
	fma.rn.ftz.f32 	%f1329, %f7295, %f7318, %f4406;
	mul.ftz.f32 	%f4407, %f7290, %f7317;
	fma.rn.ftz.f32 	%f4408, %f7286, %f7316, %f4407;
	fma.rn.ftz.f32 	%f1330, %f7294, %f7318, %f4408;
	mul.ftz.f32 	%f4409, %f7289, %f7317;
	fma.rn.ftz.f32 	%f4410, %f7285, %f7316, %f4409;
	fma.rn.ftz.f32 	%f1331, %f7293, %f7318, %f4410;
	mul.ftz.f32 	%f4411, %f7288, %f7317;
	fma.rn.ftz.f32 	%f4412, %f7284, %f7316, %f4411;
	fma.rn.ftz.f32 	%f4413, %f7292, %f7318, %f4412;
	add.ftz.f32 	%f7319, %f7319, %f4413;
	mul.ftz.f32 	%f4414, %f7291, %f7313;
	fma.rn.ftz.f32 	%f4415, %f7287, %f7312, %f4414;
	fma.rn.ftz.f32 	%f1333, %f7295, %f7314, %f4415;
	mul.ftz.f32 	%f4416, %f7290, %f7313;
	fma.rn.ftz.f32 	%f4417, %f7286, %f7312, %f4416;
	fma.rn.ftz.f32 	%f1334, %f7294, %f7314, %f4417;
	mul.ftz.f32 	%f4418, %f7289, %f7313;
	fma.rn.ftz.f32 	%f4419, %f7285, %f7312, %f4418;
	fma.rn.ftz.f32 	%f1335, %f7293, %f7314, %f4419;
	mul.ftz.f32 	%f4420, %f7288, %f7313;
	fma.rn.ftz.f32 	%f4421, %f7284, %f7312, %f4420;
	fma.rn.ftz.f32 	%f4422, %f7292, %f7314, %f4421;
	add.ftz.f32 	%f7315, %f7315, %f4422;
	mov.f32 	%f7312, %f1333;
	mov.f32 	%f7313, %f1334;
	mov.f32 	%f7314, %f1335;
	mov.f32 	%f7316, %f1329;
	mov.f32 	%f7317, %f1330;
	mov.f32 	%f7318, %f1331;
	mov.f32 	%f7320, %f1325;
	mov.f32 	%f7321, %f1326;
	mov.f32 	%f7322, %f1327;

$L__BB4_177:
	setp.gt.s32 	%p140, %r2505, 1;
	mov.u32 	%r2505, %r1243;
	mov.f32 	%f7284, %f7323;
	mov.f32 	%f7285, %f7322;
	mov.f32 	%f7286, %f7321;
	mov.f32 	%f7287, %f7320;
	mov.f32 	%f7288, %f7319;
	mov.f32 	%f7289, %f7318;
	mov.f32 	%f7290, %f7317;
	mov.f32 	%f7291, %f7316;
	mov.f32 	%f7292, %f7315;
	mov.f32 	%f7293, %f7314;
	mov.f32 	%f7294, %f7313;
	mov.f32 	%f7295, %f7312;
	@%p140 bra 	$L__BB4_162;

$L__BB4_178:
	mul.ftz.f32 	%f4423, %f7349, %f7321;
	fma.rn.ftz.f32 	%f4424, %f7348, %f7320, %f4423;
	fma.rn.ftz.f32 	%f4425, %f7350, %f7322, %f4424;
	mul.ftz.f32 	%f4426, %f7349, %f7317;
	fma.rn.ftz.f32 	%f4427, %f7348, %f7316, %f4426;
	fma.rn.ftz.f32 	%f4428, %f7350, %f7318, %f4427;
	mul.ftz.f32 	%f4429, %f7349, %f7313;
	fma.rn.ftz.f32 	%f4430, %f7348, %f7312, %f4429;
	fma.rn.ftz.f32 	%f4431, %f7350, %f7314, %f4430;
	add.ftz.f32 	%f7350, %f7315, %f4431;
	add.ftz.f32 	%f7349, %f7319, %f4428;
	add.ftz.f32 	%f7348, %f7323, %f4425;

$L__BB4_179:
	sub.ftz.f32 	%f4433, %f7348, %f7214;
	sub.ftz.f32 	%f4434, %f7349, %f7215;
	sub.ftz.f32 	%f4435, %f7350, %f7216;
	sub.ftz.f32 	%f4436, %f7282, %f7215;
	mul.ftz.f32 	%f4437, %f4436, %f4435;
	sub.ftz.f32 	%f4438, %f7283, %f7216;
	mul.ftz.f32 	%f4439, %f4438, %f4434;
	sub.ftz.f32 	%f4440, %f4437, %f4439;
	mul.ftz.f32 	%f4441, %f4438, %f4433;
	sub.ftz.f32 	%f4442, %f7281, %f7214;
	mul.ftz.f32 	%f4443, %f4442, %f4435;
	sub.ftz.f32 	%f4444, %f4441, %f4443;
	mul.ftz.f32 	%f4445, %f4442, %f4434;
	mul.ftz.f32 	%f4446, %f4436, %f4433;
	sub.ftz.f32 	%f4447, %f4445, %f4446;
	mul.ftz.f32 	%f4448, %f4444, %f4444;
	fma.rn.ftz.f32 	%f4449, %f4440, %f4440, %f4448;
	fma.rn.ftz.f32 	%f1370, %f4447, %f4447, %f4449;
	// begin inline asm
	call (%r1392), _optix_read_instance_id, ();
	// end inline asm
	ld.const.u64 	%rd76, [plp+256];
	setp.eq.s64 	%p141, %rd76, 0;
	ld.const.f32 	%f1371, [plp+272];
	setp.eq.ftz.f32 	%p142, %f1371, 0f00000000;
	mov.f32 	%f7352, 0f00000000;
	or.pred  	%p143, %p141, %p142;
	mov.f32 	%f7351, %f7352;
	@%p143 bra 	$L__BB4_181;

	cvta.to.global.u64 	%rd1127, %rd76;
	mul.wide.u32 	%rd1128, %r1392, 4;
	add.s64 	%rd1129, %rd1127, %rd1128;
	ld.global.f32 	%f4450, [%rd1129];
	div.approx.ftz.f32 	%f7351, %f4450, %f1371;

$L__BB4_181:
	ld.global.u64 	%rd77, [%rd50+120];
	setp.eq.s64 	%p144, %rd77, 0;
	@%p144 bra 	$L__BB4_184;

	ld.global.f32 	%f1374, [%rd50+136];
	setp.eq.ftz.f32 	%p145, %f1374, 0f00000000;
	@%p145 bra 	$L__BB4_184;

	ld.f32 	%f4453, [%rd77];
	div.approx.ftz.f32 	%f7352, %f4453, %f1374;

$L__BB4_184:
	ld.global.u64 	%rd78, [%rd9+32];
	setp.eq.s64 	%p146, %rd78, 0;
	mov.f32 	%f7353, 0f00000000;
	@%p146 bra 	$L__BB4_187;

	ld.global.f32 	%f1377, [%rd9+48];
	setp.eq.ftz.f32 	%p147, %f1377, 0f00000000;
	@%p147 bra 	$L__BB4_187;

	shl.b64 	%rd1130, %rd10, 2;
	add.s64 	%rd1131, %rd78, %rd1130;
	ld.f32 	%f4456, [%rd1131];
	div.approx.ftz.f32 	%f7353, %f4456, %f1377;

$L__BB4_187:
	mul.ftz.f32 	%f4457, %f7351, %f7352;
	mul.ftz.f32 	%f4458, %f4457, %f7353;
	sqrt.approx.ftz.f32 	%f4459, %f1370;
	mul.ftz.f32 	%f4460, %f4459, 0f3F000000;
	div.approx.ftz.f32 	%f4461, %f4458, %f4460;
	ld.const.u32 	%r1393, [plp+228];
	and.b32  	%r1394, %r1393, 1;
	setp.eq.b32 	%p148, %r1394, 1;
	not.pred 	%p149, %p148;
	ld.const.u64 	%rd1132, [plp+328];
	setp.eq.s64 	%p150, %rd1132, 0;
	or.pred  	%p151, %p149, %p150;
	selp.f32 	%f4462, 0f3F800000, 0f3F000000, %p151;
	mul.ftz.f32 	%f4463, %f4461, %f4462;
	ld.f32 	%f4464, [%rd6+36];
	mul.ftz.f32 	%f4465, %f4464, 0f3A83126F;
	ld.f32 	%f4466, [%rd6+40];
	mul.ftz.f32 	%f4467, %f4466, 0f3A83126F;
	ld.f32 	%f4468, [%rd6+44];
	mul.ftz.f32 	%f4469, %f4468, 0f3A83126F;
	ld.f32 	%f4470, [%rd6+24];
	sub.ftz.f32 	%f4471, %f4470, %f4465;
	ld.f32 	%f4472, [%rd6+28];
	sub.ftz.f32 	%f4473, %f4472, %f4467;
	ld.f32 	%f4474, [%rd6+32];
	sub.ftz.f32 	%f4475, %f4474, %f4469;
	sub.ftz.f32 	%f4476, %f824, %f4471;
	sub.ftz.f32 	%f4477, %f825, %f4473;
	sub.ftz.f32 	%f4478, %f826, %f4475;
	mul.ftz.f32 	%f4479, %f4477, %f4477;
	fma.rn.ftz.f32 	%f4480, %f4476, %f4476, %f4479;
	fma.rn.ftz.f32 	%f4481, %f4478, %f4478, %f4480;
	rsqrt.approx.ftz.f32 	%f4482, %f4481;
	mul.ftz.f32 	%f4483, %f4476, %f4482;
	mul.ftz.f32 	%f4484, %f4477, %f4482;
	mul.ftz.f32 	%f4485, %f4478, %f4482;
	mul.ftz.f32 	%f4486, %f801, %f4484;
	fma.rn.ftz.f32 	%f4487, %f800, %f4483, %f4486;
	fma.rn.ftz.f32 	%f4488, %f802, %f4485, %f4487;
	abs.ftz.f32 	%f4489, %f4488;
	setp.lt.ftz.f32 	%p152, %f4489, 0f358637BD;
	selp.f32 	%f4490, 0f358637BD, %f4489, %p152;
	div.approx.ftz.f32 	%f4491, %f4481, %f4490;
	mul.ftz.f32 	%f4492, %f4463, %f4491;
	ld.f32 	%f4493, [%rd6+48];
	mul.ftz.f32 	%f4494, %f4493, %f4493;
	fma.rn.ftz.f32 	%f4495, %f4492, %f4492, %f4494;
	div.approx.ftz.f32 	%f4496, %f4494, %f4495;
	ld.f32 	%f4497, [%rd6];
	mul.ftz.f32 	%f4498, %f854, %f4497;
	ld.f32 	%f4499, [%rd6+4];
	mul.ftz.f32 	%f4500, %f855, %f4499;
	ld.f32 	%f4501, [%rd6+8];
	mul.ftz.f32 	%f4502, %f856, %f4501;
	ld.f32 	%f4503, [%rd6+12];
	fma.rn.ftz.f32 	%f4504, %f4496, %f4498, %f4503;
	st.f32 	[%rd6+12], %f4504;
	ld.f32 	%f4505, [%rd6+16];
	fma.rn.ftz.f32 	%f4506, %f4496, %f4500, %f4505;
	st.f32 	[%rd6+16], %f4506;
	ld.f32 	%f4507, [%rd6+20];
	fma.rn.ftz.f32 	%f4508, %f4496, %f4502, %f4507;
	st.f32 	[%rd6+20], %f4508;

$L__BB4_190:
	mov.f32 	%f7770, 0f00000000;
	mov.f32 	%f7771, 0f00000000;
	mov.f32 	%f7772, 0f00000000;
	@%p345 bra 	$L__BB4_392;

	ld.const.u32 	%r1395, [plp+228];
	and.b32  	%r1396, %r1395, 1;
	setp.eq.b32 	%p153, %r1396, 1;
	not.pred 	%p154, %p153;
	ld.const.u64 	%rd79, [plp+328];
	setp.eq.s64 	%p155, %rd79, 0;
	or.pred  	%p156, %p154, %p155;
	selp.f32 	%f1383, 0f00000000, 0f3F000000, %p156;
	ld.const.v2.u32 	{%r1397, %r1398}, [plp+280];
	and.b32  	%r1401, %r1398, 1;
	setp.eq.b32 	%p157, %r1401, 1;
	not.pred 	%p158, %p157;
	setp.eq.s32 	%p159, %r1397, 0;
	or.pred  	%p3, %p158, %p159;
	selp.f32 	%f1384, 0f00000000, 0f3F000000, %p3;
	add.ftz.f32 	%f1385, %f1383, %f1384;
	setp.eq.ftz.f32 	%p160, %f1385, 0f00000000;
	@%p160 bra 	$L__BB4_391;

	div.approx.ftz.f32 	%f1386, %f1383, %f1385;
	mov.b64 	%rd1133, {%r2534, %r2533};
	mul.lo.s64 	%rd1134, %rd1133, 6364136223846793005;
	add.s64 	%rd80, %rd1134, 1;
	shr.u64 	%rd1135, %rd1133, 18;
	xor.b64  	%rd1136, %rd1135, %rd1133;
	shr.u64 	%rd1137, %rd1136, 27;
	cvt.u32.u64 	%r1402, %rd1137;
	shr.u64 	%rd1138, %rd1133, 59;
	cvt.u32.u64 	%r1403, %rd1138;
	shf.r.wrap.b32 	%r1404, %r1402, %r1402, %r1403;
	shr.u32 	%r1405, %r1404, 9;
	or.b32  	%r1406, %r1405, 1065353216;
	mov.b32 	%f4530, %r1406;
	add.ftz.f32 	%f4531, %f4530, 0fBF800000;
	setp.lt.ftz.f32 	%p4, %f4531, %f1386;
	div.approx.ftz.f32 	%f1387, %f1384, %f1385;
	setp.gt.ftz.f32 	%p161, %f1386, 0f00000000;
	and.pred  	%p162, %p4, %p161;
	mov.f32 	%f7744, 0f00000000;
	mov.f32 	%f7745, 0f00000000;
	mov.f32 	%f7746, 0f00000000;
	mov.f32 	%f7747, 0f00000000;
	mov.f32 	%f7748, 0f00000000;
	mov.f32 	%f7749, 0f00000000;
	mov.f32 	%f7750, 0f00000000;
	mov.f32 	%f7751, 0f00000000;
	mov.f32 	%f7752, 0f00000000;
	mov.f32 	%f7753, 0f00000000;
	@%p162 bra 	$L__BB4_345;
	bra.uni 	$L__BB4_193;

$L__BB4_345:
	mul.lo.s64 	%rd1905, %rd80, 6364136223846793005;
	add.s64 	%rd1906, %rd1905, 1;
	mul.lo.s64 	%rd1907, %rd80, 7520897724310334953;
	add.s64 	%rd138, %rd1907, 6364136223846793006;
	shr.u64 	%rd1908, %rd1906, 18;
	xor.b64  	%rd1909, %rd1908, %rd1906;
	shr.u64 	%rd1910, %rd1909, 27;
	cvt.u32.u64 	%r2376, %rd1910;
	shr.u64 	%rd1911, %rd1906, 59;
	cvt.u32.u64 	%r2377, %rd1911;
	mov.u32 	%r2526, 0;
	shf.r.wrap.b32 	%r2378, %r2376, %r2376, %r2377;
	shr.u32 	%r2379, %r2378, 9;
	or.b32  	%r2380, %r2379, 1065353216;
	mov.b32 	%f5802, %r2380;
	add.ftz.f32 	%f2381, %f5802, 0fBF800000;
	shr.u64 	%rd1912, %rd138, 18;
	xor.b64  	%rd1913, %rd1912, %rd138;
	shr.u64 	%rd1914, %rd1913, 27;
	cvt.u32.u64 	%r2381, %rd1914;
	shr.u64 	%rd1915, %rd138, 59;
	cvt.u32.u64 	%r2382, %rd1915;
	shf.r.wrap.b32 	%r2383, %r2381, %r2381, %r2382;
	shr.u32 	%r2384, %r2383, 9;
	or.b32  	%r2385, %r2384, 1065353216;
	mov.b32 	%f5803, %r2385;
	add.ftz.f32 	%f2382, %f5803, 0fBF800000;
	ld.const.u32 	%r102, [plp+324];
	setp.eq.s32 	%p265, %r102, 0;
	add.s32 	%r2386, %r102, -1;
	clz.b32 	%r2387, %r2386;
	mov.u32 	%r2388, 32;
	sub.s32 	%r2389, %r2388, %r2387;
	mov.u32 	%r2390, 1;
	shl.b32 	%r2391, %r2390, %r2389;
	shr.u32 	%r2524, %r2391, 1;
	setp.eq.s32 	%p266, %r2524, 0;
	or.pred  	%p267, %p265, %p266;
	ld.const.u64 	%rd1916, [plp+312];
	cvta.to.global.u64 	%rd139, %rd1916;
	@%p267 bra 	$L__BB4_350;

	mov.u32 	%r2526, 0;

$L__BB4_347:
	add.s32 	%r106, %r2524, %r2526;
	setp.ge.u32 	%p268, %r106, %r102;
	@%p268 bra 	$L__BB4_349;

	mul.wide.s32 	%rd1917, %r106, 4;
	add.s64 	%rd1918, %rd139, %rd1917;
	ld.global.f32 	%f5804, [%rd1918];
	setp.le.ftz.f32 	%p269, %f5804, %f2382;
	selp.b32 	%r2526, %r106, %r2526, %p269;

$L__BB4_349:
	shr.u32 	%r2524, %r2524, 1;
	setp.ne.s32 	%p270, %r2524, 0;
	@%p270 bra 	$L__BB4_347;

$L__BB4_350:
	mul.wide.s32 	%rd1919, %r2526, 4;
	add.s64 	%rd1920, %rd139, %rd1919;
	ld.global.f32 	%f5805, [%rd1920];
	sub.ftz.f32 	%f5806, %f2382, %f5805;
	ld.global.f32 	%f5807, [%rd1920+4];
	sub.ftz.f32 	%f5808, %f5807, %f5805;
	div.approx.ftz.f32 	%f5809, %f5806, %f5808;
	ld.const.u64 	%rd1921, [plp+304];
	cvta.to.global.u64 	%rd1922, %rd1921;
	add.s64 	%rd1923, %rd1922, %rd1919;
	ld.global.f32 	%f2383, [%rd1923];
	cvt.rn.f32.s32 	%f5810, %r2526;
	add.ftz.f32 	%f5811, %f5809, %f5810;
	cvt.rn.f32.u32 	%f5812, %r102;
	div.approx.ftz.f32 	%f2384, %f5811, %f5812;
	mul.ftz.f32 	%f5813, %f2384, %f5812;
	cvt.rzi.ftz.u32.f32 	%r2393, %f5813;
	min.u32 	%r2395, %r2393, %r2386;
	ld.const.u64 	%rd1924, [plp+296];
	cvta.to.global.u64 	%rd1925, %rd1924;
	mul.wide.u32 	%rd1926, %r2395, 24;
	add.s64 	%rd1927, %rd1925, %rd1926;
	add.s64 	%rd140, %rd1927, 20;
	ld.global.u32 	%r111, [%rd1927+20];
	setp.eq.s32 	%p271, %r111, 0;
	add.s32 	%r2396, %r111, -1;
	clz.b32 	%r2397, %r2396;
	sub.s32 	%r2399, %r2388, %r2397;
	shl.b32 	%r2401, %r2390, %r2399;
	shr.u32 	%r2528, %r2401, 1;
	setp.eq.s32 	%p272, %r2528, 0;
	mov.u32 	%r2530, 0;
	or.pred  	%p273, %p271, %p272;
	@%p273 bra 	$L__BB4_354;

$L__BB4_351:
	add.s32 	%r115, %r2528, %r2530;
	setp.ge.u32 	%p274, %r115, %r111;
	@%p274 bra 	$L__BB4_353;

	ld.global.u64 	%rd1928, [%rd140+-12];
	mul.wide.s32 	%rd1929, %r115, 4;
	add.s64 	%rd1930, %rd1928, %rd1929;
	ld.f32 	%f5814, [%rd1930];
	setp.le.ftz.f32 	%p275, %f5814, %f2381;
	selp.b32 	%r2530, %r115, %r2530, %p275;

$L__BB4_353:
	shr.u32 	%r2528, %r2528, 1;
	setp.eq.s32 	%p276, %r2528, 0;
	@%p276 bra 	$L__BB4_354;
	bra.uni 	$L__BB4_351;

$L__BB4_354:
	mul.lo.s64 	%rd1931, %rd138, 6364136223846793005;
	add.s64 	%rd1932, %rd1931, 1;
	mov.b64 	{%r2534, %r2533}, %rd1932;
	ld.global.u64 	%rd1933, [%rd140+-12];
	mul.wide.s32 	%rd1934, %r2530, 4;
	add.s64 	%rd1935, %rd1933, %rd1934;
	ld.f32 	%f5825, [%rd1935];
	sub.ftz.f32 	%f5826, %f2381, %f5825;
	ld.f32 	%f5827, [%rd1935+4];
	sub.ftz.f32 	%f5828, %f5827, %f5825;
	div.approx.ftz.f32 	%f5829, %f5826, %f5828;
	ld.global.u64 	%rd1936, [%rd140+-20];
	add.s64 	%rd1937, %rd1936, %rd1934;
	cvt.rn.f32.s32 	%f5830, %r2530;
	add.ftz.f32 	%f5831, %f5829, %f5830;
	cvt.rn.f32.u32 	%f5832, %r111;
	div.approx.ftz.f32 	%f2385, %f5831, %f5832;
	ld.f32 	%f5833, [%rd1937];
	mul.ftz.f32 	%f2386, %f2383, %f5833;
	mul.ftz.f32 	%f2387, %f2384, 0f40490FDB;
	setp.eq.ftz.f32 	%p277, %f2387, 0f00000000;
	mov.f32 	%f7748, 0f00000000;
	mov.f32 	%f7744, 0f00000000;
	mov.f32 	%f7745, 0f00000000;
	mov.f32 	%f7746, 0f00000000;
	mov.f32 	%f7747, 0f00000000;
	mov.f32 	%f7749, %f7748;
	mov.f32 	%f7750, %f7748;
	mov.f32 	%f7751, %f7748;
	mov.f32 	%f7752, %f7748;
	mov.f32 	%f7753, %f7748;
	@%p277 bra 	$L__BB4_361;

	mul.ftz.f32 	%f5838, %f2385, 0f40C90FDB;
	mov.f32 	%f5839, 0f40C90FDB;
	ld.const.f32 	%f5840, [plp+236];
	sub.ftz.f32 	%f5841, %f5838, %f5840;
	div.approx.ftz.f32 	%f5842, %f5841, %f5839;
	cvt.rmi.ftz.f32.f32 	%f5843, %f5842;
	mul.ftz.f32 	%f5844, %f5843, 0fC0000000;
	fma.rn.ftz.f32 	%f5845, %f5844, 0f40490FDB, %f5841;
	sin.approx.ftz.f32 	%f5846, %f5845;
	cos.approx.ftz.f32 	%f5847, %f5845;
	sin.approx.ftz.f32 	%f2388, %f2387;
	mul.ftz.f32 	%f7751, %f5846, %f2388;
	neg.ftz.f32 	%f7748, %f7751;
	mul.ftz.f32 	%f7750, %f5847, %f2388;
	cos.approx.ftz.f32 	%f7749, %f2387;
	neg.ftz.f32 	%f7752, %f7749;
	neg.ftz.f32 	%f7753, %f7750;
	setp.eq.ftz.f32 	%p278, %f2388, 0f00000000;
	@%p278 bra 	$L__BB4_361;

	mul.ftz.f32 	%f5848, %f2388, 0f419DE9E7;
	div.approx.ftz.f32 	%f7744, %f2386, %f5848;
	ld.const.f32 	%f5849, [plp+232];
	mul.ftz.f32 	%f7747, %f5849, 0f40490FDB;
	mov.f32 	%f7745, %f7747;
	mov.f32 	%f7746, %f7747;
	@%p155 bra 	$L__BB4_361;

	mov.f32 	%f5850, 0f00000000;
	tex.level.2d.v4.f32.f32 	{%f5851, %f5852, %f5853, %f5854}, [%rd79, {%f2385, %f2384}], %f5850;
	mul.ftz.f32 	%f7745, %f7747, %f5851;
	mul.ftz.f32 	%f7746, %f7747, %f5852;
	mul.ftz.f32 	%f7747, %f7747, %f5853;
	abs.ftz.f32 	%f5855, %f7745;
	setp.gtu.ftz.f32 	%p280, %f5855, 0f7F800000;
	@%p280 bra 	$L__BB4_360;

	abs.ftz.f32 	%f5856, %f7746;
	setp.gtu.ftz.f32 	%p281, %f5856, 0f7F800000;
	@%p281 bra 	$L__BB4_360;

	abs.ftz.f32 	%f5857, %f7747;
	setp.le.ftz.f32 	%p282, %f5857, 0f7F800000;
	@%p282 bra 	$L__BB4_361;

$L__BB4_360:
	add.u64 	%rd1938, %SP, 0;
	add.u64 	%rd1939, %SPL, 0;
	cvt.ftz.f64.f32 	%fd1, %f7745;
	st.local.f64 	[%rd1939], %fd1;
	cvt.ftz.f64.f32 	%fd2, %f7746;
	st.local.f64 	[%rd1939+8], %fd2;
	cvt.ftz.f64.f32 	%fd3, %f7747;
	st.local.f64 	[%rd1939+16], %fd3;
	mov.u64 	%rd1940, $str;
	cvta.global.u64 	%rd1941, %rd1940;
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1941;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd1938;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r2404, [retval0+0];
	} // callseq 1

$L__BB4_361:
	mov.u32 	%r2532, 1;
	bra.uni 	$L__BB4_362;

$L__BB4_193:
	mov.b64 	{%r2534, %r2533}, %rd80;
	mov.u32 	%r2532, 0;
	setp.leu.ftz.f32 	%p163, %f1387, 0f00000000;
	@%p163 bra 	$L__BB4_362;

	mul.lo.s64 	%rd1139, %rd80, 6364136223846793005;
	add.s64 	%rd81, %rd1139, 1;
	mul.lo.s64 	%rd1140, %rd80, 793875393913628917;
	mul.lo.s64 	%rd1141, %rd80, 7520897724310334953;
	add.s64 	%rd82, %rd1141, 6364136223846793006;
	add.s64 	%rd1142, %rd1140, -4561710125552423657;
	mov.b64 	{%r2534, %r2533}, %rd1142;
	@%p3 bra 	$L__BB4_362;

	shr.u64 	%rd1143, %rd80, 18;
	xor.b64  	%rd1144, %rd1143, %rd80;
	shr.u64 	%rd1145, %rd1144, 27;
	cvt.u32.u64 	%r1410, %rd1145;
	shr.u64 	%rd1146, %rd80, 59;
	cvt.u32.u64 	%r1411, %rd1146;
	mov.u32 	%r2508, 0;
	shf.r.wrap.b32 	%r1412, %r1410, %r1410, %r1411;
	shr.u32 	%r1413, %r1412, 9;
	or.b32  	%r1414, %r1413, 1065353216;
	mov.b32 	%f4552, %r1414;
	add.ftz.f32 	%f4553, %f4552, 0fBF800000;
	ld.const.v2.u32 	{%r1415, %r1416}, [plp+272];
	mov.b32 	%f1388, %r1415;
	mov.u32 	%r1418, 1;
	mul.ftz.f32 	%f1389, %f4553, %f1388;
	setp.eq.s32 	%p164, %r1416, 0;
	add.s32 	%r1419, %r1416, -1;
	clz.b32 	%r1420, %r1419;
	mov.u32 	%r1421, 32;
	sub.s32 	%r1422, %r1421, %r1420;
	shl.b32 	%r1423, %r1418, %r1422;
	shr.u32 	%r2506, %r1423, 1;
	setp.eq.s32 	%p165, %r2506, 0;
	or.pred  	%p166, %p164, %p165;
	ld.const.u64 	%rd1147, [plp+264];
	cvta.to.global.u64 	%rd83, %rd1147;
	@%p166 bra 	$L__BB4_200;

	mov.u32 	%r2508, 0;

$L__BB4_197:
	add.s32 	%r52, %r2506, %r2508;
	setp.ge.u32 	%p167, %r52, %r1416;
	@%p167 bra 	$L__BB4_199;

	mul.wide.s32 	%rd1148, %r52, 4;
	add.s64 	%rd1149, %rd83, %rd1148;
	ld.global.f32 	%f4554, [%rd1149];
	setp.le.ftz.f32 	%p168, %f4554, %f1389;
	selp.b32 	%r2508, %r52, %r2508, %p168;

$L__BB4_199:
	shr.u32 	%r2506, %r2506, 1;
	setp.ne.s32 	%p169, %r2506, 0;
	@%p169 bra 	$L__BB4_197;

$L__BB4_200:
	cvt.s64.s32 	%rd84, %r2508;
	mul.wide.s32 	%rd1150, %r2508, 4;
	add.s64 	%rd85, %rd83, %rd1150;
	ld.global.f32 	%f1390, [%rd85];
	setp.ge.u32 	%p170, %r2508, %r1419;
	mov.f32 	%f7354, %f1388;
	@%p170 bra 	$L__BB4_202;

	ld.global.f32 	%f7354, [%rd85+4];

$L__BB4_202:
	shr.u64 	%rd1151, %rd81, 18;
	xor.b64  	%rd1152, %rd1151, %rd81;
	shr.u64 	%rd1153, %rd1152, 27;
	cvt.u32.u64 	%r1427, %rd1153;
	shr.u64 	%rd1154, %rd81, 59;
	cvt.u32.u64 	%r1428, %rd1154;
	shr.u64 	%rd1155, %rd82, 18;
	xor.b64  	%rd1156, %rd1155, %rd82;
	shr.u64 	%rd1157, %rd1156, 27;
	cvt.u32.u64 	%r1429, %rd1157;
	shr.u64 	%rd1158, %rd82, 59;
	cvt.u32.u64 	%r1430, %rd1158;
	sub.ftz.f32 	%f4565, %f7354, %f1390;
	sub.ftz.f32 	%f4566, %f1389, %f1390;
	div.approx.ftz.f32 	%f1393, %f4566, %f4565;
	ld.const.u64 	%rd1159, [plp+256];
	cvta.to.global.u64 	%rd1160, %rd1159;
	shl.b64 	%rd1161, %rd84, 2;
	add.s64 	%rd1162, %rd1160, %rd1161;
	ld.global.f32 	%f4567, [%rd1162];
	div.approx.ftz.f32 	%f1394, %f4567, %f1388;
	setp.eq.ftz.f32 	%p171, %f1394, 0f00000000;
	mov.u32 	%r2532, 0;
	shf.r.wrap.b32 	%r1431, %r1429, %r1429, %r1430;
	shr.u32 	%r1432, %r1431, 9;
	or.b32  	%r1433, %r1432, 1065353216;
	mov.b32 	%f4568, %r1433;
	add.ftz.f32 	%f1395, %f4568, 0fBF800000;
	shf.r.wrap.b32 	%r57, %r1427, %r1427, %r1428;
	@%p171 bra 	$L__BB4_362;

	cvt.u32.u64 	%r1434, %rd84;
	mul.wide.u32 	%rd1163, %r1434, 216;
	add.s64 	%rd1164, %rd4, %rd1163;
	add.s64 	%rd86, %rd1164, 200;
	ld.global.v2.u32 	{%r1435, %r1436}, [%rd1164+200];
	mov.b32 	%f1396, %r1435;
	mov.u32 	%r1438, 1;
	mul.ftz.f32 	%f1397, %f1393, %f1396;
	setp.eq.s32 	%p172, %r1436, 0;
	add.s32 	%r1439, %r1436, -1;
	clz.b32 	%r1440, %r1439;
	mov.u32 	%r1441, 32;
	sub.s32 	%r1442, %r1441, %r1440;
	shl.b32 	%r1443, %r1438, %r1442;
	shr.u32 	%r2510, %r1443, 1;
	setp.eq.s32 	%p173, %r2510, 0;
	mov.u32 	%r2512, 0;
	or.pred  	%p174, %p172, %p173;
	@%p174 bra 	$L__BB4_207;

$L__BB4_204:
	add.s32 	%r62, %r2510, %r2512;
	setp.ge.u32 	%p175, %r62, %r1436;
	@%p175 bra 	$L__BB4_206;

	ld.global.u64 	%rd1165, [%rd86+-8];
	mul.wide.s32 	%rd1166, %r62, 4;
	add.s64 	%rd1167, %rd1165, %rd1166;
	ld.f32 	%f4569, [%rd1167];
	setp.le.ftz.f32 	%p176, %f4569, %f1397;
	selp.b32 	%r2512, %r62, %r2512, %p176;

$L__BB4_206:
	shr.u32 	%r2510, %r2510, 1;
	setp.eq.s32 	%p177, %r2510, 0;
	@%p177 bra 	$L__BB4_207;
	bra.uni 	$L__BB4_204;

$L__BB4_207:
	cvt.s64.s32 	%rd87, %r2512;
	ld.global.u64 	%rd1168, [%rd86+-8];
	mul.wide.s32 	%rd1169, %r2512, 4;
	add.s64 	%rd88, %rd1168, %rd1169;
	ld.f32 	%f1398, [%rd88];
	setp.ge.u32 	%p178, %r2512, %r1439;
	mov.f32 	%f7355, %f1396;
	@%p178 bra 	$L__BB4_209;

	ld.f32 	%f7355, [%rd88+4];

$L__BB4_209:
	sub.ftz.f32 	%f4580, %f7355, %f1398;
	sub.ftz.f32 	%f4581, %f1397, %f1398;
	div.approx.ftz.f32 	%f1401, %f4581, %f4580;
	ld.global.u64 	%rd1170, [%rd86+-16];
	shl.b64 	%rd1171, %rd87, 2;
	add.s64 	%rd1172, %rd1170, %rd1171;
	ld.f32 	%f4582, [%rd1172];
	div.approx.ftz.f32 	%f4583, %f4582, %f1396;
	cvt.u32.u64 	%r1448, %rd87;
	ld.global.u64 	%rd1173, [%rd86+-32];
	mul.wide.u32 	%rd1174, %r1448, 4;
	add.s64 	%rd89, %rd1173, %rd1174;
	mul.ftz.f32 	%f1402, %f1394, %f4583;
	setp.eq.ftz.f32 	%p179, %f4583, 0f00000000;
	@%p179 bra 	$L__BB4_362;

	ld.const.u64 	%rd1960, [plp+352];
	cvta.to.global.u64 	%rd1959, %rd1960;
	ld.u32 	%r1450, [%rd89];
	mul.wide.u32 	%rd1175, %r1450, 64;
	add.s64 	%rd1176, %rd1959, %rd1175;
	add.s64 	%rd90, %rd1176, 48;
	ld.global.v2.u32 	{%r1451, %r1452}, [%rd1176+48];
	mov.b32 	%f1403, %r1451;
	mov.u32 	%r2516, 0;
	mov.u32 	%r1454, 1;
	setp.eq.s32 	%p180, %r1452, 0;
	add.s32 	%r1455, %r1452, -1;
	clz.b32 	%r1456, %r1455;
	mov.u32 	%r1457, 32;
	sub.s32 	%r1458, %r1457, %r1456;
	shl.b32 	%r1459, %r1454, %r1458;
	shr.u32 	%r2514, %r1459, 1;
	setp.eq.s32 	%p181, %r2514, 0;
	or.pred  	%p182, %p180, %p181;
	@%p182 bra 	$L__BB4_215;

	mul.ftz.f32 	%f1404, %f1401, %f1403;
	mov.u32 	%r2516, 0;

$L__BB4_212:
	add.s32 	%r71, %r2514, %r2516;
	setp.ge.u32 	%p183, %r71, %r1452;
	@%p183 bra 	$L__BB4_214;

	ld.global.u64 	%rd1177, [%rd90+-8];
	mul.wide.s32 	%rd1178, %r71, 4;
	add.s64 	%rd1179, %rd1177, %rd1178;
	ld.f32 	%f4584, [%rd1179];
	setp.le.ftz.f32 	%p184, %f4584, %f1404;
	selp.b32 	%r2516, %r71, %r2516, %p184;

$L__BB4_214:
	shr.u32 	%r2514, %r2514, 1;
	setp.ne.s32 	%p185, %r2514, 0;
	@%p185 bra 	$L__BB4_212;

$L__BB4_215:
	ld.global.u64 	%rd1180, [%rd90+-16];
	mul.wide.s32 	%rd1181, %r2516, 4;
	add.s64 	%rd1182, %rd1180, %rd1181;
	ld.f32 	%f4585, [%rd1182];
	div.approx.ftz.f32 	%f4586, %f4585, %f1403;
	mul.ftz.f32 	%f1405, %f1402, %f4586;
	ld.global.u64 	%rd1183, [%rd90+-32];
	mul.wide.u32 	%rd1184, %r2516, 12;
	add.s64 	%rd1185, %rd1183, %rd1184;
	ld.u32 	%r1462, [%rd1185];
	ld.u32 	%r76, [%rd1185+4];
	ld.u32 	%r77, [%rd1185+8];
	ld.global.u64 	%rd91, [%rd90+-48];
	mul.wide.u32 	%rd1186, %r1462, 44;
	add.s64 	%rd92, %rd91, %rd1186;
	ld.f32 	%f7420, [%rd92];
	ld.f32 	%f7421, [%rd92+4];
	ld.f32 	%f7422, [%rd92+8];
	// begin inline asm
	call (%r1461), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p186, %r1461, 0;
	@%p186 bra 	$L__BB4_235;

	// begin inline asm
	call (%r1463), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f4587), _optix_get_ray_time, ();
	// end inline asm
	setp.lt.s32 	%p187, %r1463, 1;
	@%p187 bra 	$L__BB4_234;

	mov.u32 	%r2518, %r1463;

$L__BB4_218:
	.pragma "nounroll";
	add.s32 	%r1464, %r2518, -1;
	// begin inline asm
	call (%rd1187), _optix_get_transform_list_handle, (%r1464);
	// end inline asm
	// begin inline asm
	call (%r1465), _optix_get_transform_type_from_handle, (%rd1187);
	// end inline asm
	or.b32  	%r1466, %r1465, 1;
	setp.eq.s32 	%p188, %r1466, 3;
	@%p188 bra 	$L__BB4_225;
	bra.uni 	$L__BB4_219;

$L__BB4_225:
	setp.eq.s32 	%p192, %r1465, 2;
	@%p192 bra 	$L__BB4_229;
	bra.uni 	$L__BB4_226;

$L__BB4_229:
	// begin inline asm
	call (%rd1259), _optix_get_matrix_motion_transform_from_handle, (%rd1187);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd1261, %rd1259;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1554,%r1555,%r1556,%r1557}, [%rd1261];
	// end inline asm
	add.s64 	%rd1265, %rd1259, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1264, %rd1265;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1558,%r1559,%r1560,%r1561}, [%rd1264];
	// end inline asm
	add.s64 	%rd1268, %rd1259, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1267, %rd1268;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1562,%r1563,%r1564,%r1565}, [%rd1267];
	// end inline asm
	add.s64 	%rd1271, %rd1259, 48;
	// begin inline asm
	cvta.to.global.u64 %rd1270, %rd1271;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1566,%r1567,%r1568,%r1569}, [%rd1270];
	// end inline asm
	add.s64 	%rd1274, %rd1259, 64;
	// begin inline asm
	cvta.to.global.u64 %rd1273, %rd1274;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1570,%r1571,%r1572,%r1573}, [%rd1273];
	// end inline asm
	add.s64 	%rd1277, %rd1259, 80;
	// begin inline asm
	cvta.to.global.u64 %rd1276, %rd1277;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1574,%r1575,%r1576,%r1577}, [%rd1276];
	// end inline asm
	add.s64 	%rd1280, %rd1259, 96;
	// begin inline asm
	cvta.to.global.u64 %rd1279, %rd1280;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1578,%r1579,%r1580,%r1581}, [%rd1279];
	// end inline asm
	add.s64 	%rd1283, %rd1259, 112;
	// begin inline asm
	cvta.to.global.u64 %rd1282, %rd1283;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1582,%r1583,%r1584,%r1585}, [%rd1282];
	// end inline asm
	mov.b32 	%f4708, %r1557;
	mov.b32 	%f4709, %r1558;
	and.b32  	%r1598, %r1556, 65535;
	add.s32 	%r1599, %r1598, -1;
	cvt.rn.f32.s32 	%f4710, %r1599;
	sub.ftz.f32 	%f4711, %f4587, %f4708;
	sub.ftz.f32 	%f4712, %f4709, %f4708;
	div.approx.ftz.f32 	%f4713, %f4711, %f4712;
	mul.ftz.f32 	%f4714, %f4713, %f4710;
	min.ftz.f32 	%f4715, %f4710, %f4714;
	mov.f32 	%f4716, 0f00000000;
	max.ftz.f32 	%f4717, %f4716, %f4715;
	setp.num.ftz.f32 	%p195, %f4717, %f4717;
	selp.f32 	%f4718, %f4717, 0f00000000, %p195;
	cvt.rmi.ftz.f32.f32 	%f4719, %f4718;
	add.ftz.f32 	%f4720, %f4710, 0fBF800000;
	min.ftz.f32 	%f4721, %f4719, %f4720;
	sub.ftz.f32 	%f1495, %f4718, %f4721;
	cvt.rzi.ftz.s32.f32 	%r1600, %f4721;
	cvt.s64.s32 	%rd99, %r1600;
	mul.wide.s32 	%rd1294, %r1600, 48;
	add.s64 	%rd1286, %rd1268, %rd1294;
	// begin inline asm
	cvta.to.global.u64 %rd1285, %rd1286;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1586,%r1587,%r1588,%r1589}, [%rd1285];
	// end inline asm
	mov.b32 	%f7392, %r1586;
	mov.b32 	%f7393, %r1587;
	mov.b32 	%f7394, %r1588;
	mov.b32 	%f7395, %r1589;
	add.s64 	%rd1289, %rd1286, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1288, %rd1289;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1590,%r1591,%r1592,%r1593}, [%rd1288];
	// end inline asm
	mov.b32 	%f7388, %r1590;
	mov.b32 	%f7389, %r1591;
	mov.b32 	%f7390, %r1592;
	mov.b32 	%f7391, %r1593;
	add.s64 	%rd1292, %rd1286, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1291, %rd1292;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1594,%r1595,%r1596,%r1597}, [%rd1291];
	// end inline asm
	mov.b32 	%f7384, %r1594;
	mov.b32 	%f7385, %r1595;
	mov.b32 	%f7386, %r1596;
	mov.b32 	%f7387, %r1597;
	setp.leu.ftz.f32 	%p196, %f1495, 0f00000000;
	@%p196 bra 	$L__BB4_231;

	mov.f32 	%f4722, 0f3F800000;
	sub.ftz.f32 	%f4723, %f4722, %f1495;
	mul.lo.s64 	%rd1304, %rd99, 48;
	add.s64 	%rd1305, %rd1259, %rd1304;
	add.s64 	%rd1296, %rd1305, 80;
	// begin inline asm
	cvta.to.global.u64 %rd1295, %rd1296;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1601,%r1602,%r1603,%r1604}, [%rd1295];
	// end inline asm
	mov.b32 	%f4724, %r1601;
	mov.b32 	%f4725, %r1602;
	mov.b32 	%f4726, %r1603;
	mov.b32 	%f4727, %r1604;
	mul.ftz.f32 	%f4728, %f1495, %f4724;
	mul.ftz.f32 	%f4729, %f1495, %f4725;
	mul.ftz.f32 	%f4730, %f1495, %f4726;
	mul.ftz.f32 	%f4731, %f1495, %f4727;
	fma.rn.ftz.f32 	%f7392, %f4723, %f7392, %f4728;
	fma.rn.ftz.f32 	%f7393, %f4723, %f7393, %f4729;
	fma.rn.ftz.f32 	%f7394, %f4723, %f7394, %f4730;
	fma.rn.ftz.f32 	%f7395, %f4723, %f7395, %f4731;
	add.s64 	%rd1299, %rd1305, 96;
	// begin inline asm
	cvta.to.global.u64 %rd1298, %rd1299;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1605,%r1606,%r1607,%r1608}, [%rd1298];
	// end inline asm
	mov.b32 	%f4732, %r1605;
	mov.b32 	%f4733, %r1606;
	mov.b32 	%f4734, %r1607;
	mov.b32 	%f4735, %r1608;
	mul.ftz.f32 	%f4736, %f1495, %f4732;
	mul.ftz.f32 	%f4737, %f1495, %f4733;
	mul.ftz.f32 	%f4738, %f1495, %f4734;
	mul.ftz.f32 	%f4739, %f1495, %f4735;
	fma.rn.ftz.f32 	%f7388, %f4723, %f7388, %f4736;
	fma.rn.ftz.f32 	%f7389, %f4723, %f7389, %f4737;
	fma.rn.ftz.f32 	%f7390, %f4723, %f7390, %f4738;
	fma.rn.ftz.f32 	%f7391, %f4723, %f7391, %f4739;
	add.s64 	%rd1302, %rd1305, 112;
	// begin inline asm
	cvta.to.global.u64 %rd1301, %rd1302;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1609,%r1610,%r1611,%r1612}, [%rd1301];
	// end inline asm
	mov.b32 	%f4740, %r1609;
	mov.b32 	%f4741, %r1610;
	mov.b32 	%f4742, %r1611;
	mov.b32 	%f4743, %r1612;
	mul.ftz.f32 	%f4744, %f1495, %f4740;
	mul.ftz.f32 	%f4745, %f1495, %f4741;
	mul.ftz.f32 	%f4746, %f1495, %f4742;
	mul.ftz.f32 	%f4747, %f1495, %f4743;
	fma.rn.ftz.f32 	%f7384, %f4723, %f7384, %f4744;
	fma.rn.ftz.f32 	%f7385, %f4723, %f7385, %f4745;
	fma.rn.ftz.f32 	%f7386, %f4723, %f7386, %f4746;
	fma.rn.ftz.f32 	%f7387, %f4723, %f7387, %f4747;
	bra.uni 	$L__BB4_231;

$L__BB4_219:
	mov.f32 	%f7384, 0f00000000;
	mov.f32 	%f7386, 0f3F800000;
	setp.eq.s32 	%p189, %r1465, 4;
	@%p189 bra 	$L__BB4_221;

	setp.ne.s32 	%p190, %r1465, 1;
	mov.f32 	%f7385, %f7384;
	mov.f32 	%f7387, %f7384;
	mov.f32 	%f7388, %f7384;
	mov.f32 	%f7389, %f7386;
	mov.f32 	%f7390, %f7384;
	mov.f32 	%f7391, %f7384;
	mov.f32 	%f7392, %f7386;
	mov.f32 	%f7393, %f7384;
	mov.f32 	%f7394, %f7384;
	mov.f32 	%f7395, %f7384;
	@%p190 bra 	$L__BB4_231;

$L__BB4_221:
	@%p189 bra 	$L__BB4_223;
	bra.uni 	$L__BB4_222;

$L__BB4_223:
	// begin inline asm
	call (%rd1971), _optix_get_instance_transform_from_handle, (%rd1187);
	// end inline asm
	bra.uni 	$L__BB4_224;

$L__BB4_226:
	// begin inline asm
	call (%rd1202), _optix_get_srt_motion_transform_from_handle, (%rd1187);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd1204, %rd1202;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1479,%r1480,%r1481,%r1482}, [%rd1204];
	// end inline asm
	add.s64 	%rd1208, %rd1202, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1207, %rd1208;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1483,%r1484,%r1485,%r1486}, [%rd1207];
	// end inline asm
	add.s64 	%rd1211, %rd1202, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1210, %rd1211;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1487,%r1488,%r1489,%r1490}, [%rd1210];
	// end inline asm
	add.s64 	%rd1214, %rd1202, 48;
	// begin inline asm
	cvta.to.global.u64 %rd1213, %rd1214;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1491,%r1492,%r1493,%r1494}, [%rd1213];
	// end inline asm
	add.s64 	%rd1217, %rd1202, 64;
	// begin inline asm
	cvta.to.global.u64 %rd1216, %rd1217;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1495,%r1496,%r1497,%r1498}, [%rd1216];
	// end inline asm
	add.s64 	%rd1220, %rd1202, 80;
	// begin inline asm
	cvta.to.global.u64 %rd1219, %rd1220;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1499,%r1500,%r1501,%r1502}, [%rd1219];
	// end inline asm
	add.s64 	%rd1223, %rd1202, 96;
	// begin inline asm
	cvta.to.global.u64 %rd1222, %rd1223;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1503,%r1504,%r1505,%r1506}, [%rd1222];
	// end inline asm
	add.s64 	%rd1226, %rd1202, 112;
	// begin inline asm
	cvta.to.global.u64 %rd1225, %rd1226;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1507,%r1508,%r1509,%r1510}, [%rd1225];
	// end inline asm
	add.s64 	%rd1229, %rd1202, 128;
	// begin inline asm
	cvta.to.global.u64 %rd1228, %rd1229;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1511,%r1512,%r1513,%r1514}, [%rd1228];
	// end inline asm
	add.s64 	%rd1232, %rd1202, 144;
	// begin inline asm
	cvta.to.global.u64 %rd1231, %rd1232;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1515,%r1516,%r1517,%r1518}, [%rd1231];
	// end inline asm
	mov.b32 	%f4602, %r1482;
	mov.b32 	%f4603, %r1483;
	and.b32  	%r1535, %r1481, 65535;
	add.s32 	%r1536, %r1535, -1;
	cvt.rn.f32.s32 	%f4604, %r1536;
	sub.ftz.f32 	%f4605, %f4587, %f4602;
	sub.ftz.f32 	%f4606, %f4603, %f4602;
	div.approx.ftz.f32 	%f4607, %f4605, %f4606;
	mul.ftz.f32 	%f4608, %f4607, %f4604;
	min.ftz.f32 	%f4609, %f4604, %f4608;
	mov.f32 	%f4610, 0f00000000;
	max.ftz.f32 	%f4611, %f4610, %f4609;
	setp.num.ftz.f32 	%p193, %f4611, %f4611;
	selp.f32 	%f4612, %f4611, 0f00000000, %p193;
	cvt.rmi.ftz.f32.f32 	%f4613, %f4612;
	add.ftz.f32 	%f4614, %f4604, 0fBF800000;
	min.ftz.f32 	%f4615, %f4613, %f4614;
	sub.ftz.f32 	%f1434, %f4612, %f4615;
	cvt.rzi.ftz.s32.f32 	%r1537, %f4615;
	mul.wide.s32 	%rd1246, %r1537, 64;
	add.s64 	%rd1235, %rd1211, %rd1246;
	// begin inline asm
	cvta.to.global.u64 %rd1234, %rd1235;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1519,%r1520,%r1521,%r1522}, [%rd1234];
	// end inline asm
	mov.b32 	%f7368, %r1519;
	mov.b32 	%f7369, %r1520;
	mov.b32 	%f7370, %r1521;
	mov.b32 	%f7371, %r1522;
	add.s64 	%rd1238, %rd1235, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1237, %rd1238;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1523,%r1524,%r1525,%r1526}, [%rd1237];
	// end inline asm
	mov.b32 	%f7372, %r1523;
	mov.b32 	%f7373, %r1524;
	mov.b32 	%f7374, %r1525;
	mov.b32 	%f7375, %r1526;
	add.s64 	%rd1241, %rd1235, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1240, %rd1241;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1527,%r1528,%r1529,%r1530}, [%rd1240];
	// end inline asm
	mov.b32 	%f7376, %r1527;
	mov.b32 	%f7377, %r1528;
	mov.b32 	%f7378, %r1529;
	mov.b32 	%f7379, %r1530;
	add.s64 	%rd1244, %rd1235, 48;
	// begin inline asm
	cvta.to.global.u64 %rd1243, %rd1244;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1531,%r1532,%r1533,%r1534}, [%rd1243];
	// end inline asm
	mov.b32 	%f7380, %r1531;
	mov.b32 	%f7381, %r1532;
	mov.b32 	%f7382, %r1533;
	mov.b32 	%f7383, %r1534;
	setp.leu.ftz.f32 	%p194, %f1434, 0f00000000;
	@%p194 bra 	$L__BB4_228;

	mov.f32 	%f4616, 0f3F800000;
	sub.ftz.f32 	%f4617, %f4616, %f1434;
	add.s64 	%rd1248, %rd1235, 64;
	// begin inline asm
	cvta.to.global.u64 %rd1247, %rd1248;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1538,%r1539,%r1540,%r1541}, [%rd1247];
	// end inline asm
	mov.b32 	%f4618, %r1538;
	mov.b32 	%f4619, %r1539;
	mov.b32 	%f4620, %r1540;
	mov.b32 	%f4621, %r1541;
	mul.ftz.f32 	%f4622, %f1434, %f4618;
	mul.ftz.f32 	%f4623, %f1434, %f4619;
	mul.ftz.f32 	%f4624, %f1434, %f4620;
	mul.ftz.f32 	%f4625, %f1434, %f4621;
	fma.rn.ftz.f32 	%f7368, %f4617, %f7368, %f4622;
	fma.rn.ftz.f32 	%f7369, %f4617, %f7369, %f4623;
	fma.rn.ftz.f32 	%f7370, %f4617, %f7370, %f4624;
	fma.rn.ftz.f32 	%f7371, %f4617, %f7371, %f4625;
	add.s64 	%rd1251, %rd1235, 80;
	// begin inline asm
	cvta.to.global.u64 %rd1250, %rd1251;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1542,%r1543,%r1544,%r1545}, [%rd1250];
	// end inline asm
	mov.b32 	%f4626, %r1542;
	mov.b32 	%f4627, %r1543;
	mov.b32 	%f4628, %r1544;
	mov.b32 	%f4629, %r1545;
	mul.ftz.f32 	%f4630, %f1434, %f4626;
	mul.ftz.f32 	%f4631, %f1434, %f4627;
	mul.ftz.f32 	%f4632, %f1434, %f4628;
	mul.ftz.f32 	%f4633, %f1434, %f4629;
	fma.rn.ftz.f32 	%f7372, %f4617, %f7372, %f4630;
	fma.rn.ftz.f32 	%f7373, %f4617, %f7373, %f4631;
	fma.rn.ftz.f32 	%f7374, %f4617, %f7374, %f4632;
	fma.rn.ftz.f32 	%f7375, %f4617, %f7375, %f4633;
	add.s64 	%rd1254, %rd1235, 96;
	// begin inline asm
	cvta.to.global.u64 %rd1253, %rd1254;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1546,%r1547,%r1548,%r1549}, [%rd1253];
	// end inline asm
	mov.b32 	%f4634, %r1546;
	mov.b32 	%f4635, %r1547;
	mov.b32 	%f4636, %r1548;
	mov.b32 	%f4637, %r1549;
	mul.ftz.f32 	%f4638, %f1434, %f4634;
	mul.ftz.f32 	%f4639, %f1434, %f4635;
	mul.ftz.f32 	%f4640, %f1434, %f4636;
	mul.ftz.f32 	%f4641, %f1434, %f4637;
	fma.rn.ftz.f32 	%f7376, %f4617, %f7376, %f4638;
	fma.rn.ftz.f32 	%f4642, %f4617, %f7377, %f4639;
	fma.rn.ftz.f32 	%f4643, %f4617, %f7378, %f4640;
	fma.rn.ftz.f32 	%f4644, %f4617, %f7379, %f4641;
	add.s64 	%rd1257, %rd1235, 112;
	// begin inline asm
	cvta.to.global.u64 %rd1256, %rd1257;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1550,%r1551,%r1552,%r1553}, [%rd1256];
	// end inline asm
	mov.b32 	%f4645, %r1550;
	mov.b32 	%f4646, %r1551;
	mov.b32 	%f4647, %r1552;
	mov.b32 	%f4648, %r1553;
	mul.ftz.f32 	%f4649, %f1434, %f4645;
	mul.ftz.f32 	%f4650, %f1434, %f4646;
	mul.ftz.f32 	%f4651, %f1434, %f4647;
	mul.ftz.f32 	%f4652, %f1434, %f4648;
	fma.rn.ftz.f32 	%f4653, %f4617, %f7380, %f4649;
	fma.rn.ftz.f32 	%f7381, %f4617, %f7381, %f4650;
	fma.rn.ftz.f32 	%f7382, %f4617, %f7382, %f4651;
	fma.rn.ftz.f32 	%f7383, %f4617, %f7383, %f4652;
	mul.ftz.f32 	%f4654, %f4643, %f4643;
	fma.rn.ftz.f32 	%f4655, %f4642, %f4642, %f4654;
	fma.rn.ftz.f32 	%f4656, %f4644, %f4644, %f4655;
	fma.rn.ftz.f32 	%f4657, %f4653, %f4653, %f4656;
	rsqrt.approx.ftz.f32 	%f4658, %f4657;
	mul.ftz.f32 	%f7377, %f4642, %f4658;
	mul.ftz.f32 	%f7378, %f4643, %f4658;
	mul.ftz.f32 	%f7379, %f4644, %f4658;
	mul.ftz.f32 	%f7380, %f4658, %f4653;

$L__BB4_228:
	mul.ftz.f32 	%f4659, %f7378, %f7378;
	mul.ftz.f32 	%f4660, %f7377, %f7377;
	sub.ftz.f32 	%f4661, %f4660, %f4659;
	mul.ftz.f32 	%f4662, %f7379, %f7379;
	sub.ftz.f32 	%f4663, %f4661, %f4662;
	fma.rn.ftz.f32 	%f4664, %f7380, %f7380, %f4663;
	mul.ftz.f32 	%f4665, %f7379, %f7380;
	mul.ftz.f32 	%f4666, %f7377, %f7378;
	sub.ftz.f32 	%f4667, %f4666, %f4665;
	add.ftz.f32 	%f4668, %f4667, %f4667;
	mul.ftz.f32 	%f4669, %f7378, %f7380;
	mul.ftz.f32 	%f4670, %f7377, %f7379;
	add.ftz.f32 	%f4671, %f4670, %f4669;
	add.ftz.f32 	%f4672, %f4671, %f4671;
	add.ftz.f32 	%f4673, %f4666, %f4665;
	add.ftz.f32 	%f4674, %f4673, %f4673;
	sub.ftz.f32 	%f4675, %f4659, %f4660;
	sub.ftz.f32 	%f4676, %f4675, %f4662;
	fma.rn.ftz.f32 	%f4677, %f7380, %f7380, %f4676;
	mul.ftz.f32 	%f4678, %f7377, %f7380;
	mul.ftz.f32 	%f4679, %f7378, %f7379;
	sub.ftz.f32 	%f4680, %f4679, %f4678;
	add.ftz.f32 	%f4681, %f4680, %f4680;
	sub.ftz.f32 	%f4682, %f4670, %f4669;
	add.ftz.f32 	%f4683, %f4682, %f4682;
	add.ftz.f32 	%f4684, %f4679, %f4678;
	add.ftz.f32 	%f4685, %f4684, %f4684;
	neg.ftz.f32 	%f4686, %f4660;
	sub.ftz.f32 	%f4687, %f4686, %f4659;
	add.ftz.f32 	%f4688, %f4687, %f4662;
	fma.rn.ftz.f32 	%f4689, %f7380, %f7380, %f4688;
	mul.ftz.f32 	%f4690, %f7374, %f4668;
	fma.rn.ftz.f32 	%f4691, %f7371, %f4664, %f4690;
	fma.rn.ftz.f32 	%f4692, %f7376, %f4672, %f4691;
	add.ftz.f32 	%f7395, %f7381, %f4692;
	mul.ftz.f32 	%f4693, %f7371, %f4674;
	fma.rn.ftz.f32 	%f4694, %f7374, %f4677, %f4693;
	fma.rn.ftz.f32 	%f4695, %f7376, %f4681, %f4694;
	add.ftz.f32 	%f7391, %f7382, %f4695;
	mul.ftz.f32 	%f4696, %f7374, %f4685;
	fma.rn.ftz.f32 	%f4697, %f7371, %f4683, %f4696;
	fma.rn.ftz.f32 	%f4698, %f7376, %f4689, %f4697;
	add.ftz.f32 	%f7387, %f7383, %f4698;
	mul.ftz.f32 	%f4699, %f7373, %f4668;
	fma.rn.ftz.f32 	%f4700, %f7370, %f4664, %f4699;
	fma.rn.ftz.f32 	%f7394, %f7375, %f4672, %f4700;
	mul.ftz.f32 	%f4701, %f7370, %f4674;
	fma.rn.ftz.f32 	%f4702, %f7373, %f4677, %f4701;
	fma.rn.ftz.f32 	%f7390, %f7375, %f4681, %f4702;
	mul.ftz.f32 	%f4703, %f7373, %f4685;
	fma.rn.ftz.f32 	%f4704, %f7370, %f4683, %f4703;
	fma.rn.ftz.f32 	%f7386, %f7375, %f4689, %f4704;
	mul.ftz.f32 	%f4705, %f7372, %f4668;
	fma.rn.ftz.f32 	%f7393, %f7369, %f4664, %f4705;
	mul.ftz.f32 	%f4706, %f7369, %f4674;
	fma.rn.ftz.f32 	%f7389, %f7372, %f4677, %f4706;
	mul.ftz.f32 	%f4707, %f7372, %f4685;
	fma.rn.ftz.f32 	%f7385, %f7369, %f4683, %f4707;
	mul.ftz.f32 	%f7392, %f7368, %f4664;
	mul.ftz.f32 	%f7388, %f7368, %f4674;
	mul.ftz.f32 	%f7384, %f7368, %f4683;
	bra.uni 	$L__BB4_231;

$L__BB4_222:
	// begin inline asm
	call (%rd1189), _optix_get_static_transform_from_handle, (%rd1187);
	// end inline asm
	add.s64 	%rd1971, %rd1189, 16;

$L__BB4_224:
	// begin inline asm
	cvta.to.global.u64 %rd1193, %rd1971;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1467,%r1468,%r1469,%r1470}, [%rd1193];
	// end inline asm
	mov.b32 	%f7392, %r1467;
	mov.b32 	%f7393, %r1468;
	mov.b32 	%f7394, %r1469;
	mov.b32 	%f7395, %r1470;
	add.s64 	%rd1197, %rd1971, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1196, %rd1197;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1471,%r1472,%r1473,%r1474}, [%rd1196];
	// end inline asm
	mov.b32 	%f7388, %r1471;
	mov.b32 	%f7389, %r1472;
	mov.b32 	%f7390, %r1473;
	mov.b32 	%f7391, %r1474;
	add.s64 	%rd1200, %rd1971, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1199, %rd1200;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1475,%r1476,%r1477,%r1478}, [%rd1199];
	// end inline asm
	mov.b32 	%f7384, %r1475;
	mov.b32 	%f7385, %r1476;
	mov.b32 	%f7386, %r1477;
	mov.b32 	%f7387, %r1478;

$L__BB4_231:
	setp.eq.s32 	%p197, %r2518, %r1463;
	@%p197 bra 	$L__BB4_233;

	mul.ftz.f32 	%f4748, %f7363, %f7393;
	fma.rn.ftz.f32 	%f4749, %f7359, %f7392, %f4748;
	fma.rn.ftz.f32 	%f1532, %f7367, %f7394, %f4749;
	mul.ftz.f32 	%f4750, %f7362, %f7393;
	fma.rn.ftz.f32 	%f4751, %f7358, %f7392, %f4750;
	fma.rn.ftz.f32 	%f1533, %f7366, %f7394, %f4751;
	mul.ftz.f32 	%f4752, %f7361, %f7393;
	fma.rn.ftz.f32 	%f4753, %f7357, %f7392, %f4752;
	fma.rn.ftz.f32 	%f1534, %f7365, %f7394, %f4753;
	mul.ftz.f32 	%f4754, %f7360, %f7393;
	fma.rn.ftz.f32 	%f4755, %f7356, %f7392, %f4754;
	fma.rn.ftz.f32 	%f4756, %f7364, %f7394, %f4755;
	add.ftz.f32 	%f7395, %f7395, %f4756;
	mul.ftz.f32 	%f4757, %f7363, %f7389;
	fma.rn.ftz.f32 	%f4758, %f7359, %f7388, %f4757;
	fma.rn.ftz.f32 	%f1536, %f7367, %f7390, %f4758;
	mul.ftz.f32 	%f4759, %f7362, %f7389;
	fma.rn.ftz.f32 	%f4760, %f7358, %f7388, %f4759;
	fma.rn.ftz.f32 	%f1537, %f7366, %f7390, %f4760;
	mul.ftz.f32 	%f4761, %f7361, %f7389;
	fma.rn.ftz.f32 	%f4762, %f7357, %f7388, %f4761;
	fma.rn.ftz.f32 	%f1538, %f7365, %f7390, %f4762;
	mul.ftz.f32 	%f4763, %f7360, %f7389;
	fma.rn.ftz.f32 	%f4764, %f7356, %f7388, %f4763;
	fma.rn.ftz.f32 	%f4765, %f7364, %f7390, %f4764;
	add.ftz.f32 	%f7391, %f7391, %f4765;
	mul.ftz.f32 	%f4766, %f7363, %f7385;
	fma.rn.ftz.f32 	%f4767, %f7359, %f7384, %f4766;
	fma.rn.ftz.f32 	%f1540, %f7367, %f7386, %f4767;
	mul.ftz.f32 	%f4768, %f7362, %f7385;
	fma.rn.ftz.f32 	%f4769, %f7358, %f7384, %f4768;
	fma.rn.ftz.f32 	%f1541, %f7366, %f7386, %f4769;
	mul.ftz.f32 	%f4770, %f7361, %f7385;
	fma.rn.ftz.f32 	%f4771, %f7357, %f7384, %f4770;
	fma.rn.ftz.f32 	%f1542, %f7365, %f7386, %f4771;
	mul.ftz.f32 	%f4772, %f7360, %f7385;
	fma.rn.ftz.f32 	%f4773, %f7356, %f7384, %f4772;
	fma.rn.ftz.f32 	%f4774, %f7364, %f7386, %f4773;
	add.ftz.f32 	%f7387, %f7387, %f4774;
	mov.f32 	%f7384, %f1540;
	mov.f32 	%f7385, %f1541;
	mov.f32 	%f7386, %f1542;
	mov.f32 	%f7388, %f1536;
	mov.f32 	%f7389, %f1537;
	mov.f32 	%f7390, %f1538;
	mov.f32 	%f7392, %f1532;
	mov.f32 	%f7393, %f1533;
	mov.f32 	%f7394, %f1534;

$L__BB4_233:
	setp.gt.s32 	%p198, %r2518, 1;
	mov.u32 	%r2518, %r1464;
	mov.f32 	%f7356, %f7395;
	mov.f32 	%f7357, %f7394;
	mov.f32 	%f7358, %f7393;
	mov.f32 	%f7359, %f7392;
	mov.f32 	%f7360, %f7391;
	mov.f32 	%f7361, %f7390;
	mov.f32 	%f7362, %f7389;
	mov.f32 	%f7363, %f7388;
	mov.f32 	%f7364, %f7387;
	mov.f32 	%f7365, %f7386;
	mov.f32 	%f7366, %f7385;
	mov.f32 	%f7367, %f7384;
	@%p198 bra 	$L__BB4_218;

$L__BB4_234:
	mul.ftz.f32 	%f4775, %f7421, %f7393;
	fma.rn.ftz.f32 	%f4776, %f7420, %f7392, %f4775;
	fma.rn.ftz.f32 	%f4777, %f7422, %f7394, %f4776;
	mul.ftz.f32 	%f4778, %f7421, %f7389;
	fma.rn.ftz.f32 	%f4779, %f7420, %f7388, %f4778;
	fma.rn.ftz.f32 	%f4780, %f7422, %f7390, %f4779;
	mul.ftz.f32 	%f4781, %f7421, %f7385;
	fma.rn.ftz.f32 	%f4782, %f7420, %f7384, %f4781;
	fma.rn.ftz.f32 	%f4783, %f7422, %f7386, %f4782;
	add.ftz.f32 	%f7422, %f7387, %f4783;
	add.ftz.f32 	%f7421, %f7391, %f4780;
	add.ftz.f32 	%f7420, %f7395, %f4777;

$L__BB4_235:
	mul.wide.u32 	%rd1306, %r76, 44;
	add.s64 	%rd100, %rd91, %rd1306;
	ld.f32 	%f7487, [%rd100];
	ld.f32 	%f7488, [%rd100+4];
	ld.f32 	%f7489, [%rd100+8];
	// begin inline asm
	call (%r1613), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p199, %r1613, 0;
	@%p199 bra 	$L__BB4_255;

	// begin inline asm
	call (%r1614), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f4784), _optix_get_ray_time, ();
	// end inline asm
	setp.lt.s32 	%p200, %r1614, 1;
	@%p200 bra 	$L__BB4_254;

	mov.u32 	%r2519, %r1614;

$L__BB4_238:
	.pragma "nounroll";
	add.s32 	%r1615, %r2519, -1;
	// begin inline asm
	call (%rd1307), _optix_get_transform_list_handle, (%r1615);
	// end inline asm
	// begin inline asm
	call (%r1616), _optix_get_transform_type_from_handle, (%rd1307);
	// end inline asm
	or.b32  	%r1617, %r1616, 1;
	setp.eq.s32 	%p201, %r1617, 3;
	@%p201 bra 	$L__BB4_245;
	bra.uni 	$L__BB4_239;

$L__BB4_245:
	setp.eq.s32 	%p205, %r1616, 2;
	@%p205 bra 	$L__BB4_249;
	bra.uni 	$L__BB4_246;

$L__BB4_249:
	// begin inline asm
	call (%rd1379), _optix_get_matrix_motion_transform_from_handle, (%rd1307);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd1381, %rd1379;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1705,%r1706,%r1707,%r1708}, [%rd1381];
	// end inline asm
	add.s64 	%rd1385, %rd1379, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1384, %rd1385;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1709,%r1710,%r1711,%r1712}, [%rd1384];
	// end inline asm
	add.s64 	%rd1388, %rd1379, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1387, %rd1388;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1713,%r1714,%r1715,%r1716}, [%rd1387];
	// end inline asm
	add.s64 	%rd1391, %rd1379, 48;
	// begin inline asm
	cvta.to.global.u64 %rd1390, %rd1391;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1717,%r1718,%r1719,%r1720}, [%rd1390];
	// end inline asm
	add.s64 	%rd1394, %rd1379, 64;
	// begin inline asm
	cvta.to.global.u64 %rd1393, %rd1394;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1721,%r1722,%r1723,%r1724}, [%rd1393];
	// end inline asm
	add.s64 	%rd1397, %rd1379, 80;
	// begin inline asm
	cvta.to.global.u64 %rd1396, %rd1397;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1725,%r1726,%r1727,%r1728}, [%rd1396];
	// end inline asm
	add.s64 	%rd1400, %rd1379, 96;
	// begin inline asm
	cvta.to.global.u64 %rd1399, %rd1400;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1729,%r1730,%r1731,%r1732}, [%rd1399];
	// end inline asm
	add.s64 	%rd1403, %rd1379, 112;
	// begin inline asm
	cvta.to.global.u64 %rd1402, %rd1403;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1733,%r1734,%r1735,%r1736}, [%rd1402];
	// end inline asm
	mov.b32 	%f4905, %r1708;
	mov.b32 	%f4906, %r1709;
	and.b32  	%r1749, %r1707, 65535;
	add.s32 	%r1750, %r1749, -1;
	cvt.rn.f32.s32 	%f4907, %r1750;
	sub.ftz.f32 	%f4908, %f4784, %f4905;
	sub.ftz.f32 	%f4909, %f4906, %f4905;
	div.approx.ftz.f32 	%f4910, %f4908, %f4909;
	mul.ftz.f32 	%f4911, %f4910, %f4907;
	min.ftz.f32 	%f4912, %f4907, %f4911;
	mov.f32 	%f4913, 0f00000000;
	max.ftz.f32 	%f4914, %f4913, %f4912;
	setp.num.ftz.f32 	%p208, %f4914, %f4914;
	selp.f32 	%f4915, %f4914, 0f00000000, %p208;
	cvt.rmi.ftz.f32.f32 	%f4916, %f4915;
	add.ftz.f32 	%f4917, %f4907, 0fBF800000;
	min.ftz.f32 	%f4918, %f4916, %f4917;
	sub.ftz.f32 	%f1666, %f4915, %f4918;
	cvt.rzi.ftz.s32.f32 	%r1751, %f4918;
	cvt.s64.s32 	%rd107, %r1751;
	mul.wide.s32 	%rd1414, %r1751, 48;
	add.s64 	%rd1406, %rd1388, %rd1414;
	// begin inline asm
	cvta.to.global.u64 %rd1405, %rd1406;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1737,%r1738,%r1739,%r1740}, [%rd1405];
	// end inline asm
	mov.b32 	%f7459, %r1737;
	mov.b32 	%f7460, %r1738;
	mov.b32 	%f7461, %r1739;
	mov.b32 	%f7462, %r1740;
	add.s64 	%rd1409, %rd1406, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1408, %rd1409;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1741,%r1742,%r1743,%r1744}, [%rd1408];
	// end inline asm
	mov.b32 	%f7455, %r1741;
	mov.b32 	%f7456, %r1742;
	mov.b32 	%f7457, %r1743;
	mov.b32 	%f7458, %r1744;
	add.s64 	%rd1412, %rd1406, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1411, %rd1412;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1745,%r1746,%r1747,%r1748}, [%rd1411];
	// end inline asm
	mov.b32 	%f7451, %r1745;
	mov.b32 	%f7452, %r1746;
	mov.b32 	%f7453, %r1747;
	mov.b32 	%f7454, %r1748;
	setp.leu.ftz.f32 	%p209, %f1666, 0f00000000;
	@%p209 bra 	$L__BB4_251;

	mov.f32 	%f4919, 0f3F800000;
	sub.ftz.f32 	%f4920, %f4919, %f1666;
	mul.lo.s64 	%rd1424, %rd107, 48;
	add.s64 	%rd1425, %rd1379, %rd1424;
	add.s64 	%rd1416, %rd1425, 80;
	// begin inline asm
	cvta.to.global.u64 %rd1415, %rd1416;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1752,%r1753,%r1754,%r1755}, [%rd1415];
	// end inline asm
	mov.b32 	%f4921, %r1752;
	mov.b32 	%f4922, %r1753;
	mov.b32 	%f4923, %r1754;
	mov.b32 	%f4924, %r1755;
	mul.ftz.f32 	%f4925, %f1666, %f4921;
	mul.ftz.f32 	%f4926, %f1666, %f4922;
	mul.ftz.f32 	%f4927, %f1666, %f4923;
	mul.ftz.f32 	%f4928, %f1666, %f4924;
	fma.rn.ftz.f32 	%f7459, %f4920, %f7459, %f4925;
	fma.rn.ftz.f32 	%f7460, %f4920, %f7460, %f4926;
	fma.rn.ftz.f32 	%f7461, %f4920, %f7461, %f4927;
	fma.rn.ftz.f32 	%f7462, %f4920, %f7462, %f4928;
	add.s64 	%rd1419, %rd1425, 96;
	// begin inline asm
	cvta.to.global.u64 %rd1418, %rd1419;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1756,%r1757,%r1758,%r1759}, [%rd1418];
	// end inline asm
	mov.b32 	%f4929, %r1756;
	mov.b32 	%f4930, %r1757;
	mov.b32 	%f4931, %r1758;
	mov.b32 	%f4932, %r1759;
	mul.ftz.f32 	%f4933, %f1666, %f4929;
	mul.ftz.f32 	%f4934, %f1666, %f4930;
	mul.ftz.f32 	%f4935, %f1666, %f4931;
	mul.ftz.f32 	%f4936, %f1666, %f4932;
	fma.rn.ftz.f32 	%f7455, %f4920, %f7455, %f4933;
	fma.rn.ftz.f32 	%f7456, %f4920, %f7456, %f4934;
	fma.rn.ftz.f32 	%f7457, %f4920, %f7457, %f4935;
	fma.rn.ftz.f32 	%f7458, %f4920, %f7458, %f4936;
	add.s64 	%rd1422, %rd1425, 112;
	// begin inline asm
	cvta.to.global.u64 %rd1421, %rd1422;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1760,%r1761,%r1762,%r1763}, [%rd1421];
	// end inline asm
	mov.b32 	%f4937, %r1760;
	mov.b32 	%f4938, %r1761;
	mov.b32 	%f4939, %r1762;
	mov.b32 	%f4940, %r1763;
	mul.ftz.f32 	%f4941, %f1666, %f4937;
	mul.ftz.f32 	%f4942, %f1666, %f4938;
	mul.ftz.f32 	%f4943, %f1666, %f4939;
	mul.ftz.f32 	%f4944, %f1666, %f4940;
	fma.rn.ftz.f32 	%f7451, %f4920, %f7451, %f4941;
	fma.rn.ftz.f32 	%f7452, %f4920, %f7452, %f4942;
	fma.rn.ftz.f32 	%f7453, %f4920, %f7453, %f4943;
	fma.rn.ftz.f32 	%f7454, %f4920, %f7454, %f4944;
	bra.uni 	$L__BB4_251;

$L__BB4_239:
	mov.f32 	%f7451, 0f00000000;
	mov.f32 	%f7453, 0f3F800000;
	setp.eq.s32 	%p202, %r1616, 4;
	@%p202 bra 	$L__BB4_241;

	setp.ne.s32 	%p203, %r1616, 1;
	mov.f32 	%f7452, %f7451;
	mov.f32 	%f7454, %f7451;
	mov.f32 	%f7455, %f7451;
	mov.f32 	%f7456, %f7453;
	mov.f32 	%f7457, %f7451;
	mov.f32 	%f7458, %f7451;
	mov.f32 	%f7459, %f7453;
	mov.f32 	%f7460, %f7451;
	mov.f32 	%f7461, %f7451;
	mov.f32 	%f7462, %f7451;
	@%p203 bra 	$L__BB4_251;

$L__BB4_241:
	@%p202 bra 	$L__BB4_243;
	bra.uni 	$L__BB4_242;

$L__BB4_243:
	// begin inline asm
	call (%rd1972), _optix_get_instance_transform_from_handle, (%rd1307);
	// end inline asm
	bra.uni 	$L__BB4_244;

$L__BB4_246:
	// begin inline asm
	call (%rd1322), _optix_get_srt_motion_transform_from_handle, (%rd1307);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd1324, %rd1322;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1630,%r1631,%r1632,%r1633}, [%rd1324];
	// end inline asm
	add.s64 	%rd1328, %rd1322, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1327, %rd1328;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1634,%r1635,%r1636,%r1637}, [%rd1327];
	// end inline asm
	add.s64 	%rd1331, %rd1322, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1330, %rd1331;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1638,%r1639,%r1640,%r1641}, [%rd1330];
	// end inline asm
	add.s64 	%rd1334, %rd1322, 48;
	// begin inline asm
	cvta.to.global.u64 %rd1333, %rd1334;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1642,%r1643,%r1644,%r1645}, [%rd1333];
	// end inline asm
	add.s64 	%rd1337, %rd1322, 64;
	// begin inline asm
	cvta.to.global.u64 %rd1336, %rd1337;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1646,%r1647,%r1648,%r1649}, [%rd1336];
	// end inline asm
	add.s64 	%rd1340, %rd1322, 80;
	// begin inline asm
	cvta.to.global.u64 %rd1339, %rd1340;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1650,%r1651,%r1652,%r1653}, [%rd1339];
	// end inline asm
	add.s64 	%rd1343, %rd1322, 96;
	// begin inline asm
	cvta.to.global.u64 %rd1342, %rd1343;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1654,%r1655,%r1656,%r1657}, [%rd1342];
	// end inline asm
	add.s64 	%rd1346, %rd1322, 112;
	// begin inline asm
	cvta.to.global.u64 %rd1345, %rd1346;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1658,%r1659,%r1660,%r1661}, [%rd1345];
	// end inline asm
	add.s64 	%rd1349, %rd1322, 128;
	// begin inline asm
	cvta.to.global.u64 %rd1348, %rd1349;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1662,%r1663,%r1664,%r1665}, [%rd1348];
	// end inline asm
	add.s64 	%rd1352, %rd1322, 144;
	// begin inline asm
	cvta.to.global.u64 %rd1351, %rd1352;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1666,%r1667,%r1668,%r1669}, [%rd1351];
	// end inline asm
	mov.b32 	%f4799, %r1633;
	mov.b32 	%f4800, %r1634;
	and.b32  	%r1686, %r1632, 65535;
	add.s32 	%r1687, %r1686, -1;
	cvt.rn.f32.s32 	%f4801, %r1687;
	sub.ftz.f32 	%f4802, %f4784, %f4799;
	sub.ftz.f32 	%f4803, %f4800, %f4799;
	div.approx.ftz.f32 	%f4804, %f4802, %f4803;
	mul.ftz.f32 	%f4805, %f4804, %f4801;
	min.ftz.f32 	%f4806, %f4801, %f4805;
	mov.f32 	%f4807, 0f00000000;
	max.ftz.f32 	%f4808, %f4807, %f4806;
	setp.num.ftz.f32 	%p206, %f4808, %f4808;
	selp.f32 	%f4809, %f4808, 0f00000000, %p206;
	cvt.rmi.ftz.f32.f32 	%f4810, %f4809;
	add.ftz.f32 	%f4811, %f4801, 0fBF800000;
	min.ftz.f32 	%f4812, %f4810, %f4811;
	sub.ftz.f32 	%f1605, %f4809, %f4812;
	cvt.rzi.ftz.s32.f32 	%r1688, %f4812;
	mul.wide.s32 	%rd1366, %r1688, 64;
	add.s64 	%rd1355, %rd1331, %rd1366;
	// begin inline asm
	cvta.to.global.u64 %rd1354, %rd1355;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1670,%r1671,%r1672,%r1673}, [%rd1354];
	// end inline asm
	mov.b32 	%f7435, %r1670;
	mov.b32 	%f7436, %r1671;
	mov.b32 	%f7437, %r1672;
	mov.b32 	%f7438, %r1673;
	add.s64 	%rd1358, %rd1355, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1357, %rd1358;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1674,%r1675,%r1676,%r1677}, [%rd1357];
	// end inline asm
	mov.b32 	%f7439, %r1674;
	mov.b32 	%f7440, %r1675;
	mov.b32 	%f7441, %r1676;
	mov.b32 	%f7442, %r1677;
	add.s64 	%rd1361, %rd1355, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1360, %rd1361;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1678,%r1679,%r1680,%r1681}, [%rd1360];
	// end inline asm
	mov.b32 	%f7443, %r1678;
	mov.b32 	%f7444, %r1679;
	mov.b32 	%f7445, %r1680;
	mov.b32 	%f7446, %r1681;
	add.s64 	%rd1364, %rd1355, 48;
	// begin inline asm
	cvta.to.global.u64 %rd1363, %rd1364;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1682,%r1683,%r1684,%r1685}, [%rd1363];
	// end inline asm
	mov.b32 	%f7447, %r1682;
	mov.b32 	%f7448, %r1683;
	mov.b32 	%f7449, %r1684;
	mov.b32 	%f7450, %r1685;
	setp.leu.ftz.f32 	%p207, %f1605, 0f00000000;
	@%p207 bra 	$L__BB4_248;

	mov.f32 	%f4813, 0f3F800000;
	sub.ftz.f32 	%f4814, %f4813, %f1605;
	add.s64 	%rd1368, %rd1355, 64;
	// begin inline asm
	cvta.to.global.u64 %rd1367, %rd1368;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1689,%r1690,%r1691,%r1692}, [%rd1367];
	// end inline asm
	mov.b32 	%f4815, %r1689;
	mov.b32 	%f4816, %r1690;
	mov.b32 	%f4817, %r1691;
	mov.b32 	%f4818, %r1692;
	mul.ftz.f32 	%f4819, %f1605, %f4815;
	mul.ftz.f32 	%f4820, %f1605, %f4816;
	mul.ftz.f32 	%f4821, %f1605, %f4817;
	mul.ftz.f32 	%f4822, %f1605, %f4818;
	fma.rn.ftz.f32 	%f7435, %f4814, %f7435, %f4819;
	fma.rn.ftz.f32 	%f7436, %f4814, %f7436, %f4820;
	fma.rn.ftz.f32 	%f7437, %f4814, %f7437, %f4821;
	fma.rn.ftz.f32 	%f7438, %f4814, %f7438, %f4822;
	add.s64 	%rd1371, %rd1355, 80;
	// begin inline asm
	cvta.to.global.u64 %rd1370, %rd1371;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1693,%r1694,%r1695,%r1696}, [%rd1370];
	// end inline asm
	mov.b32 	%f4823, %r1693;
	mov.b32 	%f4824, %r1694;
	mov.b32 	%f4825, %r1695;
	mov.b32 	%f4826, %r1696;
	mul.ftz.f32 	%f4827, %f1605, %f4823;
	mul.ftz.f32 	%f4828, %f1605, %f4824;
	mul.ftz.f32 	%f4829, %f1605, %f4825;
	mul.ftz.f32 	%f4830, %f1605, %f4826;
	fma.rn.ftz.f32 	%f7439, %f4814, %f7439, %f4827;
	fma.rn.ftz.f32 	%f7440, %f4814, %f7440, %f4828;
	fma.rn.ftz.f32 	%f7441, %f4814, %f7441, %f4829;
	fma.rn.ftz.f32 	%f7442, %f4814, %f7442, %f4830;
	add.s64 	%rd1374, %rd1355, 96;
	// begin inline asm
	cvta.to.global.u64 %rd1373, %rd1374;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1697,%r1698,%r1699,%r1700}, [%rd1373];
	// end inline asm
	mov.b32 	%f4831, %r1697;
	mov.b32 	%f4832, %r1698;
	mov.b32 	%f4833, %r1699;
	mov.b32 	%f4834, %r1700;
	mul.ftz.f32 	%f4835, %f1605, %f4831;
	mul.ftz.f32 	%f4836, %f1605, %f4832;
	mul.ftz.f32 	%f4837, %f1605, %f4833;
	mul.ftz.f32 	%f4838, %f1605, %f4834;
	fma.rn.ftz.f32 	%f7443, %f4814, %f7443, %f4835;
	fma.rn.ftz.f32 	%f4839, %f4814, %f7444, %f4836;
	fma.rn.ftz.f32 	%f4840, %f4814, %f7445, %f4837;
	fma.rn.ftz.f32 	%f4841, %f4814, %f7446, %f4838;
	add.s64 	%rd1377, %rd1355, 112;
	// begin inline asm
	cvta.to.global.u64 %rd1376, %rd1377;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1701,%r1702,%r1703,%r1704}, [%rd1376];
	// end inline asm
	mov.b32 	%f4842, %r1701;
	mov.b32 	%f4843, %r1702;
	mov.b32 	%f4844, %r1703;
	mov.b32 	%f4845, %r1704;
	mul.ftz.f32 	%f4846, %f1605, %f4842;
	mul.ftz.f32 	%f4847, %f1605, %f4843;
	mul.ftz.f32 	%f4848, %f1605, %f4844;
	mul.ftz.f32 	%f4849, %f1605, %f4845;
	fma.rn.ftz.f32 	%f4850, %f4814, %f7447, %f4846;
	fma.rn.ftz.f32 	%f7448, %f4814, %f7448, %f4847;
	fma.rn.ftz.f32 	%f7449, %f4814, %f7449, %f4848;
	fma.rn.ftz.f32 	%f7450, %f4814, %f7450, %f4849;
	mul.ftz.f32 	%f4851, %f4840, %f4840;
	fma.rn.ftz.f32 	%f4852, %f4839, %f4839, %f4851;
	fma.rn.ftz.f32 	%f4853, %f4841, %f4841, %f4852;
	fma.rn.ftz.f32 	%f4854, %f4850, %f4850, %f4853;
	rsqrt.approx.ftz.f32 	%f4855, %f4854;
	mul.ftz.f32 	%f7444, %f4839, %f4855;
	mul.ftz.f32 	%f7445, %f4840, %f4855;
	mul.ftz.f32 	%f7446, %f4841, %f4855;
	mul.ftz.f32 	%f7447, %f4855, %f4850;

$L__BB4_248:
	mul.ftz.f32 	%f4856, %f7445, %f7445;
	mul.ftz.f32 	%f4857, %f7444, %f7444;
	sub.ftz.f32 	%f4858, %f4857, %f4856;
	mul.ftz.f32 	%f4859, %f7446, %f7446;
	sub.ftz.f32 	%f4860, %f4858, %f4859;
	fma.rn.ftz.f32 	%f4861, %f7447, %f7447, %f4860;
	mul.ftz.f32 	%f4862, %f7446, %f7447;
	mul.ftz.f32 	%f4863, %f7444, %f7445;
	sub.ftz.f32 	%f4864, %f4863, %f4862;
	add.ftz.f32 	%f4865, %f4864, %f4864;
	mul.ftz.f32 	%f4866, %f7445, %f7447;
	mul.ftz.f32 	%f4867, %f7444, %f7446;
	add.ftz.f32 	%f4868, %f4867, %f4866;
	add.ftz.f32 	%f4869, %f4868, %f4868;
	add.ftz.f32 	%f4870, %f4863, %f4862;
	add.ftz.f32 	%f4871, %f4870, %f4870;
	sub.ftz.f32 	%f4872, %f4856, %f4857;
	sub.ftz.f32 	%f4873, %f4872, %f4859;
	fma.rn.ftz.f32 	%f4874, %f7447, %f7447, %f4873;
	mul.ftz.f32 	%f4875, %f7444, %f7447;
	mul.ftz.f32 	%f4876, %f7445, %f7446;
	sub.ftz.f32 	%f4877, %f4876, %f4875;
	add.ftz.f32 	%f4878, %f4877, %f4877;
	sub.ftz.f32 	%f4879, %f4867, %f4866;
	add.ftz.f32 	%f4880, %f4879, %f4879;
	add.ftz.f32 	%f4881, %f4876, %f4875;
	add.ftz.f32 	%f4882, %f4881, %f4881;
	neg.ftz.f32 	%f4883, %f4857;
	sub.ftz.f32 	%f4884, %f4883, %f4856;
	add.ftz.f32 	%f4885, %f4884, %f4859;
	fma.rn.ftz.f32 	%f4886, %f7447, %f7447, %f4885;
	mul.ftz.f32 	%f4887, %f7441, %f4865;
	fma.rn.ftz.f32 	%f4888, %f7438, %f4861, %f4887;
	fma.rn.ftz.f32 	%f4889, %f7443, %f4869, %f4888;
	add.ftz.f32 	%f7462, %f7448, %f4889;
	mul.ftz.f32 	%f4890, %f7438, %f4871;
	fma.rn.ftz.f32 	%f4891, %f7441, %f4874, %f4890;
	fma.rn.ftz.f32 	%f4892, %f7443, %f4878, %f4891;
	add.ftz.f32 	%f7458, %f7449, %f4892;
	mul.ftz.f32 	%f4893, %f7441, %f4882;
	fma.rn.ftz.f32 	%f4894, %f7438, %f4880, %f4893;
	fma.rn.ftz.f32 	%f4895, %f7443, %f4886, %f4894;
	add.ftz.f32 	%f7454, %f7450, %f4895;
	mul.ftz.f32 	%f4896, %f7440, %f4865;
	fma.rn.ftz.f32 	%f4897, %f7437, %f4861, %f4896;
	fma.rn.ftz.f32 	%f7461, %f7442, %f4869, %f4897;
	mul.ftz.f32 	%f4898, %f7437, %f4871;
	fma.rn.ftz.f32 	%f4899, %f7440, %f4874, %f4898;
	fma.rn.ftz.f32 	%f7457, %f7442, %f4878, %f4899;
	mul.ftz.f32 	%f4900, %f7440, %f4882;
	fma.rn.ftz.f32 	%f4901, %f7437, %f4880, %f4900;
	fma.rn.ftz.f32 	%f7453, %f7442, %f4886, %f4901;
	mul.ftz.f32 	%f4902, %f7439, %f4865;
	fma.rn.ftz.f32 	%f7460, %f7436, %f4861, %f4902;
	mul.ftz.f32 	%f4903, %f7436, %f4871;
	fma.rn.ftz.f32 	%f7456, %f7439, %f4874, %f4903;
	mul.ftz.f32 	%f4904, %f7439, %f4882;
	fma.rn.ftz.f32 	%f7452, %f7436, %f4880, %f4904;
	mul.ftz.f32 	%f7459, %f7435, %f4861;
	mul.ftz.f32 	%f7455, %f7435, %f4871;
	mul.ftz.f32 	%f7451, %f7435, %f4880;
	bra.uni 	$L__BB4_251;

$L__BB4_242:
	// begin inline asm
	call (%rd1309), _optix_get_static_transform_from_handle, (%rd1307);
	// end inline asm
	add.s64 	%rd1972, %rd1309, 16;

$L__BB4_244:
	// begin inline asm
	cvta.to.global.u64 %rd1313, %rd1972;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1618,%r1619,%r1620,%r1621}, [%rd1313];
	// end inline asm
	mov.b32 	%f7459, %r1618;
	mov.b32 	%f7460, %r1619;
	mov.b32 	%f7461, %r1620;
	mov.b32 	%f7462, %r1621;
	add.s64 	%rd1317, %rd1972, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1316, %rd1317;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1622,%r1623,%r1624,%r1625}, [%rd1316];
	// end inline asm
	mov.b32 	%f7455, %r1622;
	mov.b32 	%f7456, %r1623;
	mov.b32 	%f7457, %r1624;
	mov.b32 	%f7458, %r1625;
	add.s64 	%rd1320, %rd1972, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1319, %rd1320;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1626,%r1627,%r1628,%r1629}, [%rd1319];
	// end inline asm
	mov.b32 	%f7451, %r1626;
	mov.b32 	%f7452, %r1627;
	mov.b32 	%f7453, %r1628;
	mov.b32 	%f7454, %r1629;

$L__BB4_251:
	setp.eq.s32 	%p210, %r2519, %r1614;
	@%p210 bra 	$L__BB4_253;

	mul.ftz.f32 	%f4945, %f7430, %f7460;
	fma.rn.ftz.f32 	%f4946, %f7426, %f7459, %f4945;
	fma.rn.ftz.f32 	%f1703, %f7434, %f7461, %f4946;
	mul.ftz.f32 	%f4947, %f7429, %f7460;
	fma.rn.ftz.f32 	%f4948, %f7425, %f7459, %f4947;
	fma.rn.ftz.f32 	%f1704, %f7433, %f7461, %f4948;
	mul.ftz.f32 	%f4949, %f7428, %f7460;
	fma.rn.ftz.f32 	%f4950, %f7424, %f7459, %f4949;
	fma.rn.ftz.f32 	%f1705, %f7432, %f7461, %f4950;
	mul.ftz.f32 	%f4951, %f7427, %f7460;
	fma.rn.ftz.f32 	%f4952, %f7423, %f7459, %f4951;
	fma.rn.ftz.f32 	%f4953, %f7431, %f7461, %f4952;
	add.ftz.f32 	%f7462, %f7462, %f4953;
	mul.ftz.f32 	%f4954, %f7430, %f7456;
	fma.rn.ftz.f32 	%f4955, %f7426, %f7455, %f4954;
	fma.rn.ftz.f32 	%f1707, %f7434, %f7457, %f4955;
	mul.ftz.f32 	%f4956, %f7429, %f7456;
	fma.rn.ftz.f32 	%f4957, %f7425, %f7455, %f4956;
	fma.rn.ftz.f32 	%f1708, %f7433, %f7457, %f4957;
	mul.ftz.f32 	%f4958, %f7428, %f7456;
	fma.rn.ftz.f32 	%f4959, %f7424, %f7455, %f4958;
	fma.rn.ftz.f32 	%f1709, %f7432, %f7457, %f4959;
	mul.ftz.f32 	%f4960, %f7427, %f7456;
	fma.rn.ftz.f32 	%f4961, %f7423, %f7455, %f4960;
	fma.rn.ftz.f32 	%f4962, %f7431, %f7457, %f4961;
	add.ftz.f32 	%f7458, %f7458, %f4962;
	mul.ftz.f32 	%f4963, %f7430, %f7452;
	fma.rn.ftz.f32 	%f4964, %f7426, %f7451, %f4963;
	fma.rn.ftz.f32 	%f1711, %f7434, %f7453, %f4964;
	mul.ftz.f32 	%f4965, %f7429, %f7452;
	fma.rn.ftz.f32 	%f4966, %f7425, %f7451, %f4965;
	fma.rn.ftz.f32 	%f1712, %f7433, %f7453, %f4966;
	mul.ftz.f32 	%f4967, %f7428, %f7452;
	fma.rn.ftz.f32 	%f4968, %f7424, %f7451, %f4967;
	fma.rn.ftz.f32 	%f1713, %f7432, %f7453, %f4968;
	mul.ftz.f32 	%f4969, %f7427, %f7452;
	fma.rn.ftz.f32 	%f4970, %f7423, %f7451, %f4969;
	fma.rn.ftz.f32 	%f4971, %f7431, %f7453, %f4970;
	add.ftz.f32 	%f7454, %f7454, %f4971;
	mov.f32 	%f7451, %f1711;
	mov.f32 	%f7452, %f1712;
	mov.f32 	%f7453, %f1713;
	mov.f32 	%f7455, %f1707;
	mov.f32 	%f7456, %f1708;
	mov.f32 	%f7457, %f1709;
	mov.f32 	%f7459, %f1703;
	mov.f32 	%f7460, %f1704;
	mov.f32 	%f7461, %f1705;

$L__BB4_253:
	setp.gt.s32 	%p211, %r2519, 1;
	mov.u32 	%r2519, %r1615;
	mov.f32 	%f7423, %f7462;
	mov.f32 	%f7424, %f7461;
	mov.f32 	%f7425, %f7460;
	mov.f32 	%f7426, %f7459;
	mov.f32 	%f7427, %f7458;
	mov.f32 	%f7428, %f7457;
	mov.f32 	%f7429, %f7456;
	mov.f32 	%f7430, %f7455;
	mov.f32 	%f7431, %f7454;
	mov.f32 	%f7432, %f7453;
	mov.f32 	%f7433, %f7452;
	mov.f32 	%f7434, %f7451;
	@%p211 bra 	$L__BB4_238;

$L__BB4_254:
	mul.ftz.f32 	%f4972, %f7488, %f7460;
	fma.rn.ftz.f32 	%f4973, %f7487, %f7459, %f4972;
	fma.rn.ftz.f32 	%f4974, %f7489, %f7461, %f4973;
	mul.ftz.f32 	%f4975, %f7488, %f7456;
	fma.rn.ftz.f32 	%f4976, %f7487, %f7455, %f4975;
	fma.rn.ftz.f32 	%f4977, %f7489, %f7457, %f4976;
	mul.ftz.f32 	%f4978, %f7488, %f7452;
	fma.rn.ftz.f32 	%f4979, %f7487, %f7451, %f4978;
	fma.rn.ftz.f32 	%f4980, %f7489, %f7453, %f4979;
	add.ftz.f32 	%f7489, %f7454, %f4980;
	add.ftz.f32 	%f7488, %f7458, %f4977;
	add.ftz.f32 	%f7487, %f7462, %f4974;

$L__BB4_255:
	mul.wide.u32 	%rd1426, %r77, 44;
	add.s64 	%rd108, %rd91, %rd1426;
	ld.f32 	%f7554, [%rd108];
	ld.f32 	%f7555, [%rd108+4];
	ld.f32 	%f7556, [%rd108+8];
	// begin inline asm
	call (%r1764), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p212, %r1764, 0;
	@%p212 bra 	$L__BB4_275;

	// begin inline asm
	call (%r1765), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f4981), _optix_get_ray_time, ();
	// end inline asm
	setp.lt.s32 	%p213, %r1765, 1;
	@%p213 bra 	$L__BB4_274;

	mov.u32 	%r2520, %r1765;

$L__BB4_258:
	.pragma "nounroll";
	add.s32 	%r1766, %r2520, -1;
	// begin inline asm
	call (%rd1427), _optix_get_transform_list_handle, (%r1766);
	// end inline asm
	// begin inline asm
	call (%r1767), _optix_get_transform_type_from_handle, (%rd1427);
	// end inline asm
	or.b32  	%r1768, %r1767, 1;
	setp.eq.s32 	%p214, %r1768, 3;
	@%p214 bra 	$L__BB4_265;
	bra.uni 	$L__BB4_259;

$L__BB4_265:
	setp.eq.s32 	%p218, %r1767, 2;
	@%p218 bra 	$L__BB4_269;
	bra.uni 	$L__BB4_266;

$L__BB4_269:
	// begin inline asm
	call (%rd1499), _optix_get_matrix_motion_transform_from_handle, (%rd1427);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd1501, %rd1499;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1856,%r1857,%r1858,%r1859}, [%rd1501];
	// end inline asm
	add.s64 	%rd1505, %rd1499, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1504, %rd1505;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1860,%r1861,%r1862,%r1863}, [%rd1504];
	// end inline asm
	add.s64 	%rd1508, %rd1499, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1507, %rd1508;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1864,%r1865,%r1866,%r1867}, [%rd1507];
	// end inline asm
	add.s64 	%rd1511, %rd1499, 48;
	// begin inline asm
	cvta.to.global.u64 %rd1510, %rd1511;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1868,%r1869,%r1870,%r1871}, [%rd1510];
	// end inline asm
	add.s64 	%rd1514, %rd1499, 64;
	// begin inline asm
	cvta.to.global.u64 %rd1513, %rd1514;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1872,%r1873,%r1874,%r1875}, [%rd1513];
	// end inline asm
	add.s64 	%rd1517, %rd1499, 80;
	// begin inline asm
	cvta.to.global.u64 %rd1516, %rd1517;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1876,%r1877,%r1878,%r1879}, [%rd1516];
	// end inline asm
	add.s64 	%rd1520, %rd1499, 96;
	// begin inline asm
	cvta.to.global.u64 %rd1519, %rd1520;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1880,%r1881,%r1882,%r1883}, [%rd1519];
	// end inline asm
	add.s64 	%rd1523, %rd1499, 112;
	// begin inline asm
	cvta.to.global.u64 %rd1522, %rd1523;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1884,%r1885,%r1886,%r1887}, [%rd1522];
	// end inline asm
	mov.b32 	%f5102, %r1859;
	mov.b32 	%f5103, %r1860;
	and.b32  	%r1900, %r1858, 65535;
	add.s32 	%r1901, %r1900, -1;
	cvt.rn.f32.s32 	%f5104, %r1901;
	sub.ftz.f32 	%f5105, %f4981, %f5102;
	sub.ftz.f32 	%f5106, %f5103, %f5102;
	div.approx.ftz.f32 	%f5107, %f5105, %f5106;
	mul.ftz.f32 	%f5108, %f5107, %f5104;
	min.ftz.f32 	%f5109, %f5104, %f5108;
	mov.f32 	%f5110, 0f00000000;
	max.ftz.f32 	%f5111, %f5110, %f5109;
	setp.num.ftz.f32 	%p221, %f5111, %f5111;
	selp.f32 	%f5112, %f5111, 0f00000000, %p221;
	cvt.rmi.ftz.f32.f32 	%f5113, %f5112;
	add.ftz.f32 	%f5114, %f5104, 0fBF800000;
	min.ftz.f32 	%f5115, %f5113, %f5114;
	sub.ftz.f32 	%f1837, %f5112, %f5115;
	cvt.rzi.ftz.s32.f32 	%r1902, %f5115;
	cvt.s64.s32 	%rd115, %r1902;
	mul.wide.s32 	%rd1534, %r1902, 48;
	add.s64 	%rd1526, %rd1508, %rd1534;
	// begin inline asm
	cvta.to.global.u64 %rd1525, %rd1526;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1888,%r1889,%r1890,%r1891}, [%rd1525];
	// end inline asm
	mov.b32 	%f7526, %r1888;
	mov.b32 	%f7527, %r1889;
	mov.b32 	%f7528, %r1890;
	mov.b32 	%f7529, %r1891;
	add.s64 	%rd1529, %rd1526, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1528, %rd1529;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1892,%r1893,%r1894,%r1895}, [%rd1528];
	// end inline asm
	mov.b32 	%f7522, %r1892;
	mov.b32 	%f7523, %r1893;
	mov.b32 	%f7524, %r1894;
	mov.b32 	%f7525, %r1895;
	add.s64 	%rd1532, %rd1526, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1531, %rd1532;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1896,%r1897,%r1898,%r1899}, [%rd1531];
	// end inline asm
	mov.b32 	%f7518, %r1896;
	mov.b32 	%f7519, %r1897;
	mov.b32 	%f7520, %r1898;
	mov.b32 	%f7521, %r1899;
	setp.leu.ftz.f32 	%p222, %f1837, 0f00000000;
	@%p222 bra 	$L__BB4_271;

	mov.f32 	%f5116, 0f3F800000;
	sub.ftz.f32 	%f5117, %f5116, %f1837;
	mul.lo.s64 	%rd1544, %rd115, 48;
	add.s64 	%rd1545, %rd1499, %rd1544;
	add.s64 	%rd1536, %rd1545, 80;
	// begin inline asm
	cvta.to.global.u64 %rd1535, %rd1536;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1903,%r1904,%r1905,%r1906}, [%rd1535];
	// end inline asm
	mov.b32 	%f5118, %r1903;
	mov.b32 	%f5119, %r1904;
	mov.b32 	%f5120, %r1905;
	mov.b32 	%f5121, %r1906;
	mul.ftz.f32 	%f5122, %f1837, %f5118;
	mul.ftz.f32 	%f5123, %f1837, %f5119;
	mul.ftz.f32 	%f5124, %f1837, %f5120;
	mul.ftz.f32 	%f5125, %f1837, %f5121;
	fma.rn.ftz.f32 	%f7526, %f5117, %f7526, %f5122;
	fma.rn.ftz.f32 	%f7527, %f5117, %f7527, %f5123;
	fma.rn.ftz.f32 	%f7528, %f5117, %f7528, %f5124;
	fma.rn.ftz.f32 	%f7529, %f5117, %f7529, %f5125;
	add.s64 	%rd1539, %rd1545, 96;
	// begin inline asm
	cvta.to.global.u64 %rd1538, %rd1539;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1907,%r1908,%r1909,%r1910}, [%rd1538];
	// end inline asm
	mov.b32 	%f5126, %r1907;
	mov.b32 	%f5127, %r1908;
	mov.b32 	%f5128, %r1909;
	mov.b32 	%f5129, %r1910;
	mul.ftz.f32 	%f5130, %f1837, %f5126;
	mul.ftz.f32 	%f5131, %f1837, %f5127;
	mul.ftz.f32 	%f5132, %f1837, %f5128;
	mul.ftz.f32 	%f5133, %f1837, %f5129;
	fma.rn.ftz.f32 	%f7522, %f5117, %f7522, %f5130;
	fma.rn.ftz.f32 	%f7523, %f5117, %f7523, %f5131;
	fma.rn.ftz.f32 	%f7524, %f5117, %f7524, %f5132;
	fma.rn.ftz.f32 	%f7525, %f5117, %f7525, %f5133;
	add.s64 	%rd1542, %rd1545, 112;
	// begin inline asm
	cvta.to.global.u64 %rd1541, %rd1542;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1911,%r1912,%r1913,%r1914}, [%rd1541];
	// end inline asm
	mov.b32 	%f5134, %r1911;
	mov.b32 	%f5135, %r1912;
	mov.b32 	%f5136, %r1913;
	mov.b32 	%f5137, %r1914;
	mul.ftz.f32 	%f5138, %f1837, %f5134;
	mul.ftz.f32 	%f5139, %f1837, %f5135;
	mul.ftz.f32 	%f5140, %f1837, %f5136;
	mul.ftz.f32 	%f5141, %f1837, %f5137;
	fma.rn.ftz.f32 	%f7518, %f5117, %f7518, %f5138;
	fma.rn.ftz.f32 	%f7519, %f5117, %f7519, %f5139;
	fma.rn.ftz.f32 	%f7520, %f5117, %f7520, %f5140;
	fma.rn.ftz.f32 	%f7521, %f5117, %f7521, %f5141;
	bra.uni 	$L__BB4_271;

$L__BB4_259:
	mov.f32 	%f7518, 0f00000000;
	mov.f32 	%f7520, 0f3F800000;
	setp.eq.s32 	%p215, %r1767, 4;
	@%p215 bra 	$L__BB4_261;

	setp.ne.s32 	%p216, %r1767, 1;
	mov.f32 	%f7519, %f7518;
	mov.f32 	%f7521, %f7518;
	mov.f32 	%f7522, %f7518;
	mov.f32 	%f7523, %f7520;
	mov.f32 	%f7524, %f7518;
	mov.f32 	%f7525, %f7518;
	mov.f32 	%f7526, %f7520;
	mov.f32 	%f7527, %f7518;
	mov.f32 	%f7528, %f7518;
	mov.f32 	%f7529, %f7518;
	@%p216 bra 	$L__BB4_271;

$L__BB4_261:
	@%p215 bra 	$L__BB4_263;
	bra.uni 	$L__BB4_262;

$L__BB4_263:
	// begin inline asm
	call (%rd1973), _optix_get_instance_transform_from_handle, (%rd1427);
	// end inline asm
	bra.uni 	$L__BB4_264;

$L__BB4_266:
	// begin inline asm
	call (%rd1442), _optix_get_srt_motion_transform_from_handle, (%rd1427);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd1444, %rd1442;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1781,%r1782,%r1783,%r1784}, [%rd1444];
	// end inline asm
	add.s64 	%rd1448, %rd1442, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1447, %rd1448;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1785,%r1786,%r1787,%r1788}, [%rd1447];
	// end inline asm
	add.s64 	%rd1451, %rd1442, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1450, %rd1451;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1789,%r1790,%r1791,%r1792}, [%rd1450];
	// end inline asm
	add.s64 	%rd1454, %rd1442, 48;
	// begin inline asm
	cvta.to.global.u64 %rd1453, %rd1454;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1793,%r1794,%r1795,%r1796}, [%rd1453];
	// end inline asm
	add.s64 	%rd1457, %rd1442, 64;
	// begin inline asm
	cvta.to.global.u64 %rd1456, %rd1457;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1797,%r1798,%r1799,%r1800}, [%rd1456];
	// end inline asm
	add.s64 	%rd1460, %rd1442, 80;
	// begin inline asm
	cvta.to.global.u64 %rd1459, %rd1460;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1801,%r1802,%r1803,%r1804}, [%rd1459];
	// end inline asm
	add.s64 	%rd1463, %rd1442, 96;
	// begin inline asm
	cvta.to.global.u64 %rd1462, %rd1463;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1805,%r1806,%r1807,%r1808}, [%rd1462];
	// end inline asm
	add.s64 	%rd1466, %rd1442, 112;
	// begin inline asm
	cvta.to.global.u64 %rd1465, %rd1466;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1809,%r1810,%r1811,%r1812}, [%rd1465];
	// end inline asm
	add.s64 	%rd1469, %rd1442, 128;
	// begin inline asm
	cvta.to.global.u64 %rd1468, %rd1469;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1813,%r1814,%r1815,%r1816}, [%rd1468];
	// end inline asm
	add.s64 	%rd1472, %rd1442, 144;
	// begin inline asm
	cvta.to.global.u64 %rd1471, %rd1472;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1817,%r1818,%r1819,%r1820}, [%rd1471];
	// end inline asm
	mov.b32 	%f4996, %r1784;
	mov.b32 	%f4997, %r1785;
	and.b32  	%r1837, %r1783, 65535;
	add.s32 	%r1838, %r1837, -1;
	cvt.rn.f32.s32 	%f4998, %r1838;
	sub.ftz.f32 	%f4999, %f4981, %f4996;
	sub.ftz.f32 	%f5000, %f4997, %f4996;
	div.approx.ftz.f32 	%f5001, %f4999, %f5000;
	mul.ftz.f32 	%f5002, %f5001, %f4998;
	min.ftz.f32 	%f5003, %f4998, %f5002;
	mov.f32 	%f5004, 0f00000000;
	max.ftz.f32 	%f5005, %f5004, %f5003;
	setp.num.ftz.f32 	%p219, %f5005, %f5005;
	selp.f32 	%f5006, %f5005, 0f00000000, %p219;
	cvt.rmi.ftz.f32.f32 	%f5007, %f5006;
	add.ftz.f32 	%f5008, %f4998, 0fBF800000;
	min.ftz.f32 	%f5009, %f5007, %f5008;
	sub.ftz.f32 	%f1776, %f5006, %f5009;
	cvt.rzi.ftz.s32.f32 	%r1839, %f5009;
	mul.wide.s32 	%rd1486, %r1839, 64;
	add.s64 	%rd1475, %rd1451, %rd1486;
	// begin inline asm
	cvta.to.global.u64 %rd1474, %rd1475;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1821,%r1822,%r1823,%r1824}, [%rd1474];
	// end inline asm
	mov.b32 	%f7502, %r1821;
	mov.b32 	%f7503, %r1822;
	mov.b32 	%f7504, %r1823;
	mov.b32 	%f7505, %r1824;
	add.s64 	%rd1478, %rd1475, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1477, %rd1478;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1825,%r1826,%r1827,%r1828}, [%rd1477];
	// end inline asm
	mov.b32 	%f7506, %r1825;
	mov.b32 	%f7507, %r1826;
	mov.b32 	%f7508, %r1827;
	mov.b32 	%f7509, %r1828;
	add.s64 	%rd1481, %rd1475, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1480, %rd1481;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1829,%r1830,%r1831,%r1832}, [%rd1480];
	// end inline asm
	mov.b32 	%f7510, %r1829;
	mov.b32 	%f7511, %r1830;
	mov.b32 	%f7512, %r1831;
	mov.b32 	%f7513, %r1832;
	add.s64 	%rd1484, %rd1475, 48;
	// begin inline asm
	cvta.to.global.u64 %rd1483, %rd1484;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1833,%r1834,%r1835,%r1836}, [%rd1483];
	// end inline asm
	mov.b32 	%f7514, %r1833;
	mov.b32 	%f7515, %r1834;
	mov.b32 	%f7516, %r1835;
	mov.b32 	%f7517, %r1836;
	setp.leu.ftz.f32 	%p220, %f1776, 0f00000000;
	@%p220 bra 	$L__BB4_268;

	mov.f32 	%f5010, 0f3F800000;
	sub.ftz.f32 	%f5011, %f5010, %f1776;
	add.s64 	%rd1488, %rd1475, 64;
	// begin inline asm
	cvta.to.global.u64 %rd1487, %rd1488;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1840,%r1841,%r1842,%r1843}, [%rd1487];
	// end inline asm
	mov.b32 	%f5012, %r1840;
	mov.b32 	%f5013, %r1841;
	mov.b32 	%f5014, %r1842;
	mov.b32 	%f5015, %r1843;
	mul.ftz.f32 	%f5016, %f1776, %f5012;
	mul.ftz.f32 	%f5017, %f1776, %f5013;
	mul.ftz.f32 	%f5018, %f1776, %f5014;
	mul.ftz.f32 	%f5019, %f1776, %f5015;
	fma.rn.ftz.f32 	%f7502, %f5011, %f7502, %f5016;
	fma.rn.ftz.f32 	%f7503, %f5011, %f7503, %f5017;
	fma.rn.ftz.f32 	%f7504, %f5011, %f7504, %f5018;
	fma.rn.ftz.f32 	%f7505, %f5011, %f7505, %f5019;
	add.s64 	%rd1491, %rd1475, 80;
	// begin inline asm
	cvta.to.global.u64 %rd1490, %rd1491;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1844,%r1845,%r1846,%r1847}, [%rd1490];
	// end inline asm
	mov.b32 	%f5020, %r1844;
	mov.b32 	%f5021, %r1845;
	mov.b32 	%f5022, %r1846;
	mov.b32 	%f5023, %r1847;
	mul.ftz.f32 	%f5024, %f1776, %f5020;
	mul.ftz.f32 	%f5025, %f1776, %f5021;
	mul.ftz.f32 	%f5026, %f1776, %f5022;
	mul.ftz.f32 	%f5027, %f1776, %f5023;
	fma.rn.ftz.f32 	%f7506, %f5011, %f7506, %f5024;
	fma.rn.ftz.f32 	%f7507, %f5011, %f7507, %f5025;
	fma.rn.ftz.f32 	%f7508, %f5011, %f7508, %f5026;
	fma.rn.ftz.f32 	%f7509, %f5011, %f7509, %f5027;
	add.s64 	%rd1494, %rd1475, 96;
	// begin inline asm
	cvta.to.global.u64 %rd1493, %rd1494;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1848,%r1849,%r1850,%r1851}, [%rd1493];
	// end inline asm
	mov.b32 	%f5028, %r1848;
	mov.b32 	%f5029, %r1849;
	mov.b32 	%f5030, %r1850;
	mov.b32 	%f5031, %r1851;
	mul.ftz.f32 	%f5032, %f1776, %f5028;
	mul.ftz.f32 	%f5033, %f1776, %f5029;
	mul.ftz.f32 	%f5034, %f1776, %f5030;
	mul.ftz.f32 	%f5035, %f1776, %f5031;
	fma.rn.ftz.f32 	%f7510, %f5011, %f7510, %f5032;
	fma.rn.ftz.f32 	%f5036, %f5011, %f7511, %f5033;
	fma.rn.ftz.f32 	%f5037, %f5011, %f7512, %f5034;
	fma.rn.ftz.f32 	%f5038, %f5011, %f7513, %f5035;
	add.s64 	%rd1497, %rd1475, 112;
	// begin inline asm
	cvta.to.global.u64 %rd1496, %rd1497;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1852,%r1853,%r1854,%r1855}, [%rd1496];
	// end inline asm
	mov.b32 	%f5039, %r1852;
	mov.b32 	%f5040, %r1853;
	mov.b32 	%f5041, %r1854;
	mov.b32 	%f5042, %r1855;
	mul.ftz.f32 	%f5043, %f1776, %f5039;
	mul.ftz.f32 	%f5044, %f1776, %f5040;
	mul.ftz.f32 	%f5045, %f1776, %f5041;
	mul.ftz.f32 	%f5046, %f1776, %f5042;
	fma.rn.ftz.f32 	%f5047, %f5011, %f7514, %f5043;
	fma.rn.ftz.f32 	%f7515, %f5011, %f7515, %f5044;
	fma.rn.ftz.f32 	%f7516, %f5011, %f7516, %f5045;
	fma.rn.ftz.f32 	%f7517, %f5011, %f7517, %f5046;
	mul.ftz.f32 	%f5048, %f5037, %f5037;
	fma.rn.ftz.f32 	%f5049, %f5036, %f5036, %f5048;
	fma.rn.ftz.f32 	%f5050, %f5038, %f5038, %f5049;
	fma.rn.ftz.f32 	%f5051, %f5047, %f5047, %f5050;
	rsqrt.approx.ftz.f32 	%f5052, %f5051;
	mul.ftz.f32 	%f7511, %f5036, %f5052;
	mul.ftz.f32 	%f7512, %f5037, %f5052;
	mul.ftz.f32 	%f7513, %f5038, %f5052;
	mul.ftz.f32 	%f7514, %f5052, %f5047;

$L__BB4_268:
	mul.ftz.f32 	%f5053, %f7512, %f7512;
	mul.ftz.f32 	%f5054, %f7511, %f7511;
	sub.ftz.f32 	%f5055, %f5054, %f5053;
	mul.ftz.f32 	%f5056, %f7513, %f7513;
	sub.ftz.f32 	%f5057, %f5055, %f5056;
	fma.rn.ftz.f32 	%f5058, %f7514, %f7514, %f5057;
	mul.ftz.f32 	%f5059, %f7513, %f7514;
	mul.ftz.f32 	%f5060, %f7511, %f7512;
	sub.ftz.f32 	%f5061, %f5060, %f5059;
	add.ftz.f32 	%f5062, %f5061, %f5061;
	mul.ftz.f32 	%f5063, %f7512, %f7514;
	mul.ftz.f32 	%f5064, %f7511, %f7513;
	add.ftz.f32 	%f5065, %f5064, %f5063;
	add.ftz.f32 	%f5066, %f5065, %f5065;
	add.ftz.f32 	%f5067, %f5060, %f5059;
	add.ftz.f32 	%f5068, %f5067, %f5067;
	sub.ftz.f32 	%f5069, %f5053, %f5054;
	sub.ftz.f32 	%f5070, %f5069, %f5056;
	fma.rn.ftz.f32 	%f5071, %f7514, %f7514, %f5070;
	mul.ftz.f32 	%f5072, %f7511, %f7514;
	mul.ftz.f32 	%f5073, %f7512, %f7513;
	sub.ftz.f32 	%f5074, %f5073, %f5072;
	add.ftz.f32 	%f5075, %f5074, %f5074;
	sub.ftz.f32 	%f5076, %f5064, %f5063;
	add.ftz.f32 	%f5077, %f5076, %f5076;
	add.ftz.f32 	%f5078, %f5073, %f5072;
	add.ftz.f32 	%f5079, %f5078, %f5078;
	neg.ftz.f32 	%f5080, %f5054;
	sub.ftz.f32 	%f5081, %f5080, %f5053;
	add.ftz.f32 	%f5082, %f5081, %f5056;
	fma.rn.ftz.f32 	%f5083, %f7514, %f7514, %f5082;
	mul.ftz.f32 	%f5084, %f7508, %f5062;
	fma.rn.ftz.f32 	%f5085, %f7505, %f5058, %f5084;
	fma.rn.ftz.f32 	%f5086, %f7510, %f5066, %f5085;
	add.ftz.f32 	%f7529, %f7515, %f5086;
	mul.ftz.f32 	%f5087, %f7505, %f5068;
	fma.rn.ftz.f32 	%f5088, %f7508, %f5071, %f5087;
	fma.rn.ftz.f32 	%f5089, %f7510, %f5075, %f5088;
	add.ftz.f32 	%f7525, %f7516, %f5089;
	mul.ftz.f32 	%f5090, %f7508, %f5079;
	fma.rn.ftz.f32 	%f5091, %f7505, %f5077, %f5090;
	fma.rn.ftz.f32 	%f5092, %f7510, %f5083, %f5091;
	add.ftz.f32 	%f7521, %f7517, %f5092;
	mul.ftz.f32 	%f5093, %f7507, %f5062;
	fma.rn.ftz.f32 	%f5094, %f7504, %f5058, %f5093;
	fma.rn.ftz.f32 	%f7528, %f7509, %f5066, %f5094;
	mul.ftz.f32 	%f5095, %f7504, %f5068;
	fma.rn.ftz.f32 	%f5096, %f7507, %f5071, %f5095;
	fma.rn.ftz.f32 	%f7524, %f7509, %f5075, %f5096;
	mul.ftz.f32 	%f5097, %f7507, %f5079;
	fma.rn.ftz.f32 	%f5098, %f7504, %f5077, %f5097;
	fma.rn.ftz.f32 	%f7520, %f7509, %f5083, %f5098;
	mul.ftz.f32 	%f5099, %f7506, %f5062;
	fma.rn.ftz.f32 	%f7527, %f7503, %f5058, %f5099;
	mul.ftz.f32 	%f5100, %f7503, %f5068;
	fma.rn.ftz.f32 	%f7523, %f7506, %f5071, %f5100;
	mul.ftz.f32 	%f5101, %f7506, %f5079;
	fma.rn.ftz.f32 	%f7519, %f7503, %f5077, %f5101;
	mul.ftz.f32 	%f7526, %f7502, %f5058;
	mul.ftz.f32 	%f7522, %f7502, %f5068;
	mul.ftz.f32 	%f7518, %f7502, %f5077;
	bra.uni 	$L__BB4_271;

$L__BB4_262:
	// begin inline asm
	call (%rd1429), _optix_get_static_transform_from_handle, (%rd1427);
	// end inline asm
	add.s64 	%rd1973, %rd1429, 16;

$L__BB4_264:
	// begin inline asm
	cvta.to.global.u64 %rd1433, %rd1973;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1769,%r1770,%r1771,%r1772}, [%rd1433];
	// end inline asm
	mov.b32 	%f7526, %r1769;
	mov.b32 	%f7527, %r1770;
	mov.b32 	%f7528, %r1771;
	mov.b32 	%f7529, %r1772;
	add.s64 	%rd1437, %rd1973, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1436, %rd1437;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1773,%r1774,%r1775,%r1776}, [%rd1436];
	// end inline asm
	mov.b32 	%f7522, %r1773;
	mov.b32 	%f7523, %r1774;
	mov.b32 	%f7524, %r1775;
	mov.b32 	%f7525, %r1776;
	add.s64 	%rd1440, %rd1973, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1439, %rd1440;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1777,%r1778,%r1779,%r1780}, [%rd1439];
	// end inline asm
	mov.b32 	%f7518, %r1777;
	mov.b32 	%f7519, %r1778;
	mov.b32 	%f7520, %r1779;
	mov.b32 	%f7521, %r1780;

$L__BB4_271:
	setp.eq.s32 	%p223, %r2520, %r1765;
	@%p223 bra 	$L__BB4_273;

	mul.ftz.f32 	%f5142, %f7497, %f7527;
	fma.rn.ftz.f32 	%f5143, %f7493, %f7526, %f5142;
	fma.rn.ftz.f32 	%f1874, %f7501, %f7528, %f5143;
	mul.ftz.f32 	%f5144, %f7496, %f7527;
	fma.rn.ftz.f32 	%f5145, %f7492, %f7526, %f5144;
	fma.rn.ftz.f32 	%f1875, %f7500, %f7528, %f5145;
	mul.ftz.f32 	%f5146, %f7495, %f7527;
	fma.rn.ftz.f32 	%f5147, %f7491, %f7526, %f5146;
	fma.rn.ftz.f32 	%f1876, %f7499, %f7528, %f5147;
	mul.ftz.f32 	%f5148, %f7494, %f7527;
	fma.rn.ftz.f32 	%f5149, %f7490, %f7526, %f5148;
	fma.rn.ftz.f32 	%f5150, %f7498, %f7528, %f5149;
	add.ftz.f32 	%f7529, %f7529, %f5150;
	mul.ftz.f32 	%f5151, %f7497, %f7523;
	fma.rn.ftz.f32 	%f5152, %f7493, %f7522, %f5151;
	fma.rn.ftz.f32 	%f1878, %f7501, %f7524, %f5152;
	mul.ftz.f32 	%f5153, %f7496, %f7523;
	fma.rn.ftz.f32 	%f5154, %f7492, %f7522, %f5153;
	fma.rn.ftz.f32 	%f1879, %f7500, %f7524, %f5154;
	mul.ftz.f32 	%f5155, %f7495, %f7523;
	fma.rn.ftz.f32 	%f5156, %f7491, %f7522, %f5155;
	fma.rn.ftz.f32 	%f1880, %f7499, %f7524, %f5156;
	mul.ftz.f32 	%f5157, %f7494, %f7523;
	fma.rn.ftz.f32 	%f5158, %f7490, %f7522, %f5157;
	fma.rn.ftz.f32 	%f5159, %f7498, %f7524, %f5158;
	add.ftz.f32 	%f7525, %f7525, %f5159;
	mul.ftz.f32 	%f5160, %f7497, %f7519;
	fma.rn.ftz.f32 	%f5161, %f7493, %f7518, %f5160;
	fma.rn.ftz.f32 	%f1882, %f7501, %f7520, %f5161;
	mul.ftz.f32 	%f5162, %f7496, %f7519;
	fma.rn.ftz.f32 	%f5163, %f7492, %f7518, %f5162;
	fma.rn.ftz.f32 	%f1883, %f7500, %f7520, %f5163;
	mul.ftz.f32 	%f5164, %f7495, %f7519;
	fma.rn.ftz.f32 	%f5165, %f7491, %f7518, %f5164;
	fma.rn.ftz.f32 	%f1884, %f7499, %f7520, %f5165;
	mul.ftz.f32 	%f5166, %f7494, %f7519;
	fma.rn.ftz.f32 	%f5167, %f7490, %f7518, %f5166;
	fma.rn.ftz.f32 	%f5168, %f7498, %f7520, %f5167;
	add.ftz.f32 	%f7521, %f7521, %f5168;
	mov.f32 	%f7518, %f1882;
	mov.f32 	%f7519, %f1883;
	mov.f32 	%f7520, %f1884;
	mov.f32 	%f7522, %f1878;
	mov.f32 	%f7523, %f1879;
	mov.f32 	%f7524, %f1880;
	mov.f32 	%f7526, %f1874;
	mov.f32 	%f7527, %f1875;
	mov.f32 	%f7528, %f1876;

$L__BB4_273:
	setp.gt.s32 	%p224, %r2520, 1;
	mov.u32 	%r2520, %r1766;
	mov.f32 	%f7490, %f7529;
	mov.f32 	%f7491, %f7528;
	mov.f32 	%f7492, %f7527;
	mov.f32 	%f7493, %f7526;
	mov.f32 	%f7494, %f7525;
	mov.f32 	%f7495, %f7524;
	mov.f32 	%f7496, %f7523;
	mov.f32 	%f7497, %f7522;
	mov.f32 	%f7498, %f7521;
	mov.f32 	%f7499, %f7520;
	mov.f32 	%f7500, %f7519;
	mov.f32 	%f7501, %f7518;
	@%p224 bra 	$L__BB4_258;

$L__BB4_274:
	mul.ftz.f32 	%f5169, %f7555, %f7527;
	fma.rn.ftz.f32 	%f5170, %f7554, %f7526, %f5169;
	fma.rn.ftz.f32 	%f5171, %f7556, %f7528, %f5170;
	mul.ftz.f32 	%f5172, %f7555, %f7523;
	fma.rn.ftz.f32 	%f5173, %f7554, %f7522, %f5172;
	fma.rn.ftz.f32 	%f5174, %f7556, %f7524, %f5173;
	mul.ftz.f32 	%f5175, %f7555, %f7519;
	fma.rn.ftz.f32 	%f5176, %f7554, %f7518, %f5175;
	fma.rn.ftz.f32 	%f5177, %f7556, %f7520, %f5176;
	add.ftz.f32 	%f7556, %f7521, %f5177;
	add.ftz.f32 	%f7555, %f7525, %f5174;
	add.ftz.f32 	%f7554, %f7529, %f5171;

$L__BB4_275:
	shr.u32 	%r1916, %r57, 9;
	or.b32  	%r1917, %r1916, 1065353216;
	mov.b32 	%f5178, %r1917;
	add.ftz.f32 	%f5179, %f5178, 0fBF800000;
	sqrt.approx.ftz.f32 	%f5180, %f5179;
	mov.f32 	%f5181, 0f3F800000;
	sub.ftz.f32 	%f1925, %f5181, %f5180;
	mul.ftz.f32 	%f1926, %f1395, %f5180;
	sub.ftz.f32 	%f5182, %f5181, %f1925;
	sub.ftz.f32 	%f1927, %f5182, %f1926;
	mul.ftz.f32 	%f5183, %f7487, %f1926;
	mul.ftz.f32 	%f5184, %f7488, %f1926;
	mul.ftz.f32 	%f5185, %f7489, %f1926;
	fma.rn.ftz.f32 	%f5186, %f7420, %f1925, %f5183;
	fma.rn.ftz.f32 	%f5187, %f7421, %f1925, %f5184;
	fma.rn.ftz.f32 	%f5188, %f7422, %f1925, %f5185;
	fma.rn.ftz.f32 	%f7748, %f7554, %f1927, %f5186;
	fma.rn.ftz.f32 	%f7749, %f7555, %f1927, %f5187;
	fma.rn.ftz.f32 	%f7750, %f7556, %f1927, %f5188;
	ld.f32 	%f7612, [%rd92+12];
	ld.f32 	%f7613, [%rd92+16];
	ld.f32 	%f1936, [%rd92+20];
	// begin inline asm
	call (%r1915), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p225, %r1915, 0;
	@%p225 bra 	$L__BB4_296;

	// begin inline asm
	call (%r1918), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f5189), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p226, %r1918, 0;
	@%p226 bra 	$L__BB4_295;

	mov.u32 	%r2521, 0;

$L__BB4_278:
	.pragma "nounroll";
	// begin inline asm
	call (%rd1546), _optix_get_transform_list_handle, (%r2521);
	// end inline asm
	// begin inline asm
	call (%r1921), _optix_get_transform_type_from_handle, (%rd1546);
	// end inline asm
	or.b32  	%r1922, %r1921, 1;
	setp.eq.s32 	%p227, %r1922, 3;
	@%p227 bra 	$L__BB4_285;
	bra.uni 	$L__BB4_279;

$L__BB4_285:
	setp.eq.s32 	%p231, %r1921, 2;
	@%p231 bra 	$L__BB4_289;
	bra.uni 	$L__BB4_286;

$L__BB4_289:
	// begin inline asm
	call (%rd1618), _optix_get_matrix_motion_transform_from_handle, (%rd1546);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd1620, %rd1618;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2010,%r2011,%r2012,%r2013}, [%rd1620];
	// end inline asm
	add.s64 	%rd1624, %rd1618, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1623, %rd1624;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2014,%r2015,%r2016,%r2017}, [%rd1623];
	// end inline asm
	add.s64 	%rd1627, %rd1618, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1626, %rd1627;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2018,%r2019,%r2020,%r2021}, [%rd1626];
	// end inline asm
	add.s64 	%rd1630, %rd1618, 48;
	// begin inline asm
	cvta.to.global.u64 %rd1629, %rd1630;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2022,%r2023,%r2024,%r2025}, [%rd1629];
	// end inline asm
	add.s64 	%rd1633, %rd1618, 64;
	// begin inline asm
	cvta.to.global.u64 %rd1632, %rd1633;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2026,%r2027,%r2028,%r2029}, [%rd1632];
	// end inline asm
	add.s64 	%rd1636, %rd1618, 80;
	// begin inline asm
	cvta.to.global.u64 %rd1635, %rd1636;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2030,%r2031,%r2032,%r2033}, [%rd1635];
	// end inline asm
	add.s64 	%rd1639, %rd1618, 96;
	// begin inline asm
	cvta.to.global.u64 %rd1638, %rd1639;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2034,%r2035,%r2036,%r2037}, [%rd1638];
	// end inline asm
	add.s64 	%rd1642, %rd1618, 112;
	// begin inline asm
	cvta.to.global.u64 %rd1641, %rd1642;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2038,%r2039,%r2040,%r2041}, [%rd1641];
	// end inline asm
	mov.b32 	%f5286, %r2013;
	mov.b32 	%f5287, %r2014;
	and.b32  	%r2054, %r2012, 65535;
	add.s32 	%r2055, %r2054, -1;
	cvt.rn.f32.s32 	%f5288, %r2055;
	sub.ftz.f32 	%f5289, %f5189, %f5286;
	sub.ftz.f32 	%f5290, %f5287, %f5286;
	div.approx.ftz.f32 	%f5291, %f5289, %f5290;
	mul.ftz.f32 	%f5292, %f5291, %f5288;
	min.ftz.f32 	%f5293, %f5288, %f5292;
	mov.f32 	%f5294, 0f00000000;
	max.ftz.f32 	%f5295, %f5294, %f5293;
	setp.num.ftz.f32 	%p234, %f5295, %f5295;
	selp.f32 	%f5296, %f5295, 0f00000000, %p234;
	cvt.rmi.ftz.f32.f32 	%f5297, %f5296;
	add.ftz.f32 	%f5298, %f5288, 0fBF800000;
	min.ftz.f32 	%f5299, %f5297, %f5298;
	sub.ftz.f32 	%f1996, %f5296, %f5299;
	cvt.rzi.ftz.s32.f32 	%r2056, %f5299;
	cvt.s64.s32 	%rd122, %r2056;
	mul.wide.s32 	%rd1653, %r2056, 48;
	add.s64 	%rd1645, %rd1627, %rd1653;
	// begin inline asm
	cvta.to.global.u64 %rd1644, %rd1645;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2042,%r2043,%r2044,%r2045}, [%rd1644];
	// end inline asm
	mov.b32 	%f7582, %r2042;
	mov.b32 	%f7583, %r2043;
	mov.b32 	%f7584, %r2044;
	add.s64 	%rd1648, %rd1645, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1647, %rd1648;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2046,%r2047,%r2048,%r2049}, [%rd1647];
	// end inline asm
	mov.b32 	%f7579, %r2046;
	mov.b32 	%f7580, %r2047;
	mov.b32 	%f7581, %r2048;
	add.s64 	%rd1651, %rd1645, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1650, %rd1651;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2050,%r2051,%r2052,%r2053}, [%rd1650];
	// end inline asm
	mov.b32 	%f7576, %r2050;
	mov.b32 	%f7577, %r2051;
	mov.b32 	%f7578, %r2052;
	setp.leu.ftz.f32 	%p235, %f1996, 0f00000000;
	@%p235 bra 	$L__BB4_291;

	mov.f32 	%f5300, 0f3F800000;
	sub.ftz.f32 	%f5301, %f5300, %f1996;
	mul.lo.s64 	%rd1663, %rd122, 48;
	add.s64 	%rd1664, %rd1618, %rd1663;
	add.s64 	%rd1655, %rd1664, 80;
	// begin inline asm
	cvta.to.global.u64 %rd1654, %rd1655;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2057,%r2058,%r2059,%r2060}, [%rd1654];
	// end inline asm
	mov.b32 	%f5302, %r2057;
	mov.b32 	%f5303, %r2058;
	mov.b32 	%f5304, %r2059;
	mul.ftz.f32 	%f5305, %f1996, %f5302;
	mul.ftz.f32 	%f5306, %f1996, %f5303;
	mul.ftz.f32 	%f5307, %f1996, %f5304;
	fma.rn.ftz.f32 	%f7582, %f5301, %f7582, %f5305;
	fma.rn.ftz.f32 	%f7583, %f5301, %f7583, %f5306;
	fma.rn.ftz.f32 	%f7584, %f5301, %f7584, %f5307;
	add.s64 	%rd1658, %rd1664, 96;
	// begin inline asm
	cvta.to.global.u64 %rd1657, %rd1658;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2061,%r2062,%r2063,%r2064}, [%rd1657];
	// end inline asm
	mov.b32 	%f5308, %r2061;
	mov.b32 	%f5309, %r2062;
	mov.b32 	%f5310, %r2063;
	mul.ftz.f32 	%f5311, %f1996, %f5308;
	mul.ftz.f32 	%f5312, %f1996, %f5309;
	mul.ftz.f32 	%f5313, %f1996, %f5310;
	fma.rn.ftz.f32 	%f7579, %f5301, %f7579, %f5311;
	fma.rn.ftz.f32 	%f7580, %f5301, %f7580, %f5312;
	fma.rn.ftz.f32 	%f7581, %f5301, %f7581, %f5313;
	add.s64 	%rd1661, %rd1664, 112;
	// begin inline asm
	cvta.to.global.u64 %rd1660, %rd1661;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2065,%r2066,%r2067,%r2068}, [%rd1660];
	// end inline asm
	mov.b32 	%f5314, %r2065;
	mov.b32 	%f5315, %r2066;
	mov.b32 	%f5316, %r2067;
	mul.ftz.f32 	%f5317, %f1996, %f5314;
	mul.ftz.f32 	%f5318, %f1996, %f5315;
	mul.ftz.f32 	%f5319, %f1996, %f5316;
	fma.rn.ftz.f32 	%f7576, %f5301, %f7576, %f5317;
	fma.rn.ftz.f32 	%f7577, %f5301, %f7577, %f5318;
	fma.rn.ftz.f32 	%f7578, %f5301, %f7578, %f5319;
	bra.uni 	$L__BB4_291;

$L__BB4_279:
	mov.f32 	%f7585, 0f00000000;
	mov.f32 	%f7587, 0f3F800000;
	setp.eq.s32 	%p228, %r1921, 4;
	@%p228 bra 	$L__BB4_281;

	setp.ne.s32 	%p229, %r1921, 1;
	mov.f32 	%f7586, %f7585;
	mov.f32 	%f7588, %f7585;
	mov.f32 	%f7589, %f7587;
	mov.f32 	%f7590, %f7585;
	mov.f32 	%f7591, %f7587;
	mov.f32 	%f7592, %f7585;
	mov.f32 	%f7593, %f7585;
	@%p229 bra 	$L__BB4_292;

$L__BB4_281:
	@%p228 bra 	$L__BB4_283;
	bra.uni 	$L__BB4_282;

$L__BB4_283:
	// begin inline asm
	call (%rd1974), _optix_get_instance_inverse_transform_from_handle, (%rd1546);
	// end inline asm
	bra.uni 	$L__BB4_284;

$L__BB4_286:
	// begin inline asm
	call (%rd1561), _optix_get_srt_motion_transform_from_handle, (%rd1546);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd1563, %rd1561;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1935,%r1936,%r1937,%r1938}, [%rd1563];
	// end inline asm
	add.s64 	%rd1567, %rd1561, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1566, %rd1567;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1939,%r1940,%r1941,%r1942}, [%rd1566];
	// end inline asm
	add.s64 	%rd1570, %rd1561, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1569, %rd1570;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1943,%r1944,%r1945,%r1946}, [%rd1569];
	// end inline asm
	add.s64 	%rd1573, %rd1561, 48;
	// begin inline asm
	cvta.to.global.u64 %rd1572, %rd1573;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1947,%r1948,%r1949,%r1950}, [%rd1572];
	// end inline asm
	add.s64 	%rd1576, %rd1561, 64;
	// begin inline asm
	cvta.to.global.u64 %rd1575, %rd1576;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1951,%r1952,%r1953,%r1954}, [%rd1575];
	// end inline asm
	add.s64 	%rd1579, %rd1561, 80;
	// begin inline asm
	cvta.to.global.u64 %rd1578, %rd1579;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1955,%r1956,%r1957,%r1958}, [%rd1578];
	// end inline asm
	add.s64 	%rd1582, %rd1561, 96;
	// begin inline asm
	cvta.to.global.u64 %rd1581, %rd1582;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1959,%r1960,%r1961,%r1962}, [%rd1581];
	// end inline asm
	add.s64 	%rd1585, %rd1561, 112;
	// begin inline asm
	cvta.to.global.u64 %rd1584, %rd1585;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1963,%r1964,%r1965,%r1966}, [%rd1584];
	// end inline asm
	add.s64 	%rd1588, %rd1561, 128;
	// begin inline asm
	cvta.to.global.u64 %rd1587, %rd1588;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1967,%r1968,%r1969,%r1970}, [%rd1587];
	// end inline asm
	add.s64 	%rd1591, %rd1561, 144;
	// begin inline asm
	cvta.to.global.u64 %rd1590, %rd1591;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1971,%r1972,%r1973,%r1974}, [%rd1590];
	// end inline asm
	mov.b32 	%f5201, %r1938;
	mov.b32 	%f5202, %r1939;
	and.b32  	%r1991, %r1937, 65535;
	add.s32 	%r1992, %r1991, -1;
	cvt.rn.f32.s32 	%f5203, %r1992;
	sub.ftz.f32 	%f5204, %f5189, %f5201;
	sub.ftz.f32 	%f5205, %f5202, %f5201;
	div.approx.ftz.f32 	%f5206, %f5204, %f5205;
	mul.ftz.f32 	%f5207, %f5206, %f5203;
	min.ftz.f32 	%f5208, %f5203, %f5207;
	mov.f32 	%f5209, 0f00000000;
	max.ftz.f32 	%f5210, %f5209, %f5208;
	setp.num.ftz.f32 	%p232, %f5210, %f5210;
	selp.f32 	%f5211, %f5210, 0f00000000, %p232;
	cvt.rmi.ftz.f32.f32 	%f5212, %f5211;
	add.ftz.f32 	%f5213, %f5203, 0fBF800000;
	min.ftz.f32 	%f5214, %f5212, %f5213;
	sub.ftz.f32 	%f1956, %f5211, %f5214;
	cvt.rzi.ftz.s32.f32 	%r1993, %f5214;
	mul.wide.s32 	%rd1605, %r1993, 64;
	add.s64 	%rd1594, %rd1570, %rd1605;
	// begin inline asm
	cvta.to.global.u64 %rd1593, %rd1594;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1975,%r1976,%r1977,%r1978}, [%rd1593];
	// end inline asm
	mov.b32 	%f7566, %r1975;
	mov.b32 	%f7567, %r1976;
	mov.b32 	%f7568, %r1977;
	add.s64 	%rd1597, %rd1594, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1596, %rd1597;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1979,%r1980,%r1981,%r1982}, [%rd1596];
	// end inline asm
	mov.b32 	%f7569, %r1979;
	mov.b32 	%f7570, %r1980;
	mov.b32 	%f7571, %r1982;
	add.s64 	%rd1600, %rd1594, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1599, %rd1600;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1983,%r1984,%r1985,%r1986}, [%rd1599];
	// end inline asm
	mov.b32 	%f7572, %r1984;
	mov.b32 	%f7573, %r1985;
	mov.b32 	%f7574, %r1986;
	add.s64 	%rd1603, %rd1594, 48;
	// begin inline asm
	cvta.to.global.u64 %rd1602, %rd1603;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1987,%r1988,%r1989,%r1990}, [%rd1602];
	// end inline asm
	mov.b32 	%f7575, %r1987;
	setp.leu.ftz.f32 	%p233, %f1956, 0f00000000;
	@%p233 bra 	$L__BB4_288;

	mov.f32 	%f5215, 0f3F800000;
	sub.ftz.f32 	%f5216, %f5215, %f1956;
	add.s64 	%rd1607, %rd1594, 64;
	// begin inline asm
	cvta.to.global.u64 %rd1606, %rd1607;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1994,%r1995,%r1996,%r1997}, [%rd1606];
	// end inline asm
	mov.b32 	%f5217, %r1994;
	mov.b32 	%f5218, %r1995;
	mov.b32 	%f5219, %r1996;
	mul.ftz.f32 	%f5220, %f1956, %f5217;
	mul.ftz.f32 	%f5221, %f1956, %f5218;
	mul.ftz.f32 	%f5222, %f1956, %f5219;
	fma.rn.ftz.f32 	%f7566, %f5216, %f7566, %f5220;
	fma.rn.ftz.f32 	%f7567, %f5216, %f7567, %f5221;
	fma.rn.ftz.f32 	%f7568, %f5216, %f7568, %f5222;
	add.s64 	%rd1610, %rd1594, 80;
	// begin inline asm
	cvta.to.global.u64 %rd1609, %rd1610;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1998,%r1999,%r2000,%r2001}, [%rd1609];
	// end inline asm
	mov.b32 	%f5223, %r1998;
	mov.b32 	%f5224, %r1999;
	mov.b32 	%f5225, %r2001;
	mul.ftz.f32 	%f5226, %f1956, %f5223;
	mul.ftz.f32 	%f5227, %f1956, %f5224;
	mul.ftz.f32 	%f5228, %f1956, %f5225;
	fma.rn.ftz.f32 	%f7569, %f5216, %f7569, %f5226;
	fma.rn.ftz.f32 	%f7570, %f5216, %f7570, %f5227;
	fma.rn.ftz.f32 	%f7571, %f5216, %f7571, %f5228;
	add.s64 	%rd1613, %rd1594, 96;
	// begin inline asm
	cvta.to.global.u64 %rd1612, %rd1613;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2002,%r2003,%r2004,%r2005}, [%rd1612];
	// end inline asm
	mov.b32 	%f5229, %r2003;
	mov.b32 	%f5230, %r2004;
	mov.b32 	%f5231, %r2005;
	mul.ftz.f32 	%f5232, %f1956, %f5229;
	mul.ftz.f32 	%f5233, %f1956, %f5230;
	mul.ftz.f32 	%f5234, %f1956, %f5231;
	fma.rn.ftz.f32 	%f5235, %f5216, %f7572, %f5232;
	fma.rn.ftz.f32 	%f5236, %f5216, %f7573, %f5233;
	fma.rn.ftz.f32 	%f5237, %f5216, %f7574, %f5234;
	add.s64 	%rd1616, %rd1594, 112;
	// begin inline asm
	cvta.to.global.u64 %rd1615, %rd1616;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2006,%r2007,%r2008,%r2009}, [%rd1615];
	// end inline asm
	mov.b32 	%f5238, %r2006;
	mul.ftz.f32 	%f5239, %f1956, %f5238;
	fma.rn.ftz.f32 	%f5240, %f5216, %f7575, %f5239;
	mul.ftz.f32 	%f5241, %f5236, %f5236;
	fma.rn.ftz.f32 	%f5242, %f5235, %f5235, %f5241;
	fma.rn.ftz.f32 	%f5243, %f5237, %f5237, %f5242;
	fma.rn.ftz.f32 	%f5244, %f5240, %f5240, %f5243;
	rsqrt.approx.ftz.f32 	%f5245, %f5244;
	mul.ftz.f32 	%f7572, %f5235, %f5245;
	mul.ftz.f32 	%f7573, %f5236, %f5245;
	mul.ftz.f32 	%f7574, %f5237, %f5245;
	mul.ftz.f32 	%f7575, %f5245, %f5240;

$L__BB4_288:
	mul.ftz.f32 	%f5246, %f7573, %f7573;
	mul.ftz.f32 	%f5247, %f7572, %f7572;
	sub.ftz.f32 	%f5248, %f5247, %f5246;
	mul.ftz.f32 	%f5249, %f7574, %f7574;
	sub.ftz.f32 	%f5250, %f5248, %f5249;
	fma.rn.ftz.f32 	%f5251, %f7575, %f7575, %f5250;
	mul.ftz.f32 	%f5252, %f7574, %f7575;
	mul.ftz.f32 	%f5253, %f7572, %f7573;
	sub.ftz.f32 	%f5254, %f5253, %f5252;
	add.ftz.f32 	%f5255, %f5254, %f5254;
	mul.ftz.f32 	%f5256, %f7573, %f7575;
	mul.ftz.f32 	%f5257, %f7572, %f7574;
	add.ftz.f32 	%f5258, %f5257, %f5256;
	add.ftz.f32 	%f5259, %f5258, %f5258;
	add.ftz.f32 	%f5260, %f5253, %f5252;
	add.ftz.f32 	%f5261, %f5260, %f5260;
	sub.ftz.f32 	%f5262, %f5246, %f5247;
	sub.ftz.f32 	%f5263, %f5262, %f5249;
	fma.rn.ftz.f32 	%f5264, %f7575, %f7575, %f5263;
	mul.ftz.f32 	%f5265, %f7572, %f7575;
	mul.ftz.f32 	%f5266, %f7573, %f7574;
	sub.ftz.f32 	%f5267, %f5266, %f5265;
	add.ftz.f32 	%f5268, %f5267, %f5267;
	sub.ftz.f32 	%f5269, %f5257, %f5256;
	add.ftz.f32 	%f5270, %f5269, %f5269;
	add.ftz.f32 	%f5271, %f5266, %f5265;
	add.ftz.f32 	%f5272, %f5271, %f5271;
	neg.ftz.f32 	%f5273, %f5247;
	sub.ftz.f32 	%f5274, %f5273, %f5246;
	add.ftz.f32 	%f5275, %f5274, %f5249;
	fma.rn.ftz.f32 	%f5276, %f7575, %f7575, %f5275;
	mul.ftz.f32 	%f5277, %f7570, %f5255;
	fma.rn.ftz.f32 	%f5278, %f7568, %f5251, %f5277;
	fma.rn.ftz.f32 	%f7584, %f7571, %f5259, %f5278;
	mul.ftz.f32 	%f5279, %f7568, %f5261;
	fma.rn.ftz.f32 	%f5280, %f7570, %f5264, %f5279;
	fma.rn.ftz.f32 	%f7581, %f7571, %f5268, %f5280;
	mul.ftz.f32 	%f5281, %f7570, %f5272;
	fma.rn.ftz.f32 	%f5282, %f7568, %f5270, %f5281;
	fma.rn.ftz.f32 	%f7578, %f7571, %f5276, %f5282;
	mul.ftz.f32 	%f5283, %f7569, %f5255;
	fma.rn.ftz.f32 	%f7583, %f7567, %f5251, %f5283;
	mul.ftz.f32 	%f5284, %f7567, %f5261;
	fma.rn.ftz.f32 	%f7580, %f7569, %f5264, %f5284;
	mul.ftz.f32 	%f5285, %f7569, %f5272;
	fma.rn.ftz.f32 	%f7577, %f7567, %f5270, %f5285;
	mul.ftz.f32 	%f7582, %f7566, %f5251;
	mul.ftz.f32 	%f7579, %f7566, %f5261;
	mul.ftz.f32 	%f7576, %f7566, %f5270;

$L__BB4_291:
	mul.ftz.f32 	%f5320, %f7577, %f7581;
	mul.ftz.f32 	%f5321, %f7578, %f7580;
	sub.ftz.f32 	%f5322, %f5321, %f5320;
	mul.ftz.f32 	%f5323, %f7582, %f5322;
	mul.ftz.f32 	%f5324, %f7576, %f7581;
	mul.ftz.f32 	%f5325, %f7578, %f7579;
	sub.ftz.f32 	%f5326, %f5325, %f5324;
	mul.ftz.f32 	%f5327, %f5326, %f7583;
	sub.ftz.f32 	%f5328, %f5323, %f5327;
	mul.ftz.f32 	%f5329, %f7576, %f7580;
	mul.ftz.f32 	%f5330, %f7577, %f7579;
	sub.ftz.f32 	%f5331, %f5330, %f5329;
	fma.rn.ftz.f32 	%f5332, %f5331, %f7584, %f5328;
	rcp.approx.ftz.f32 	%f5333, %f5332;
	mul.ftz.f32 	%f7591, %f5322, %f5333;
	mul.ftz.f32 	%f5334, %f7578, %f7583;
	mul.ftz.f32 	%f5335, %f7577, %f7584;
	sub.ftz.f32 	%f5336, %f5335, %f5334;
	mul.ftz.f32 	%f7592, %f5336, %f5333;
	mul.ftz.f32 	%f5337, %f7580, %f7584;
	mul.ftz.f32 	%f5338, %f7581, %f7583;
	sub.ftz.f32 	%f5339, %f5338, %f5337;
	mul.ftz.f32 	%f7593, %f5339, %f5333;
	sub.ftz.f32 	%f5340, %f5324, %f5325;
	mul.ftz.f32 	%f7588, %f5340, %f5333;
	mul.ftz.f32 	%f5341, %f7576, %f7584;
	mul.ftz.f32 	%f5342, %f7578, %f7582;
	sub.ftz.f32 	%f5343, %f5342, %f5341;
	mul.ftz.f32 	%f7589, %f5343, %f5333;
	mul.ftz.f32 	%f5344, %f7581, %f7582;
	mul.ftz.f32 	%f5345, %f7579, %f7584;
	sub.ftz.f32 	%f5346, %f5345, %f5344;
	mul.ftz.f32 	%f7590, %f5346, %f5333;
	mul.ftz.f32 	%f7585, %f5331, %f5333;
	mul.ftz.f32 	%f5347, %f7577, %f7582;
	mul.ftz.f32 	%f5348, %f7576, %f7583;
	sub.ftz.f32 	%f5349, %f5348, %f5347;
	mul.ftz.f32 	%f7586, %f5349, %f5333;
	mul.ftz.f32 	%f5350, %f7579, %f7583;
	mul.ftz.f32 	%f5351, %f7580, %f7582;
	sub.ftz.f32 	%f5352, %f5351, %f5350;
	mul.ftz.f32 	%f7587, %f5352, %f5333;
	bra.uni 	$L__BB4_292;

$L__BB4_282:
	// begin inline asm
	call (%rd1548), _optix_get_static_transform_from_handle, (%rd1546);
	// end inline asm
	add.s64 	%rd1974, %rd1548, 64;

$L__BB4_284:
	// begin inline asm
	cvta.to.global.u64 %rd1552, %rd1974;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1923,%r1924,%r1925,%r1926}, [%rd1552];
	// end inline asm
	mov.b32 	%f7591, %r1923;
	mov.b32 	%f7592, %r1924;
	mov.b32 	%f7593, %r1925;
	add.s64 	%rd1556, %rd1974, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1555, %rd1556;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1927,%r1928,%r1929,%r1930}, [%rd1555];
	// end inline asm
	mov.b32 	%f7588, %r1927;
	mov.b32 	%f7589, %r1928;
	mov.b32 	%f7590, %r1929;
	add.s64 	%rd1559, %rd1974, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1558, %rd1559;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r1931,%r1932,%r1933,%r1934}, [%rd1558];
	// end inline asm
	mov.b32 	%f7585, %r1931;
	mov.b32 	%f7586, %r1932;
	mov.b32 	%f7587, %r1933;

$L__BB4_292:
	setp.eq.s32 	%p236, %r2521, 0;
	@%p236 bra 	$L__BB4_294;

	mul.ftz.f32 	%f5353, %f7562, %f7592;
	fma.rn.ftz.f32 	%f5354, %f7559, %f7591, %f5353;
	fma.rn.ftz.f32 	%f2042, %f7565, %f7593, %f5354;
	mul.ftz.f32 	%f5355, %f7561, %f7592;
	fma.rn.ftz.f32 	%f5356, %f7558, %f7591, %f5355;
	fma.rn.ftz.f32 	%f2043, %f7564, %f7593, %f5356;
	mul.ftz.f32 	%f5357, %f7560, %f7592;
	fma.rn.ftz.f32 	%f5358, %f7557, %f7591, %f5357;
	fma.rn.ftz.f32 	%f7593, %f7563, %f7593, %f5358;
	mul.ftz.f32 	%f5359, %f7562, %f7589;
	fma.rn.ftz.f32 	%f5360, %f7559, %f7588, %f5359;
	fma.rn.ftz.f32 	%f2045, %f7565, %f7590, %f5360;
	mul.ftz.f32 	%f5361, %f7561, %f7589;
	fma.rn.ftz.f32 	%f5362, %f7558, %f7588, %f5361;
	fma.rn.ftz.f32 	%f2046, %f7564, %f7590, %f5362;
	mul.ftz.f32 	%f5363, %f7560, %f7589;
	fma.rn.ftz.f32 	%f5364, %f7557, %f7588, %f5363;
	fma.rn.ftz.f32 	%f7590, %f7563, %f7590, %f5364;
	mul.ftz.f32 	%f5365, %f7562, %f7586;
	fma.rn.ftz.f32 	%f5366, %f7559, %f7585, %f5365;
	fma.rn.ftz.f32 	%f2048, %f7565, %f7587, %f5366;
	mul.ftz.f32 	%f5367, %f7561, %f7586;
	fma.rn.ftz.f32 	%f5368, %f7558, %f7585, %f5367;
	fma.rn.ftz.f32 	%f2049, %f7564, %f7587, %f5368;
	mul.ftz.f32 	%f5369, %f7560, %f7586;
	fma.rn.ftz.f32 	%f5370, %f7557, %f7585, %f5369;
	fma.rn.ftz.f32 	%f7587, %f7563, %f7587, %f5370;
	mov.f32 	%f7585, %f2048;
	mov.f32 	%f7586, %f2049;
	mov.f32 	%f7588, %f2045;
	mov.f32 	%f7589, %f2046;
	mov.f32 	%f7591, %f2042;
	mov.f32 	%f7592, %f2043;

$L__BB4_294:
	add.s32 	%r2521, %r2521, 1;
	setp.lt.u32 	%p237, %r2521, %r1918;
	mov.f32 	%f7557, %f7593;
	mov.f32 	%f7558, %f7592;
	mov.f32 	%f7559, %f7591;
	mov.f32 	%f7560, %f7590;
	mov.f32 	%f7561, %f7589;
	mov.f32 	%f7562, %f7588;
	mov.f32 	%f7563, %f7587;
	mov.f32 	%f7564, %f7586;
	mov.f32 	%f7565, %f7585;
	@%p237 bra 	$L__BB4_278;

$L__BB4_295:
	mul.ftz.f32 	%f5371, %f7612, %f7591;
	fma.rn.ftz.f32 	%f5372, %f7613, %f7588, %f5371;
	mul.ftz.f32 	%f5373, %f7612, %f7592;
	fma.rn.ftz.f32 	%f5374, %f7613, %f7589, %f5373;
	mul.ftz.f32 	%f5375, %f7612, %f7593;
	fma.rn.ftz.f32 	%f5376, %f7613, %f7590, %f5375;
	fma.rn.ftz.f32 	%f7614, %f1936, %f7587, %f5376;
	fma.rn.ftz.f32 	%f7613, %f1936, %f7586, %f5374;
	fma.rn.ftz.f32 	%f7612, %f1936, %f7585, %f5372;
	bra.uni 	$L__BB4_297;

$L__BB4_296:
	mov.f32 	%f7614, %f1936;

$L__BB4_297:
	ld.f32 	%f7670, [%rd100+12];
	ld.f32 	%f7671, [%rd100+16];
	ld.f32 	%f2080, [%rd100+20];
	// begin inline asm
	call (%r2069), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p238, %r2069, 0;
	@%p238 bra 	$L__BB4_318;

	// begin inline asm
	call (%r2070), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f5377), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p239, %r2070, 0;
	@%p239 bra 	$L__BB4_317;

	mov.u32 	%r2522, 0;

$L__BB4_300:
	.pragma "nounroll";
	// begin inline asm
	call (%rd1665), _optix_get_transform_list_handle, (%r2522);
	// end inline asm
	// begin inline asm
	call (%r2073), _optix_get_transform_type_from_handle, (%rd1665);
	// end inline asm
	or.b32  	%r2074, %r2073, 1;
	setp.eq.s32 	%p240, %r2074, 3;
	@%p240 bra 	$L__BB4_307;
	bra.uni 	$L__BB4_301;

$L__BB4_307:
	setp.eq.s32 	%p244, %r2073, 2;
	@%p244 bra 	$L__BB4_311;
	bra.uni 	$L__BB4_308;

$L__BB4_311:
	// begin inline asm
	call (%rd1737), _optix_get_matrix_motion_transform_from_handle, (%rd1665);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd1739, %rd1737;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2162,%r2163,%r2164,%r2165}, [%rd1739];
	// end inline asm
	add.s64 	%rd1743, %rd1737, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1742, %rd1743;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2166,%r2167,%r2168,%r2169}, [%rd1742];
	// end inline asm
	add.s64 	%rd1746, %rd1737, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1745, %rd1746;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2170,%r2171,%r2172,%r2173}, [%rd1745];
	// end inline asm
	add.s64 	%rd1749, %rd1737, 48;
	// begin inline asm
	cvta.to.global.u64 %rd1748, %rd1749;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2174,%r2175,%r2176,%r2177}, [%rd1748];
	// end inline asm
	add.s64 	%rd1752, %rd1737, 64;
	// begin inline asm
	cvta.to.global.u64 %rd1751, %rd1752;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2178,%r2179,%r2180,%r2181}, [%rd1751];
	// end inline asm
	add.s64 	%rd1755, %rd1737, 80;
	// begin inline asm
	cvta.to.global.u64 %rd1754, %rd1755;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2182,%r2183,%r2184,%r2185}, [%rd1754];
	// end inline asm
	add.s64 	%rd1758, %rd1737, 96;
	// begin inline asm
	cvta.to.global.u64 %rd1757, %rd1758;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2186,%r2187,%r2188,%r2189}, [%rd1757];
	// end inline asm
	add.s64 	%rd1761, %rd1737, 112;
	// begin inline asm
	cvta.to.global.u64 %rd1760, %rd1761;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2190,%r2191,%r2192,%r2193}, [%rd1760];
	// end inline asm
	mov.b32 	%f5474, %r2165;
	mov.b32 	%f5475, %r2166;
	and.b32  	%r2206, %r2164, 65535;
	add.s32 	%r2207, %r2206, -1;
	cvt.rn.f32.s32 	%f5476, %r2207;
	sub.ftz.f32 	%f5477, %f5377, %f5474;
	sub.ftz.f32 	%f5478, %f5475, %f5474;
	div.approx.ftz.f32 	%f5479, %f5477, %f5478;
	mul.ftz.f32 	%f5480, %f5479, %f5476;
	min.ftz.f32 	%f5481, %f5476, %f5480;
	mov.f32 	%f5482, 0f00000000;
	max.ftz.f32 	%f5483, %f5482, %f5481;
	setp.num.ftz.f32 	%p247, %f5483, %f5483;
	selp.f32 	%f5484, %f5483, 0f00000000, %p247;
	cvt.rmi.ftz.f32.f32 	%f5485, %f5484;
	add.ftz.f32 	%f5486, %f5476, 0fBF800000;
	min.ftz.f32 	%f5487, %f5485, %f5486;
	sub.ftz.f32 	%f2140, %f5484, %f5487;
	cvt.rzi.ftz.s32.f32 	%r2208, %f5487;
	cvt.s64.s32 	%rd129, %r2208;
	mul.wide.s32 	%rd1772, %r2208, 48;
	add.s64 	%rd1764, %rd1746, %rd1772;
	// begin inline asm
	cvta.to.global.u64 %rd1763, %rd1764;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2194,%r2195,%r2196,%r2197}, [%rd1763];
	// end inline asm
	mov.b32 	%f7640, %r2194;
	mov.b32 	%f7641, %r2195;
	mov.b32 	%f7642, %r2196;
	add.s64 	%rd1767, %rd1764, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1766, %rd1767;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2198,%r2199,%r2200,%r2201}, [%rd1766];
	// end inline asm
	mov.b32 	%f7637, %r2198;
	mov.b32 	%f7638, %r2199;
	mov.b32 	%f7639, %r2200;
	add.s64 	%rd1770, %rd1764, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1769, %rd1770;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2202,%r2203,%r2204,%r2205}, [%rd1769];
	// end inline asm
	mov.b32 	%f7634, %r2202;
	mov.b32 	%f7635, %r2203;
	mov.b32 	%f7636, %r2204;
	setp.leu.ftz.f32 	%p248, %f2140, 0f00000000;
	@%p248 bra 	$L__BB4_313;

	mov.f32 	%f5488, 0f3F800000;
	sub.ftz.f32 	%f5489, %f5488, %f2140;
	mul.lo.s64 	%rd1782, %rd129, 48;
	add.s64 	%rd1783, %rd1737, %rd1782;
	add.s64 	%rd1774, %rd1783, 80;
	// begin inline asm
	cvta.to.global.u64 %rd1773, %rd1774;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2209,%r2210,%r2211,%r2212}, [%rd1773];
	// end inline asm
	mov.b32 	%f5490, %r2209;
	mov.b32 	%f5491, %r2210;
	mov.b32 	%f5492, %r2211;
	mul.ftz.f32 	%f5493, %f2140, %f5490;
	mul.ftz.f32 	%f5494, %f2140, %f5491;
	mul.ftz.f32 	%f5495, %f2140, %f5492;
	fma.rn.ftz.f32 	%f7640, %f5489, %f7640, %f5493;
	fma.rn.ftz.f32 	%f7641, %f5489, %f7641, %f5494;
	fma.rn.ftz.f32 	%f7642, %f5489, %f7642, %f5495;
	add.s64 	%rd1777, %rd1783, 96;
	// begin inline asm
	cvta.to.global.u64 %rd1776, %rd1777;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2213,%r2214,%r2215,%r2216}, [%rd1776];
	// end inline asm
	mov.b32 	%f5496, %r2213;
	mov.b32 	%f5497, %r2214;
	mov.b32 	%f5498, %r2215;
	mul.ftz.f32 	%f5499, %f2140, %f5496;
	mul.ftz.f32 	%f5500, %f2140, %f5497;
	mul.ftz.f32 	%f5501, %f2140, %f5498;
	fma.rn.ftz.f32 	%f7637, %f5489, %f7637, %f5499;
	fma.rn.ftz.f32 	%f7638, %f5489, %f7638, %f5500;
	fma.rn.ftz.f32 	%f7639, %f5489, %f7639, %f5501;
	add.s64 	%rd1780, %rd1783, 112;
	// begin inline asm
	cvta.to.global.u64 %rd1779, %rd1780;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2217,%r2218,%r2219,%r2220}, [%rd1779];
	// end inline asm
	mov.b32 	%f5502, %r2217;
	mov.b32 	%f5503, %r2218;
	mov.b32 	%f5504, %r2219;
	mul.ftz.f32 	%f5505, %f2140, %f5502;
	mul.ftz.f32 	%f5506, %f2140, %f5503;
	mul.ftz.f32 	%f5507, %f2140, %f5504;
	fma.rn.ftz.f32 	%f7634, %f5489, %f7634, %f5505;
	fma.rn.ftz.f32 	%f7635, %f5489, %f7635, %f5506;
	fma.rn.ftz.f32 	%f7636, %f5489, %f7636, %f5507;
	bra.uni 	$L__BB4_313;

$L__BB4_301:
	mov.f32 	%f7643, 0f00000000;
	mov.f32 	%f7645, 0f3F800000;
	setp.eq.s32 	%p241, %r2073, 4;
	@%p241 bra 	$L__BB4_303;

	setp.ne.s32 	%p242, %r2073, 1;
	mov.f32 	%f7644, %f7643;
	mov.f32 	%f7646, %f7643;
	mov.f32 	%f7647, %f7645;
	mov.f32 	%f7648, %f7643;
	mov.f32 	%f7649, %f7645;
	mov.f32 	%f7650, %f7643;
	mov.f32 	%f7651, %f7643;
	@%p242 bra 	$L__BB4_314;

$L__BB4_303:
	@%p241 bra 	$L__BB4_305;
	bra.uni 	$L__BB4_304;

$L__BB4_305:
	// begin inline asm
	call (%rd1975), _optix_get_instance_inverse_transform_from_handle, (%rd1665);
	// end inline asm
	bra.uni 	$L__BB4_306;

$L__BB4_308:
	// begin inline asm
	call (%rd1680), _optix_get_srt_motion_transform_from_handle, (%rd1665);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd1682, %rd1680;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2087,%r2088,%r2089,%r2090}, [%rd1682];
	// end inline asm
	add.s64 	%rd1686, %rd1680, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1685, %rd1686;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2091,%r2092,%r2093,%r2094}, [%rd1685];
	// end inline asm
	add.s64 	%rd1689, %rd1680, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1688, %rd1689;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2095,%r2096,%r2097,%r2098}, [%rd1688];
	// end inline asm
	add.s64 	%rd1692, %rd1680, 48;
	// begin inline asm
	cvta.to.global.u64 %rd1691, %rd1692;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2099,%r2100,%r2101,%r2102}, [%rd1691];
	// end inline asm
	add.s64 	%rd1695, %rd1680, 64;
	// begin inline asm
	cvta.to.global.u64 %rd1694, %rd1695;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2103,%r2104,%r2105,%r2106}, [%rd1694];
	// end inline asm
	add.s64 	%rd1698, %rd1680, 80;
	// begin inline asm
	cvta.to.global.u64 %rd1697, %rd1698;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2107,%r2108,%r2109,%r2110}, [%rd1697];
	// end inline asm
	add.s64 	%rd1701, %rd1680, 96;
	// begin inline asm
	cvta.to.global.u64 %rd1700, %rd1701;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2111,%r2112,%r2113,%r2114}, [%rd1700];
	// end inline asm
	add.s64 	%rd1704, %rd1680, 112;
	// begin inline asm
	cvta.to.global.u64 %rd1703, %rd1704;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2115,%r2116,%r2117,%r2118}, [%rd1703];
	// end inline asm
	add.s64 	%rd1707, %rd1680, 128;
	// begin inline asm
	cvta.to.global.u64 %rd1706, %rd1707;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2119,%r2120,%r2121,%r2122}, [%rd1706];
	// end inline asm
	add.s64 	%rd1710, %rd1680, 144;
	// begin inline asm
	cvta.to.global.u64 %rd1709, %rd1710;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2123,%r2124,%r2125,%r2126}, [%rd1709];
	// end inline asm
	mov.b32 	%f5389, %r2090;
	mov.b32 	%f5390, %r2091;
	and.b32  	%r2143, %r2089, 65535;
	add.s32 	%r2144, %r2143, -1;
	cvt.rn.f32.s32 	%f5391, %r2144;
	sub.ftz.f32 	%f5392, %f5377, %f5389;
	sub.ftz.f32 	%f5393, %f5390, %f5389;
	div.approx.ftz.f32 	%f5394, %f5392, %f5393;
	mul.ftz.f32 	%f5395, %f5394, %f5391;
	min.ftz.f32 	%f5396, %f5391, %f5395;
	mov.f32 	%f5397, 0f00000000;
	max.ftz.f32 	%f5398, %f5397, %f5396;
	setp.num.ftz.f32 	%p245, %f5398, %f5398;
	selp.f32 	%f5399, %f5398, 0f00000000, %p245;
	cvt.rmi.ftz.f32.f32 	%f5400, %f5399;
	add.ftz.f32 	%f5401, %f5391, 0fBF800000;
	min.ftz.f32 	%f5402, %f5400, %f5401;
	sub.ftz.f32 	%f2100, %f5399, %f5402;
	cvt.rzi.ftz.s32.f32 	%r2145, %f5402;
	mul.wide.s32 	%rd1724, %r2145, 64;
	add.s64 	%rd1713, %rd1689, %rd1724;
	// begin inline asm
	cvta.to.global.u64 %rd1712, %rd1713;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2127,%r2128,%r2129,%r2130}, [%rd1712];
	// end inline asm
	mov.b32 	%f7624, %r2127;
	mov.b32 	%f7625, %r2128;
	mov.b32 	%f7626, %r2129;
	add.s64 	%rd1716, %rd1713, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1715, %rd1716;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2131,%r2132,%r2133,%r2134}, [%rd1715];
	// end inline asm
	mov.b32 	%f7627, %r2131;
	mov.b32 	%f7628, %r2132;
	mov.b32 	%f7629, %r2134;
	add.s64 	%rd1719, %rd1713, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1718, %rd1719;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2135,%r2136,%r2137,%r2138}, [%rd1718];
	// end inline asm
	mov.b32 	%f7630, %r2136;
	mov.b32 	%f7631, %r2137;
	mov.b32 	%f7632, %r2138;
	add.s64 	%rd1722, %rd1713, 48;
	// begin inline asm
	cvta.to.global.u64 %rd1721, %rd1722;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2139,%r2140,%r2141,%r2142}, [%rd1721];
	// end inline asm
	mov.b32 	%f7633, %r2139;
	setp.leu.ftz.f32 	%p246, %f2100, 0f00000000;
	@%p246 bra 	$L__BB4_310;

	mov.f32 	%f5403, 0f3F800000;
	sub.ftz.f32 	%f5404, %f5403, %f2100;
	add.s64 	%rd1726, %rd1713, 64;
	// begin inline asm
	cvta.to.global.u64 %rd1725, %rd1726;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2146,%r2147,%r2148,%r2149}, [%rd1725];
	// end inline asm
	mov.b32 	%f5405, %r2146;
	mov.b32 	%f5406, %r2147;
	mov.b32 	%f5407, %r2148;
	mul.ftz.f32 	%f5408, %f2100, %f5405;
	mul.ftz.f32 	%f5409, %f2100, %f5406;
	mul.ftz.f32 	%f5410, %f2100, %f5407;
	fma.rn.ftz.f32 	%f7624, %f5404, %f7624, %f5408;
	fma.rn.ftz.f32 	%f7625, %f5404, %f7625, %f5409;
	fma.rn.ftz.f32 	%f7626, %f5404, %f7626, %f5410;
	add.s64 	%rd1729, %rd1713, 80;
	// begin inline asm
	cvta.to.global.u64 %rd1728, %rd1729;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2150,%r2151,%r2152,%r2153}, [%rd1728];
	// end inline asm
	mov.b32 	%f5411, %r2150;
	mov.b32 	%f5412, %r2151;
	mov.b32 	%f5413, %r2153;
	mul.ftz.f32 	%f5414, %f2100, %f5411;
	mul.ftz.f32 	%f5415, %f2100, %f5412;
	mul.ftz.f32 	%f5416, %f2100, %f5413;
	fma.rn.ftz.f32 	%f7627, %f5404, %f7627, %f5414;
	fma.rn.ftz.f32 	%f7628, %f5404, %f7628, %f5415;
	fma.rn.ftz.f32 	%f7629, %f5404, %f7629, %f5416;
	add.s64 	%rd1732, %rd1713, 96;
	// begin inline asm
	cvta.to.global.u64 %rd1731, %rd1732;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2154,%r2155,%r2156,%r2157}, [%rd1731];
	// end inline asm
	mov.b32 	%f5417, %r2155;
	mov.b32 	%f5418, %r2156;
	mov.b32 	%f5419, %r2157;
	mul.ftz.f32 	%f5420, %f2100, %f5417;
	mul.ftz.f32 	%f5421, %f2100, %f5418;
	mul.ftz.f32 	%f5422, %f2100, %f5419;
	fma.rn.ftz.f32 	%f5423, %f5404, %f7630, %f5420;
	fma.rn.ftz.f32 	%f5424, %f5404, %f7631, %f5421;
	fma.rn.ftz.f32 	%f5425, %f5404, %f7632, %f5422;
	add.s64 	%rd1735, %rd1713, 112;
	// begin inline asm
	cvta.to.global.u64 %rd1734, %rd1735;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2158,%r2159,%r2160,%r2161}, [%rd1734];
	// end inline asm
	mov.b32 	%f5426, %r2158;
	mul.ftz.f32 	%f5427, %f2100, %f5426;
	fma.rn.ftz.f32 	%f5428, %f5404, %f7633, %f5427;
	mul.ftz.f32 	%f5429, %f5424, %f5424;
	fma.rn.ftz.f32 	%f5430, %f5423, %f5423, %f5429;
	fma.rn.ftz.f32 	%f5431, %f5425, %f5425, %f5430;
	fma.rn.ftz.f32 	%f5432, %f5428, %f5428, %f5431;
	rsqrt.approx.ftz.f32 	%f5433, %f5432;
	mul.ftz.f32 	%f7630, %f5423, %f5433;
	mul.ftz.f32 	%f7631, %f5424, %f5433;
	mul.ftz.f32 	%f7632, %f5425, %f5433;
	mul.ftz.f32 	%f7633, %f5433, %f5428;

$L__BB4_310:
	mul.ftz.f32 	%f5434, %f7631, %f7631;
	mul.ftz.f32 	%f5435, %f7630, %f7630;
	sub.ftz.f32 	%f5436, %f5435, %f5434;
	mul.ftz.f32 	%f5437, %f7632, %f7632;
	sub.ftz.f32 	%f5438, %f5436, %f5437;
	fma.rn.ftz.f32 	%f5439, %f7633, %f7633, %f5438;
	mul.ftz.f32 	%f5440, %f7632, %f7633;
	mul.ftz.f32 	%f5441, %f7630, %f7631;
	sub.ftz.f32 	%f5442, %f5441, %f5440;
	add.ftz.f32 	%f5443, %f5442, %f5442;
	mul.ftz.f32 	%f5444, %f7631, %f7633;
	mul.ftz.f32 	%f5445, %f7630, %f7632;
	add.ftz.f32 	%f5446, %f5445, %f5444;
	add.ftz.f32 	%f5447, %f5446, %f5446;
	add.ftz.f32 	%f5448, %f5441, %f5440;
	add.ftz.f32 	%f5449, %f5448, %f5448;
	sub.ftz.f32 	%f5450, %f5434, %f5435;
	sub.ftz.f32 	%f5451, %f5450, %f5437;
	fma.rn.ftz.f32 	%f5452, %f7633, %f7633, %f5451;
	mul.ftz.f32 	%f5453, %f7630, %f7633;
	mul.ftz.f32 	%f5454, %f7631, %f7632;
	sub.ftz.f32 	%f5455, %f5454, %f5453;
	add.ftz.f32 	%f5456, %f5455, %f5455;
	sub.ftz.f32 	%f5457, %f5445, %f5444;
	add.ftz.f32 	%f5458, %f5457, %f5457;
	add.ftz.f32 	%f5459, %f5454, %f5453;
	add.ftz.f32 	%f5460, %f5459, %f5459;
	neg.ftz.f32 	%f5461, %f5435;
	sub.ftz.f32 	%f5462, %f5461, %f5434;
	add.ftz.f32 	%f5463, %f5462, %f5437;
	fma.rn.ftz.f32 	%f5464, %f7633, %f7633, %f5463;
	mul.ftz.f32 	%f5465, %f7628, %f5443;
	fma.rn.ftz.f32 	%f5466, %f7626, %f5439, %f5465;
	fma.rn.ftz.f32 	%f7642, %f7629, %f5447, %f5466;
	mul.ftz.f32 	%f5467, %f7626, %f5449;
	fma.rn.ftz.f32 	%f5468, %f7628, %f5452, %f5467;
	fma.rn.ftz.f32 	%f7639, %f7629, %f5456, %f5468;
	mul.ftz.f32 	%f5469, %f7628, %f5460;
	fma.rn.ftz.f32 	%f5470, %f7626, %f5458, %f5469;
	fma.rn.ftz.f32 	%f7636, %f7629, %f5464, %f5470;
	mul.ftz.f32 	%f5471, %f7627, %f5443;
	fma.rn.ftz.f32 	%f7641, %f7625, %f5439, %f5471;
	mul.ftz.f32 	%f5472, %f7625, %f5449;
	fma.rn.ftz.f32 	%f7638, %f7627, %f5452, %f5472;
	mul.ftz.f32 	%f5473, %f7627, %f5460;
	fma.rn.ftz.f32 	%f7635, %f7625, %f5458, %f5473;
	mul.ftz.f32 	%f7640, %f7624, %f5439;
	mul.ftz.f32 	%f7637, %f7624, %f5449;
	mul.ftz.f32 	%f7634, %f7624, %f5458;

$L__BB4_313:
	mul.ftz.f32 	%f5508, %f7635, %f7639;
	mul.ftz.f32 	%f5509, %f7636, %f7638;
	sub.ftz.f32 	%f5510, %f5509, %f5508;
	mul.ftz.f32 	%f5511, %f7640, %f5510;
	mul.ftz.f32 	%f5512, %f7634, %f7639;
	mul.ftz.f32 	%f5513, %f7636, %f7637;
	sub.ftz.f32 	%f5514, %f5513, %f5512;
	mul.ftz.f32 	%f5515, %f5514, %f7641;
	sub.ftz.f32 	%f5516, %f5511, %f5515;
	mul.ftz.f32 	%f5517, %f7634, %f7638;
	mul.ftz.f32 	%f5518, %f7635, %f7637;
	sub.ftz.f32 	%f5519, %f5518, %f5517;
	fma.rn.ftz.f32 	%f5520, %f5519, %f7642, %f5516;
	rcp.approx.ftz.f32 	%f5521, %f5520;
	mul.ftz.f32 	%f7649, %f5510, %f5521;
	mul.ftz.f32 	%f5522, %f7636, %f7641;
	mul.ftz.f32 	%f5523, %f7635, %f7642;
	sub.ftz.f32 	%f5524, %f5523, %f5522;
	mul.ftz.f32 	%f7650, %f5524, %f5521;
	mul.ftz.f32 	%f5525, %f7638, %f7642;
	mul.ftz.f32 	%f5526, %f7639, %f7641;
	sub.ftz.f32 	%f5527, %f5526, %f5525;
	mul.ftz.f32 	%f7651, %f5527, %f5521;
	sub.ftz.f32 	%f5528, %f5512, %f5513;
	mul.ftz.f32 	%f7646, %f5528, %f5521;
	mul.ftz.f32 	%f5529, %f7634, %f7642;
	mul.ftz.f32 	%f5530, %f7636, %f7640;
	sub.ftz.f32 	%f5531, %f5530, %f5529;
	mul.ftz.f32 	%f7647, %f5531, %f5521;
	mul.ftz.f32 	%f5532, %f7639, %f7640;
	mul.ftz.f32 	%f5533, %f7637, %f7642;
	sub.ftz.f32 	%f5534, %f5533, %f5532;
	mul.ftz.f32 	%f7648, %f5534, %f5521;
	mul.ftz.f32 	%f7643, %f5519, %f5521;
	mul.ftz.f32 	%f5535, %f7635, %f7640;
	mul.ftz.f32 	%f5536, %f7634, %f7641;
	sub.ftz.f32 	%f5537, %f5536, %f5535;
	mul.ftz.f32 	%f7644, %f5537, %f5521;
	mul.ftz.f32 	%f5538, %f7637, %f7641;
	mul.ftz.f32 	%f5539, %f7638, %f7640;
	sub.ftz.f32 	%f5540, %f5539, %f5538;
	mul.ftz.f32 	%f7645, %f5540, %f5521;
	bra.uni 	$L__BB4_314;

$L__BB4_304:
	// begin inline asm
	call (%rd1667), _optix_get_static_transform_from_handle, (%rd1665);
	// end inline asm
	add.s64 	%rd1975, %rd1667, 64;

$L__BB4_306:
	// begin inline asm
	cvta.to.global.u64 %rd1671, %rd1975;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2075,%r2076,%r2077,%r2078}, [%rd1671];
	// end inline asm
	mov.b32 	%f7649, %r2075;
	mov.b32 	%f7650, %r2076;
	mov.b32 	%f7651, %r2077;
	add.s64 	%rd1675, %rd1975, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1674, %rd1675;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2079,%r2080,%r2081,%r2082}, [%rd1674];
	// end inline asm
	mov.b32 	%f7646, %r2079;
	mov.b32 	%f7647, %r2080;
	mov.b32 	%f7648, %r2081;
	add.s64 	%rd1678, %rd1975, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1677, %rd1678;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2083,%r2084,%r2085,%r2086}, [%rd1677];
	// end inline asm
	mov.b32 	%f7643, %r2083;
	mov.b32 	%f7644, %r2084;
	mov.b32 	%f7645, %r2085;

$L__BB4_314:
	setp.eq.s32 	%p249, %r2522, 0;
	@%p249 bra 	$L__BB4_316;

	mul.ftz.f32 	%f5541, %f7620, %f7650;
	fma.rn.ftz.f32 	%f5542, %f7617, %f7649, %f5541;
	fma.rn.ftz.f32 	%f2186, %f7623, %f7651, %f5542;
	mul.ftz.f32 	%f5543, %f7619, %f7650;
	fma.rn.ftz.f32 	%f5544, %f7616, %f7649, %f5543;
	fma.rn.ftz.f32 	%f2187, %f7622, %f7651, %f5544;
	mul.ftz.f32 	%f5545, %f7618, %f7650;
	fma.rn.ftz.f32 	%f5546, %f7615, %f7649, %f5545;
	fma.rn.ftz.f32 	%f7651, %f7621, %f7651, %f5546;
	mul.ftz.f32 	%f5547, %f7620, %f7647;
	fma.rn.ftz.f32 	%f5548, %f7617, %f7646, %f5547;
	fma.rn.ftz.f32 	%f2189, %f7623, %f7648, %f5548;
	mul.ftz.f32 	%f5549, %f7619, %f7647;
	fma.rn.ftz.f32 	%f5550, %f7616, %f7646, %f5549;
	fma.rn.ftz.f32 	%f2190, %f7622, %f7648, %f5550;
	mul.ftz.f32 	%f5551, %f7618, %f7647;
	fma.rn.ftz.f32 	%f5552, %f7615, %f7646, %f5551;
	fma.rn.ftz.f32 	%f7648, %f7621, %f7648, %f5552;
	mul.ftz.f32 	%f5553, %f7620, %f7644;
	fma.rn.ftz.f32 	%f5554, %f7617, %f7643, %f5553;
	fma.rn.ftz.f32 	%f2192, %f7623, %f7645, %f5554;
	mul.ftz.f32 	%f5555, %f7619, %f7644;
	fma.rn.ftz.f32 	%f5556, %f7616, %f7643, %f5555;
	fma.rn.ftz.f32 	%f2193, %f7622, %f7645, %f5556;
	mul.ftz.f32 	%f5557, %f7618, %f7644;
	fma.rn.ftz.f32 	%f5558, %f7615, %f7643, %f5557;
	fma.rn.ftz.f32 	%f7645, %f7621, %f7645, %f5558;
	mov.f32 	%f7643, %f2192;
	mov.f32 	%f7644, %f2193;
	mov.f32 	%f7646, %f2189;
	mov.f32 	%f7647, %f2190;
	mov.f32 	%f7649, %f2186;
	mov.f32 	%f7650, %f2187;

$L__BB4_316:
	add.s32 	%r2522, %r2522, 1;
	setp.lt.u32 	%p250, %r2522, %r2070;
	mov.f32 	%f7615, %f7651;
	mov.f32 	%f7616, %f7650;
	mov.f32 	%f7617, %f7649;
	mov.f32 	%f7618, %f7648;
	mov.f32 	%f7619, %f7647;
	mov.f32 	%f7620, %f7646;
	mov.f32 	%f7621, %f7645;
	mov.f32 	%f7622, %f7644;
	mov.f32 	%f7623, %f7643;
	@%p250 bra 	$L__BB4_300;

$L__BB4_317:
	mul.ftz.f32 	%f5559, %f7670, %f7649;
	fma.rn.ftz.f32 	%f5560, %f7671, %f7646, %f5559;
	mul.ftz.f32 	%f5561, %f7670, %f7650;
	fma.rn.ftz.f32 	%f5562, %f7671, %f7647, %f5561;
	mul.ftz.f32 	%f5563, %f7670, %f7651;
	fma.rn.ftz.f32 	%f5564, %f7671, %f7648, %f5563;
	fma.rn.ftz.f32 	%f7672, %f2080, %f7645, %f5564;
	fma.rn.ftz.f32 	%f7671, %f2080, %f7644, %f5562;
	fma.rn.ftz.f32 	%f7670, %f2080, %f7643, %f5560;
	bra.uni 	$L__BB4_319;

$L__BB4_318:
	mov.f32 	%f7672, %f2080;

$L__BB4_319:
	ld.f32 	%f7728, [%rd108+12];
	ld.f32 	%f7729, [%rd108+16];
	ld.f32 	%f2224, [%rd108+20];
	// begin inline asm
	call (%r2221), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p251, %r2221, 0;
	@%p251 bra 	$L__BB4_340;

	// begin inline asm
	call (%r2222), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f5565), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p252, %r2222, 0;
	@%p252 bra 	$L__BB4_339;

	mov.u32 	%r2523, 0;

$L__BB4_322:
	.pragma "nounroll";
	// begin inline asm
	call (%rd1784), _optix_get_transform_list_handle, (%r2523);
	// end inline asm
	// begin inline asm
	call (%r2225), _optix_get_transform_type_from_handle, (%rd1784);
	// end inline asm
	or.b32  	%r2226, %r2225, 1;
	setp.eq.s32 	%p253, %r2226, 3;
	@%p253 bra 	$L__BB4_329;
	bra.uni 	$L__BB4_323;

$L__BB4_329:
	setp.eq.s32 	%p257, %r2225, 2;
	@%p257 bra 	$L__BB4_333;
	bra.uni 	$L__BB4_330;

$L__BB4_333:
	// begin inline asm
	call (%rd1856), _optix_get_matrix_motion_transform_from_handle, (%rd1784);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd1858, %rd1856;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2314,%r2315,%r2316,%r2317}, [%rd1858];
	// end inline asm
	add.s64 	%rd1862, %rd1856, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1861, %rd1862;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2318,%r2319,%r2320,%r2321}, [%rd1861];
	// end inline asm
	add.s64 	%rd1865, %rd1856, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1864, %rd1865;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2322,%r2323,%r2324,%r2325}, [%rd1864];
	// end inline asm
	add.s64 	%rd1868, %rd1856, 48;
	// begin inline asm
	cvta.to.global.u64 %rd1867, %rd1868;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2326,%r2327,%r2328,%r2329}, [%rd1867];
	// end inline asm
	add.s64 	%rd1871, %rd1856, 64;
	// begin inline asm
	cvta.to.global.u64 %rd1870, %rd1871;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2330,%r2331,%r2332,%r2333}, [%rd1870];
	// end inline asm
	add.s64 	%rd1874, %rd1856, 80;
	// begin inline asm
	cvta.to.global.u64 %rd1873, %rd1874;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2334,%r2335,%r2336,%r2337}, [%rd1873];
	// end inline asm
	add.s64 	%rd1877, %rd1856, 96;
	// begin inline asm
	cvta.to.global.u64 %rd1876, %rd1877;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2338,%r2339,%r2340,%r2341}, [%rd1876];
	// end inline asm
	add.s64 	%rd1880, %rd1856, 112;
	// begin inline asm
	cvta.to.global.u64 %rd1879, %rd1880;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2342,%r2343,%r2344,%r2345}, [%rd1879];
	// end inline asm
	mov.b32 	%f5662, %r2317;
	mov.b32 	%f5663, %r2318;
	and.b32  	%r2358, %r2316, 65535;
	add.s32 	%r2359, %r2358, -1;
	cvt.rn.f32.s32 	%f5664, %r2359;
	sub.ftz.f32 	%f5665, %f5565, %f5662;
	sub.ftz.f32 	%f5666, %f5663, %f5662;
	div.approx.ftz.f32 	%f5667, %f5665, %f5666;
	mul.ftz.f32 	%f5668, %f5667, %f5664;
	min.ftz.f32 	%f5669, %f5664, %f5668;
	mov.f32 	%f5670, 0f00000000;
	max.ftz.f32 	%f5671, %f5670, %f5669;
	setp.num.ftz.f32 	%p260, %f5671, %f5671;
	selp.f32 	%f5672, %f5671, 0f00000000, %p260;
	cvt.rmi.ftz.f32.f32 	%f5673, %f5672;
	add.ftz.f32 	%f5674, %f5664, 0fBF800000;
	min.ftz.f32 	%f5675, %f5673, %f5674;
	sub.ftz.f32 	%f2284, %f5672, %f5675;
	cvt.rzi.ftz.s32.f32 	%r2360, %f5675;
	cvt.s64.s32 	%rd136, %r2360;
	mul.wide.s32 	%rd1891, %r2360, 48;
	add.s64 	%rd1883, %rd1865, %rd1891;
	// begin inline asm
	cvta.to.global.u64 %rd1882, %rd1883;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2346,%r2347,%r2348,%r2349}, [%rd1882];
	// end inline asm
	mov.b32 	%f7698, %r2346;
	mov.b32 	%f7699, %r2347;
	mov.b32 	%f7700, %r2348;
	add.s64 	%rd1886, %rd1883, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1885, %rd1886;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2350,%r2351,%r2352,%r2353}, [%rd1885];
	// end inline asm
	mov.b32 	%f7695, %r2350;
	mov.b32 	%f7696, %r2351;
	mov.b32 	%f7697, %r2352;
	add.s64 	%rd1889, %rd1883, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1888, %rd1889;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2354,%r2355,%r2356,%r2357}, [%rd1888];
	// end inline asm
	mov.b32 	%f7692, %r2354;
	mov.b32 	%f7693, %r2355;
	mov.b32 	%f7694, %r2356;
	setp.leu.ftz.f32 	%p261, %f2284, 0f00000000;
	@%p261 bra 	$L__BB4_335;

	mov.f32 	%f5676, 0f3F800000;
	sub.ftz.f32 	%f5677, %f5676, %f2284;
	mul.lo.s64 	%rd1901, %rd136, 48;
	add.s64 	%rd1902, %rd1856, %rd1901;
	add.s64 	%rd1893, %rd1902, 80;
	// begin inline asm
	cvta.to.global.u64 %rd1892, %rd1893;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2361,%r2362,%r2363,%r2364}, [%rd1892];
	// end inline asm
	mov.b32 	%f5678, %r2361;
	mov.b32 	%f5679, %r2362;
	mov.b32 	%f5680, %r2363;
	mul.ftz.f32 	%f5681, %f2284, %f5678;
	mul.ftz.f32 	%f5682, %f2284, %f5679;
	mul.ftz.f32 	%f5683, %f2284, %f5680;
	fma.rn.ftz.f32 	%f7698, %f5677, %f7698, %f5681;
	fma.rn.ftz.f32 	%f7699, %f5677, %f7699, %f5682;
	fma.rn.ftz.f32 	%f7700, %f5677, %f7700, %f5683;
	add.s64 	%rd1896, %rd1902, 96;
	// begin inline asm
	cvta.to.global.u64 %rd1895, %rd1896;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2365,%r2366,%r2367,%r2368}, [%rd1895];
	// end inline asm
	mov.b32 	%f5684, %r2365;
	mov.b32 	%f5685, %r2366;
	mov.b32 	%f5686, %r2367;
	mul.ftz.f32 	%f5687, %f2284, %f5684;
	mul.ftz.f32 	%f5688, %f2284, %f5685;
	mul.ftz.f32 	%f5689, %f2284, %f5686;
	fma.rn.ftz.f32 	%f7695, %f5677, %f7695, %f5687;
	fma.rn.ftz.f32 	%f7696, %f5677, %f7696, %f5688;
	fma.rn.ftz.f32 	%f7697, %f5677, %f7697, %f5689;
	add.s64 	%rd1899, %rd1902, 112;
	// begin inline asm
	cvta.to.global.u64 %rd1898, %rd1899;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2369,%r2370,%r2371,%r2372}, [%rd1898];
	// end inline asm
	mov.b32 	%f5690, %r2369;
	mov.b32 	%f5691, %r2370;
	mov.b32 	%f5692, %r2371;
	mul.ftz.f32 	%f5693, %f2284, %f5690;
	mul.ftz.f32 	%f5694, %f2284, %f5691;
	mul.ftz.f32 	%f5695, %f2284, %f5692;
	fma.rn.ftz.f32 	%f7692, %f5677, %f7692, %f5693;
	fma.rn.ftz.f32 	%f7693, %f5677, %f7693, %f5694;
	fma.rn.ftz.f32 	%f7694, %f5677, %f7694, %f5695;
	bra.uni 	$L__BB4_335;

$L__BB4_323:
	mov.f32 	%f7701, 0f00000000;
	mov.f32 	%f7703, 0f3F800000;
	setp.eq.s32 	%p254, %r2225, 4;
	@%p254 bra 	$L__BB4_325;

	setp.ne.s32 	%p255, %r2225, 1;
	mov.f32 	%f7702, %f7701;
	mov.f32 	%f7704, %f7701;
	mov.f32 	%f7705, %f7703;
	mov.f32 	%f7706, %f7701;
	mov.f32 	%f7707, %f7703;
	mov.f32 	%f7708, %f7701;
	mov.f32 	%f7709, %f7701;
	@%p255 bra 	$L__BB4_336;

$L__BB4_325:
	@%p254 bra 	$L__BB4_327;
	bra.uni 	$L__BB4_326;

$L__BB4_327:
	// begin inline asm
	call (%rd1976), _optix_get_instance_inverse_transform_from_handle, (%rd1784);
	// end inline asm
	bra.uni 	$L__BB4_328;

$L__BB4_330:
	// begin inline asm
	call (%rd1799), _optix_get_srt_motion_transform_from_handle, (%rd1784);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd1801, %rd1799;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2239,%r2240,%r2241,%r2242}, [%rd1801];
	// end inline asm
	add.s64 	%rd1805, %rd1799, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1804, %rd1805;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2243,%r2244,%r2245,%r2246}, [%rd1804];
	// end inline asm
	add.s64 	%rd1808, %rd1799, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1807, %rd1808;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2247,%r2248,%r2249,%r2250}, [%rd1807];
	// end inline asm
	add.s64 	%rd1811, %rd1799, 48;
	// begin inline asm
	cvta.to.global.u64 %rd1810, %rd1811;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2251,%r2252,%r2253,%r2254}, [%rd1810];
	// end inline asm
	add.s64 	%rd1814, %rd1799, 64;
	// begin inline asm
	cvta.to.global.u64 %rd1813, %rd1814;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2255,%r2256,%r2257,%r2258}, [%rd1813];
	// end inline asm
	add.s64 	%rd1817, %rd1799, 80;
	// begin inline asm
	cvta.to.global.u64 %rd1816, %rd1817;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2259,%r2260,%r2261,%r2262}, [%rd1816];
	// end inline asm
	add.s64 	%rd1820, %rd1799, 96;
	// begin inline asm
	cvta.to.global.u64 %rd1819, %rd1820;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2263,%r2264,%r2265,%r2266}, [%rd1819];
	// end inline asm
	add.s64 	%rd1823, %rd1799, 112;
	// begin inline asm
	cvta.to.global.u64 %rd1822, %rd1823;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2267,%r2268,%r2269,%r2270}, [%rd1822];
	// end inline asm
	add.s64 	%rd1826, %rd1799, 128;
	// begin inline asm
	cvta.to.global.u64 %rd1825, %rd1826;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2271,%r2272,%r2273,%r2274}, [%rd1825];
	// end inline asm
	add.s64 	%rd1829, %rd1799, 144;
	// begin inline asm
	cvta.to.global.u64 %rd1828, %rd1829;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2275,%r2276,%r2277,%r2278}, [%rd1828];
	// end inline asm
	mov.b32 	%f5577, %r2242;
	mov.b32 	%f5578, %r2243;
	and.b32  	%r2295, %r2241, 65535;
	add.s32 	%r2296, %r2295, -1;
	cvt.rn.f32.s32 	%f5579, %r2296;
	sub.ftz.f32 	%f5580, %f5565, %f5577;
	sub.ftz.f32 	%f5581, %f5578, %f5577;
	div.approx.ftz.f32 	%f5582, %f5580, %f5581;
	mul.ftz.f32 	%f5583, %f5582, %f5579;
	min.ftz.f32 	%f5584, %f5579, %f5583;
	mov.f32 	%f5585, 0f00000000;
	max.ftz.f32 	%f5586, %f5585, %f5584;
	setp.num.ftz.f32 	%p258, %f5586, %f5586;
	selp.f32 	%f5587, %f5586, 0f00000000, %p258;
	cvt.rmi.ftz.f32.f32 	%f5588, %f5587;
	add.ftz.f32 	%f5589, %f5579, 0fBF800000;
	min.ftz.f32 	%f5590, %f5588, %f5589;
	sub.ftz.f32 	%f2244, %f5587, %f5590;
	cvt.rzi.ftz.s32.f32 	%r2297, %f5590;
	mul.wide.s32 	%rd1843, %r2297, 64;
	add.s64 	%rd1832, %rd1808, %rd1843;
	// begin inline asm
	cvta.to.global.u64 %rd1831, %rd1832;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2279,%r2280,%r2281,%r2282}, [%rd1831];
	// end inline asm
	mov.b32 	%f7682, %r2279;
	mov.b32 	%f7683, %r2280;
	mov.b32 	%f7684, %r2281;
	add.s64 	%rd1835, %rd1832, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1834, %rd1835;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2283,%r2284,%r2285,%r2286}, [%rd1834];
	// end inline asm
	mov.b32 	%f7685, %r2283;
	mov.b32 	%f7686, %r2284;
	mov.b32 	%f7687, %r2286;
	add.s64 	%rd1838, %rd1832, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1837, %rd1838;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2287,%r2288,%r2289,%r2290}, [%rd1837];
	// end inline asm
	mov.b32 	%f7688, %r2288;
	mov.b32 	%f7689, %r2289;
	mov.b32 	%f7690, %r2290;
	add.s64 	%rd1841, %rd1832, 48;
	// begin inline asm
	cvta.to.global.u64 %rd1840, %rd1841;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2291,%r2292,%r2293,%r2294}, [%rd1840];
	// end inline asm
	mov.b32 	%f7691, %r2291;
	setp.leu.ftz.f32 	%p259, %f2244, 0f00000000;
	@%p259 bra 	$L__BB4_332;

	mov.f32 	%f5591, 0f3F800000;
	sub.ftz.f32 	%f5592, %f5591, %f2244;
	add.s64 	%rd1845, %rd1832, 64;
	// begin inline asm
	cvta.to.global.u64 %rd1844, %rd1845;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2298,%r2299,%r2300,%r2301}, [%rd1844];
	// end inline asm
	mov.b32 	%f5593, %r2298;
	mov.b32 	%f5594, %r2299;
	mov.b32 	%f5595, %r2300;
	mul.ftz.f32 	%f5596, %f2244, %f5593;
	mul.ftz.f32 	%f5597, %f2244, %f5594;
	mul.ftz.f32 	%f5598, %f2244, %f5595;
	fma.rn.ftz.f32 	%f7682, %f5592, %f7682, %f5596;
	fma.rn.ftz.f32 	%f7683, %f5592, %f7683, %f5597;
	fma.rn.ftz.f32 	%f7684, %f5592, %f7684, %f5598;
	add.s64 	%rd1848, %rd1832, 80;
	// begin inline asm
	cvta.to.global.u64 %rd1847, %rd1848;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2302,%r2303,%r2304,%r2305}, [%rd1847];
	// end inline asm
	mov.b32 	%f5599, %r2302;
	mov.b32 	%f5600, %r2303;
	mov.b32 	%f5601, %r2305;
	mul.ftz.f32 	%f5602, %f2244, %f5599;
	mul.ftz.f32 	%f5603, %f2244, %f5600;
	mul.ftz.f32 	%f5604, %f2244, %f5601;
	fma.rn.ftz.f32 	%f7685, %f5592, %f7685, %f5602;
	fma.rn.ftz.f32 	%f7686, %f5592, %f7686, %f5603;
	fma.rn.ftz.f32 	%f7687, %f5592, %f7687, %f5604;
	add.s64 	%rd1851, %rd1832, 96;
	// begin inline asm
	cvta.to.global.u64 %rd1850, %rd1851;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2306,%r2307,%r2308,%r2309}, [%rd1850];
	// end inline asm
	mov.b32 	%f5605, %r2307;
	mov.b32 	%f5606, %r2308;
	mov.b32 	%f5607, %r2309;
	mul.ftz.f32 	%f5608, %f2244, %f5605;
	mul.ftz.f32 	%f5609, %f2244, %f5606;
	mul.ftz.f32 	%f5610, %f2244, %f5607;
	fma.rn.ftz.f32 	%f5611, %f5592, %f7688, %f5608;
	fma.rn.ftz.f32 	%f5612, %f5592, %f7689, %f5609;
	fma.rn.ftz.f32 	%f5613, %f5592, %f7690, %f5610;
	add.s64 	%rd1854, %rd1832, 112;
	// begin inline asm
	cvta.to.global.u64 %rd1853, %rd1854;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2310,%r2311,%r2312,%r2313}, [%rd1853];
	// end inline asm
	mov.b32 	%f5614, %r2310;
	mul.ftz.f32 	%f5615, %f2244, %f5614;
	fma.rn.ftz.f32 	%f5616, %f5592, %f7691, %f5615;
	mul.ftz.f32 	%f5617, %f5612, %f5612;
	fma.rn.ftz.f32 	%f5618, %f5611, %f5611, %f5617;
	fma.rn.ftz.f32 	%f5619, %f5613, %f5613, %f5618;
	fma.rn.ftz.f32 	%f5620, %f5616, %f5616, %f5619;
	rsqrt.approx.ftz.f32 	%f5621, %f5620;
	mul.ftz.f32 	%f7688, %f5611, %f5621;
	mul.ftz.f32 	%f7689, %f5612, %f5621;
	mul.ftz.f32 	%f7690, %f5613, %f5621;
	mul.ftz.f32 	%f7691, %f5621, %f5616;

$L__BB4_332:
	mul.ftz.f32 	%f5622, %f7689, %f7689;
	mul.ftz.f32 	%f5623, %f7688, %f7688;
	sub.ftz.f32 	%f5624, %f5623, %f5622;
	mul.ftz.f32 	%f5625, %f7690, %f7690;
	sub.ftz.f32 	%f5626, %f5624, %f5625;
	fma.rn.ftz.f32 	%f5627, %f7691, %f7691, %f5626;
	mul.ftz.f32 	%f5628, %f7690, %f7691;
	mul.ftz.f32 	%f5629, %f7688, %f7689;
	sub.ftz.f32 	%f5630, %f5629, %f5628;
	add.ftz.f32 	%f5631, %f5630, %f5630;
	mul.ftz.f32 	%f5632, %f7689, %f7691;
	mul.ftz.f32 	%f5633, %f7688, %f7690;
	add.ftz.f32 	%f5634, %f5633, %f5632;
	add.ftz.f32 	%f5635, %f5634, %f5634;
	add.ftz.f32 	%f5636, %f5629, %f5628;
	add.ftz.f32 	%f5637, %f5636, %f5636;
	sub.ftz.f32 	%f5638, %f5622, %f5623;
	sub.ftz.f32 	%f5639, %f5638, %f5625;
	fma.rn.ftz.f32 	%f5640, %f7691, %f7691, %f5639;
	mul.ftz.f32 	%f5641, %f7688, %f7691;
	mul.ftz.f32 	%f5642, %f7689, %f7690;
	sub.ftz.f32 	%f5643, %f5642, %f5641;
	add.ftz.f32 	%f5644, %f5643, %f5643;
	sub.ftz.f32 	%f5645, %f5633, %f5632;
	add.ftz.f32 	%f5646, %f5645, %f5645;
	add.ftz.f32 	%f5647, %f5642, %f5641;
	add.ftz.f32 	%f5648, %f5647, %f5647;
	neg.ftz.f32 	%f5649, %f5623;
	sub.ftz.f32 	%f5650, %f5649, %f5622;
	add.ftz.f32 	%f5651, %f5650, %f5625;
	fma.rn.ftz.f32 	%f5652, %f7691, %f7691, %f5651;
	mul.ftz.f32 	%f5653, %f7686, %f5631;
	fma.rn.ftz.f32 	%f5654, %f7684, %f5627, %f5653;
	fma.rn.ftz.f32 	%f7700, %f7687, %f5635, %f5654;
	mul.ftz.f32 	%f5655, %f7684, %f5637;
	fma.rn.ftz.f32 	%f5656, %f7686, %f5640, %f5655;
	fma.rn.ftz.f32 	%f7697, %f7687, %f5644, %f5656;
	mul.ftz.f32 	%f5657, %f7686, %f5648;
	fma.rn.ftz.f32 	%f5658, %f7684, %f5646, %f5657;
	fma.rn.ftz.f32 	%f7694, %f7687, %f5652, %f5658;
	mul.ftz.f32 	%f5659, %f7685, %f5631;
	fma.rn.ftz.f32 	%f7699, %f7683, %f5627, %f5659;
	mul.ftz.f32 	%f5660, %f7683, %f5637;
	fma.rn.ftz.f32 	%f7696, %f7685, %f5640, %f5660;
	mul.ftz.f32 	%f5661, %f7685, %f5648;
	fma.rn.ftz.f32 	%f7693, %f7683, %f5646, %f5661;
	mul.ftz.f32 	%f7698, %f7682, %f5627;
	mul.ftz.f32 	%f7695, %f7682, %f5637;
	mul.ftz.f32 	%f7692, %f7682, %f5646;

$L__BB4_335:
	mul.ftz.f32 	%f5696, %f7693, %f7697;
	mul.ftz.f32 	%f5697, %f7694, %f7696;
	sub.ftz.f32 	%f5698, %f5697, %f5696;
	mul.ftz.f32 	%f5699, %f7698, %f5698;
	mul.ftz.f32 	%f5700, %f7692, %f7697;
	mul.ftz.f32 	%f5701, %f7694, %f7695;
	sub.ftz.f32 	%f5702, %f5701, %f5700;
	mul.ftz.f32 	%f5703, %f5702, %f7699;
	sub.ftz.f32 	%f5704, %f5699, %f5703;
	mul.ftz.f32 	%f5705, %f7692, %f7696;
	mul.ftz.f32 	%f5706, %f7693, %f7695;
	sub.ftz.f32 	%f5707, %f5706, %f5705;
	fma.rn.ftz.f32 	%f5708, %f5707, %f7700, %f5704;
	rcp.approx.ftz.f32 	%f5709, %f5708;
	mul.ftz.f32 	%f7707, %f5698, %f5709;
	mul.ftz.f32 	%f5710, %f7694, %f7699;
	mul.ftz.f32 	%f5711, %f7693, %f7700;
	sub.ftz.f32 	%f5712, %f5711, %f5710;
	mul.ftz.f32 	%f7708, %f5712, %f5709;
	mul.ftz.f32 	%f5713, %f7696, %f7700;
	mul.ftz.f32 	%f5714, %f7697, %f7699;
	sub.ftz.f32 	%f5715, %f5714, %f5713;
	mul.ftz.f32 	%f7709, %f5715, %f5709;
	sub.ftz.f32 	%f5716, %f5700, %f5701;
	mul.ftz.f32 	%f7704, %f5716, %f5709;
	mul.ftz.f32 	%f5717, %f7692, %f7700;
	mul.ftz.f32 	%f5718, %f7694, %f7698;
	sub.ftz.f32 	%f5719, %f5718, %f5717;
	mul.ftz.f32 	%f7705, %f5719, %f5709;
	mul.ftz.f32 	%f5720, %f7697, %f7698;
	mul.ftz.f32 	%f5721, %f7695, %f7700;
	sub.ftz.f32 	%f5722, %f5721, %f5720;
	mul.ftz.f32 	%f7706, %f5722, %f5709;
	mul.ftz.f32 	%f7701, %f5707, %f5709;
	mul.ftz.f32 	%f5723, %f7693, %f7698;
	mul.ftz.f32 	%f5724, %f7692, %f7699;
	sub.ftz.f32 	%f5725, %f5724, %f5723;
	mul.ftz.f32 	%f7702, %f5725, %f5709;
	mul.ftz.f32 	%f5726, %f7695, %f7699;
	mul.ftz.f32 	%f5727, %f7696, %f7698;
	sub.ftz.f32 	%f5728, %f5727, %f5726;
	mul.ftz.f32 	%f7703, %f5728, %f5709;
	bra.uni 	$L__BB4_336;

$L__BB4_326:
	// begin inline asm
	call (%rd1786), _optix_get_static_transform_from_handle, (%rd1784);
	// end inline asm
	add.s64 	%rd1976, %rd1786, 64;

$L__BB4_328:
	// begin inline asm
	cvta.to.global.u64 %rd1790, %rd1976;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2227,%r2228,%r2229,%r2230}, [%rd1790];
	// end inline asm
	mov.b32 	%f7707, %r2227;
	mov.b32 	%f7708, %r2228;
	mov.b32 	%f7709, %r2229;
	add.s64 	%rd1794, %rd1976, 16;
	// begin inline asm
	cvta.to.global.u64 %rd1793, %rd1794;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2231,%r2232,%r2233,%r2234}, [%rd1793];
	// end inline asm
	mov.b32 	%f7704, %r2231;
	mov.b32 	%f7705, %r2232;
	mov.b32 	%f7706, %r2233;
	add.s64 	%rd1797, %rd1976, 32;
	// begin inline asm
	cvta.to.global.u64 %rd1796, %rd1797;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r2235,%r2236,%r2237,%r2238}, [%rd1796];
	// end inline asm
	mov.b32 	%f7701, %r2235;
	mov.b32 	%f7702, %r2236;
	mov.b32 	%f7703, %r2237;

$L__BB4_336:
	setp.eq.s32 	%p262, %r2523, 0;
	@%p262 bra 	$L__BB4_338;

	mul.ftz.f32 	%f5729, %f7678, %f7708;
	fma.rn.ftz.f32 	%f5730, %f7675, %f7707, %f5729;
	fma.rn.ftz.f32 	%f2330, %f7681, %f7709, %f5730;
	mul.ftz.f32 	%f5731, %f7677, %f7708;
	fma.rn.ftz.f32 	%f5732, %f7674, %f7707, %f5731;
	fma.rn.ftz.f32 	%f2331, %f7680, %f7709, %f5732;
	mul.ftz.f32 	%f5733, %f7676, %f7708;
	fma.rn.ftz.f32 	%f5734, %f7673, %f7707, %f5733;
	fma.rn.ftz.f32 	%f7709, %f7679, %f7709, %f5734;
	mul.ftz.f32 	%f5735, %f7678, %f7705;
	fma.rn.ftz.f32 	%f5736, %f7675, %f7704, %f5735;
	fma.rn.ftz.f32 	%f2333, %f7681, %f7706, %f5736;
	mul.ftz.f32 	%f5737, %f7677, %f7705;
	fma.rn.ftz.f32 	%f5738, %f7674, %f7704, %f5737;
	fma.rn.ftz.f32 	%f2334, %f7680, %f7706, %f5738;
	mul.ftz.f32 	%f5739, %f7676, %f7705;
	fma.rn.ftz.f32 	%f5740, %f7673, %f7704, %f5739;
	fma.rn.ftz.f32 	%f7706, %f7679, %f7706, %f5740;
	mul.ftz.f32 	%f5741, %f7678, %f7702;
	fma.rn.ftz.f32 	%f5742, %f7675, %f7701, %f5741;
	fma.rn.ftz.f32 	%f2336, %f7681, %f7703, %f5742;
	mul.ftz.f32 	%f5743, %f7677, %f7702;
	fma.rn.ftz.f32 	%f5744, %f7674, %f7701, %f5743;
	fma.rn.ftz.f32 	%f2337, %f7680, %f7703, %f5744;
	mul.ftz.f32 	%f5745, %f7676, %f7702;
	fma.rn.ftz.f32 	%f5746, %f7673, %f7701, %f5745;
	fma.rn.ftz.f32 	%f7703, %f7679, %f7703, %f5746;
	mov.f32 	%f7701, %f2336;
	mov.f32 	%f7702, %f2337;
	mov.f32 	%f7704, %f2333;
	mov.f32 	%f7705, %f2334;
	mov.f32 	%f7707, %f2330;
	mov.f32 	%f7708, %f2331;

$L__BB4_338:
	add.s32 	%r2523, %r2523, 1;
	setp.lt.u32 	%p263, %r2523, %r2222;
	mov.f32 	%f7673, %f7709;
	mov.f32 	%f7674, %f7708;
	mov.f32 	%f7675, %f7707;
	mov.f32 	%f7676, %f7706;
	mov.f32 	%f7677, %f7705;
	mov.f32 	%f7678, %f7704;
	mov.f32 	%f7679, %f7703;
	mov.f32 	%f7680, %f7702;
	mov.f32 	%f7681, %f7701;
	@%p263 bra 	$L__BB4_322;

$L__BB4_339:
	mul.ftz.f32 	%f5747, %f7728, %f7707;
	fma.rn.ftz.f32 	%f5748, %f7729, %f7704, %f5747;
	mul.ftz.f32 	%f5749, %f7728, %f7708;
	fma.rn.ftz.f32 	%f5750, %f7729, %f7705, %f5749;
	mul.ftz.f32 	%f5751, %f7728, %f7709;
	fma.rn.ftz.f32 	%f5752, %f7729, %f7706, %f5751;
	fma.rn.ftz.f32 	%f7730, %f2224, %f7703, %f5752;
	fma.rn.ftz.f32 	%f7729, %f2224, %f7702, %f5750;
	fma.rn.ftz.f32 	%f7728, %f2224, %f7701, %f5748;
	bra.uni 	$L__BB4_341;

$L__BB4_340:
	mov.f32 	%f7730, %f2224;

$L__BB4_341:
	ld.const.u64 	%rd1962, [plp+336];
	cvta.to.global.u64 	%rd1961, %rd1962;
	mul.ftz.f32 	%f5753, %f1926, %f7670;
	fma.rn.ftz.f32 	%f5754, %f1925, %f7612, %f5753;
	mul.ftz.f32 	%f5755, %f1926, %f7671;
	fma.rn.ftz.f32 	%f5756, %f1925, %f7613, %f5755;
	mul.ftz.f32 	%f5757, %f1926, %f7672;
	fma.rn.ftz.f32 	%f5758, %f1925, %f7614, %f5757;
	fma.rn.ftz.f32 	%f5759, %f1927, %f7728, %f5754;
	fma.rn.ftz.f32 	%f5760, %f1927, %f7729, %f5756;
	fma.rn.ftz.f32 	%f5761, %f1927, %f7730, %f5758;
	mul.ftz.f32 	%f5762, %f5760, %f5760;
	fma.rn.ftz.f32 	%f5763, %f5759, %f5759, %f5762;
	fma.rn.ftz.f32 	%f5764, %f5761, %f5761, %f5763;
	rsqrt.approx.ftz.f32 	%f5765, %f5764;
	mul.ftz.f32 	%f7751, %f5765, %f5759;
	mul.ftz.f32 	%f7752, %f5765, %f5760;
	mul.ftz.f32 	%f7753, %f5765, %f5761;
	ld.global.u32 	%r2373, [%rd90+8];
	ld.f32 	%f5766, [%rd92+36];
	ld.f32 	%f5767, [%rd92+40];
	ld.f32 	%f5768, [%rd100+36];
	mul.ftz.f32 	%f5769, %f1926, %f5768;
	ld.f32 	%f5770, [%rd100+40];
	mul.ftz.f32 	%f5771, %f1926, %f5770;
	fma.rn.ftz.f32 	%f5772, %f1925, %f5766, %f5769;
	fma.rn.ftz.f32 	%f5773, %f1925, %f5767, %f5771;
	ld.f32 	%f5774, [%rd108+36];
	ld.f32 	%f5775, [%rd108+40];
	fma.rn.ftz.f32 	%f2369, %f1927, %f5774, %f5772;
	fma.rn.ftz.f32 	%f2370, %f1927, %f5775, %f5773;
	mul.wide.u32 	%rd1903, %r2373, 272;
	add.s64 	%rd1904, %rd1961, %rd1903;
	ld.global.u64 	%rd137, [%rd1904+160];
	setp.eq.s64 	%p264, %rd137, 0;
	@%p264 bra 	$L__BB4_343;

	mov.f32 	%f5776, 0f00000000;
	tex.level.2d.v4.f32.f32 	{%f5777, %f5778, %f5779, %f5780}, [%rd137, {%f2369, %f2370}], %f5776;
	ld.const.f32 	%f5781, [plp+288];
	mul.ftz.f32 	%f7745, %f5777, %f5781;
	mul.ftz.f32 	%f7746, %f5778, %f5781;
	mul.ftz.f32 	%f7747, %f5779, %f5781;
	bra.uni 	$L__BB4_344;

$L__BB4_343:
	ld.global.f32 	%f7745, [_Z15sampleAreaLightRK9Point3D_TIfEfffPN11milo_shared11LightSampleEPf$286];
	ld.global.f32 	%f7746, [_Z15sampleAreaLightRK9Point3D_TIfEfffPN11milo_shared11LightSampleEPf$286+4];
	ld.global.f32 	%f7747, [_Z15sampleAreaLightRK9Point3D_TIfEfffPN11milo_shared11LightSampleEPf$286+8];

$L__BB4_344:
	sub.ftz.f32 	%f5782, %f7556, %f7422;
	sub.ftz.f32 	%f5783, %f7488, %f7421;
	mul.ftz.f32 	%f5784, %f5783, %f5782;
	sub.ftz.f32 	%f5785, %f7555, %f7421;
	sub.ftz.f32 	%f5786, %f7489, %f7422;
	mul.ftz.f32 	%f5787, %f5786, %f5785;
	sub.ftz.f32 	%f5788, %f5784, %f5787;
	sub.ftz.f32 	%f5789, %f7554, %f7420;
	mul.ftz.f32 	%f5790, %f5786, %f5789;
	sub.ftz.f32 	%f5791, %f7487, %f7420;
	mul.ftz.f32 	%f5792, %f5791, %f5782;
	sub.ftz.f32 	%f5793, %f5790, %f5792;
	mul.ftz.f32 	%f5794, %f5791, %f5785;
	mul.ftz.f32 	%f5795, %f5783, %f5789;
	sub.ftz.f32 	%f5796, %f5794, %f5795;
	mul.ftz.f32 	%f5797, %f5793, %f5793;
	fma.rn.ftz.f32 	%f5798, %f5788, %f5788, %f5797;
	fma.rn.ftz.f32 	%f5799, %f5796, %f5796, %f5798;
	sqrt.approx.ftz.f32 	%f5800, %f5799;
	mul.ftz.f32 	%f5801, %f5800, 0f3F000000;
	div.approx.ftz.f32 	%f7744, %f1405, %f5801;
	mov.u32 	%r2532, 0;

$L__BB4_362:
	setp.le.ftz.f32 	%p283, %f7744, 0f00000000;
	selp.f32 	%f2420, %f1386, %f1387, %p4;
	@%p283 bra 	$L__BB4_391;

	mul.ftz.f32 	%f2421, %f2420, %f7744;
	sub.ftz.f32 	%f5862, %f7748, %f824;
	setp.eq.s32 	%p284, %r2532, 0;
	selp.f32 	%f5863, %f5862, %f7748, %p284;
	sub.ftz.f32 	%f5864, %f7749, %f825;
	selp.f32 	%f5865, %f5864, %f7749, %p284;
	sub.ftz.f32 	%f5866, %f7750, %f826;
	selp.f32 	%f5867, %f5866, %f7750, %p284;
	mul.ftz.f32 	%f5868, %f5865, %f5865;
	fma.rn.ftz.f32 	%f5869, %f5863, %f5863, %f5868;
	fma.rn.ftz.f32 	%f2422, %f5867, %f5867, %f5869;
	sqrt.approx.ftz.f32 	%f2423, %f2422;
	rsqrt.approx.ftz.f32 	%f5870, %f2422;
	mul.ftz.f32 	%f2424, %f5863, %f5870;
	mul.ftz.f32 	%f2425, %f5865, %f5870;
	mul.ftz.f32 	%f2426, %f5867, %f5870;
	mul.ftz.f32 	%f5871, %f7146, %f2425;
	fma.rn.ftz.f32 	%f5872, %f7147, %f2424, %f5871;
	fma.rn.ftz.f32 	%f2427, %f7145, %f2426, %f5872;
	mul.ftz.f32 	%f5873, %f822, %f2425;
	fma.rn.ftz.f32 	%f5874, %f821, %f2424, %f5873;
	fma.rn.ftz.f32 	%f2428, %f823, %f2426, %f5874;
	mul.ftz.f32 	%f5875, %f7140, %f2425;
	fma.rn.ftz.f32 	%f5876, %f7141, %f2424, %f5875;
	fma.rn.ftz.f32 	%f2429, %f7139, %f2426, %f5876;
	setp.le.ftz.f32 	%p285, %f2429, 0f00000000;
	mov.f32 	%f7754, 0f00000000;
	@%p285 bra 	$L__BB4_365;

	add.ftz.f32 	%f5877, %f827, %f2427;
	add.ftz.f32 	%f5878, %f828, %f2428;
	mul.ftz.f32 	%f5879, %f5878, %f5878;
	fma.rn.ftz.f32 	%f5880, %f5877, %f5877, %f5879;
	add.ftz.f32 	%f5881, %f829, %f2429;
	fma.rn.ftz.f32 	%f5882, %f5881, %f5881, %f5880;
	rsqrt.approx.ftz.f32 	%f5883, %f5882;
	mov.f32 	%f5884, 0f3F800000;
	mul.ftz.f32 	%f5885, %f5877, %f5883;
	mul.ftz.f32 	%f5886, %f5878, %f5883;
	mul.ftz.f32 	%f5887, %f5881, %f5883;
	mul.ftz.f32 	%f5888, %f7148, %f7149;
	sqrt.approx.ftz.f32 	%f5889, %f5888;
	mov.f32 	%f5890, 0f00000000;
	max.ftz.f32 	%f5891, %f829, %f5890;
	mul.ftz.f32 	%f5892, %f5891, %f5891;
	sub.ftz.f32 	%f5893, %f5884, %f5892;
	div.approx.ftz.f32 	%f5894, %f5893, %f5892;
	mul.ftz.f32 	%f5895, %f5889, %f5889;
	fma.rn.ftz.f32 	%f5896, %f5895, %f5894, 0f3F800000;
	sqrt.approx.ftz.f32 	%f5897, %f5896;
	add.ftz.f32 	%f5898, %f5897, 0f3F800000;
	mov.f32 	%f5899, 0f40000000;
	div.approx.ftz.f32 	%f5900, %f5899, %f5898;
	mul.ftz.f32 	%f5901, %f5885, %f5885;
	mul.ftz.f32 	%f5902, %f7148, %f7148;
	div.approx.ftz.f32 	%f5903, %f5901, %f5902;
	mul.ftz.f32 	%f5904, %f5886, %f5886;
	mul.ftz.f32 	%f5905, %f7149, %f7149;
	div.approx.ftz.f32 	%f5906, %f5904, %f5905;
	add.ftz.f32 	%f5907, %f5903, %f5906;
	fma.rn.ftz.f32 	%f5908, %f5887, %f5887, %f5907;
	mov.f32 	%f5909, 0f33D6BF95;
	max.ftz.f32 	%f5910, %f5908, %f5909;
	mul.ftz.f32 	%f5911, %f7148, 0f40490FDB;
	mul.ftz.f32 	%f5912, %f5911, %f7149;
	mul.ftz.f32 	%f5913, %f5912, %f5910;
	mul.ftz.f32 	%f5914, %f5910, %f5913;
	rcp.approx.ftz.f32 	%f5915, %f5914;
	mul.ftz.f32 	%f5916, %f5900, %f5915;
	mul.ftz.f32 	%f5917, %f5891, 0f40800000;
	div.approx.ftz.f32 	%f7754, %f5916, %f5917;

$L__BB4_365:
	abs.ftz.f32 	%f5921, %f7754;
	setp.geu.ftz.f32 	%p286, %f5921, 0f7F800000;
	setp.le.ftz.f32 	%p287, %f7754, 0f00000000;
	or.pred  	%p288, %p287, %p286;
	@%p288 bra 	$L__BB4_391;

	mul.ftz.f32 	%f5925, %f2421, %f2421;
	fma.rn.ftz.f32 	%f5926, %f7754, %f7754, %f5925;
	div.approx.ftz.f32 	%f2432, %f5925, %f5926;
	setp.leu.ftz.f32 	%p289, %f2421, 0f00000000;
	@%p289 bra 	$L__BB4_391;

	mov.u32 	%r2476, 0;
	mul.ftz.f32 	%f5939, %f7752, %f2425;
	neg.ftz.f32 	%f5940, %f5939;
	mul.ftz.f32 	%f5941, %f7751, %f2424;
	sub.ftz.f32 	%f5942, %f5940, %f5941;
	mul.ftz.f32 	%f5943, %f7753, %f2426;
	sub.ftz.f32 	%f2433, %f5942, %f5943;
	ld.const.u64 	%rd1942, [plp];
	mul.ftz.f32 	%f5944, %f2423, 0f3F7FF972;
	selp.f32 	%f5934, %f5944, 0f5014FF28, %p284;
	mov.u32 	%r2439, 255;
	mov.u32 	%r2442, 2;
	mov.u32 	%r2444, 1;
	mov.u32 	%r2445, 1065353216;
	mov.f32 	%f7764, 0f00000000;
	// begin inline asm
	call(%r2406,%r2407,%r2408,%r2409,%r2410,%r2411,%r2412,%r2413,%r2414,%r2415,%r2416,%r2417,%r2418,%r2419,%r2420,%r2421,%r2422,%r2423,%r2424,%r2425,%r2426,%r2427,%r2428,%r2429,%r2430,%r2431,%r2432,%r2433,%r2434,%r2435,%r2436,%r2437),_optix_trace_typed_32,(%r2476,%rd1942,%f824,%f825,%f826,%f2424,%f2425,%f2426,%f7764,%f5934,%f7764,%r2439,%r2476,%r2444,%r2442,%r2444,%r2444,%r2445,%r2476,%r2476,%r2476,%r2476,%r2476,%r2476,%r2476,%r2476,%r2476,%r2476,%r2476,%r2476,%r2476,%r2476,%r2476,%r2476,%r2476,%r2476,%r2476,%r2476,%r2476,%r2476,%r2476,%r2476,%r2476,%r2476,%r2476,%r2476,%r2476,%r2476,%r2476);
	// end inline asm
	mov.b32 	%f5945, %r2406;
	setp.leu.ftz.f32 	%p291, %f5945, 0f00000000;
	setp.leu.ftz.f32 	%p292, %f2433, 0f00000000;
	or.pred  	%p293, %p292, %p291;
	mov.f32 	%f7768, %f7764;
	mov.f32 	%f7769, %f7764;
	@%p293 bra 	$L__BB4_390;

	setp.gt.ftz.f32 	%p294, %f845, 0f3F666666;
	setp.lt.ftz.f32 	%p295, %f848, 0f3B03126F;
	and.pred  	%p296, %p295, %p294;
	mov.f32 	%f7765, %f7764;
	mov.f32 	%f7766, %f7764;
	@%p296 bra 	$L__BB4_389;

	setp.leu.ftz.f32 	%p297, %f845, 0f00000000;
	setp.gtu.ftz.f32 	%p298, %f844, 0f00000000;
	or.pred  	%p299, %p298, %p297;
	@%p299 bra 	$L__BB4_382;
	bra.uni 	$L__BB4_370;

$L__BB4_382:
	add.ftz.f32 	%f6131, %f827, %f2427;
	add.ftz.f32 	%f6132, %f828, %f2428;
	mul.ftz.f32 	%f6133, %f6132, %f6132;
	fma.rn.ftz.f32 	%f6134, %f6131, %f6131, %f6133;
	add.ftz.f32 	%f6135, %f829, %f2429;
	fma.rn.ftz.f32 	%f6136, %f6135, %f6135, %f6134;
	rsqrt.approx.ftz.f32 	%f6137, %f6136;
	mul.ftz.f32 	%f2463, %f6131, %f6137;
	mul.ftz.f32 	%f2464, %f6132, %f6137;
	mul.ftz.f32 	%f2465, %f6135, %f6137;
	mul.ftz.f32 	%f6138, %f828, %f2464;
	fma.rn.ftz.f32 	%f6139, %f827, %f2463, %f6138;
	fma.rn.ftz.f32 	%f2466, %f829, %f2465, %f6139;
	mul.ftz.f32 	%f6140, %f2428, %f2464;
	fma.rn.ftz.f32 	%f6141, %f2427, %f2463, %f6140;
	fma.rn.ftz.f32 	%f2467, %f2429, %f2465, %f6141;
	mov.f32 	%f6130, 0f00000000;
	max.ftz.f32 	%f2468, %f2429, %f6130;
	setp.le.ftz.f32 	%p306, %f2468, 0f00000000;
	max.ftz.f32 	%f2469, %f829, %f6130;
	setp.le.ftz.f32 	%p307, %f2469, 0f00000000;
	or.pred  	%p308, %p306, %p307;
	mov.f32 	%f7765, %f7764;
	mov.f32 	%f7766, %f7764;
	@%p308 bra 	$L__BB4_389;

	setp.gt.ftz.f32 	%p309, %f844, 0f00000000;
	@%p309 bra 	$L__BB4_385;
	bra.uni 	$L__BB4_384;

$L__BB4_385:
	ld.global.f32 	%f6147, [_ZNK16DisneyPrincipled8evaluateERK10Vector3D_TIfLb0EES3_$909];
	mov.f32 	%f6148, 0f3F800000;
	sub.ftz.f32 	%f6149, %f6148, %f844;
	mul.ftz.f32 	%f6150, %f6149, %f6147;
	ld.global.f32 	%f6151, [_ZNK16DisneyPrincipled8evaluateERK10Vector3D_TIfLb0EES3_$909+4];
	mul.ftz.f32 	%f6152, %f6149, %f6151;
	ld.global.f32 	%f6153, [_ZNK16DisneyPrincipled8evaluateERK10Vector3D_TIfLb0EES3_$909+8];
	mul.ftz.f32 	%f6154, %f6149, %f6153;
	fma.rn.ftz.f32 	%f7758, %f831, %f844, %f6150;
	fma.rn.ftz.f32 	%f7759, %f832, %f844, %f6152;
	fma.rn.ftz.f32 	%f7760, %f833, %f844, %f6154;
	bra.uni 	$L__BB4_386;

$L__BB4_370:
	setp.eq.s32 	%p300, %r27, 0;
	abs.ftz.f32 	%f2434, %f829;
	abs.ftz.f32 	%f2435, %f2429;
	@%p300 bra 	$L__BB4_379;
	bra.uni 	$L__BB4_371;

$L__BB4_379:
	mul.ftz.f32 	%f6108, %f2434, %f2434;
	fma.rn.ftz.f32 	%f6109, %f830, %f830, %f6108;
	add.ftz.f32 	%f2457, %f6109, 0fBF800000;
	setp.lt.ftz.f32 	%p305, %f2457, 0f00000000;
	mov.f32 	%f6107, 0f3F800000;
	mov.f32 	%f7757, %f6107;
	@%p305 bra 	$L__BB4_381;

	sqrt.approx.ftz.f32 	%f6110, %f2457;
	sub.ftz.f32 	%f6111, %f6110, %f2434;
	add.ftz.f32 	%f6112, %f2434, %f6110;
	div.approx.ftz.f32 	%f6113, %f6111, %f6112;
	mul.ftz.f32 	%f6114, %f6113, %f6113;
	mul.ftz.f32 	%f6115, %f6114, 0f3F000000;
	fma.rn.ftz.f32 	%f6116, %f2434, %f6112, 0fBF800000;
	fma.rn.ftz.f32 	%f6117, %f2434, %f6111, 0f3F800000;
	div.approx.ftz.f32 	%f6118, %f6116, %f6117;
	fma.rn.ftz.f32 	%f6119, %f6118, %f6118, 0f3F800000;
	mul.ftz.f32 	%f7757, %f6115, %f6119;

$L__BB4_381:
	sub.ftz.f32 	%f6121, %f6107, %f7757;
	mul.ftz.f32 	%f6122, %f831, %f6121;
	mul.ftz.f32 	%f6123, %f832, %f6121;
	mul.ftz.f32 	%f6124, %f833, %f6121;
	mul.ftz.f32 	%f6125, %f845, %f6122;
	mul.ftz.f32 	%f6126, %f845, %f6123;
	mul.ftz.f32 	%f6127, %f845, %f6124;
	mul.ftz.f32 	%f7766, %f846, %f6127;
	mul.ftz.f32 	%f7765, %f846, %f6126;
	mul.ftz.f32 	%f7764, %f846, %f6125;
	bra.uni 	$L__BB4_389;

$L__BB4_371:
	mul.ftz.f32 	%f5949, %f828, %f2428;
	fma.rn.ftz.f32 	%f5950, %f827, %f2427, %f5949;
	fma.rn.ftz.f32 	%f5951, %f829, %f2429, %f5950;
	setp.gt.ftz.f32 	%p301, %f5951, 0f00000000;
	@%p301 bra 	$L__BB4_376;
	bra.uni 	$L__BB4_372;

$L__BB4_376:
	add.ftz.f32 	%f6046, %f827, %f2427;
	add.ftz.f32 	%f6047, %f828, %f2428;
	mul.ftz.f32 	%f6048, %f6047, %f6047;
	fma.rn.ftz.f32 	%f6049, %f6046, %f6046, %f6048;
	add.ftz.f32 	%f6050, %f829, %f2429;
	fma.rn.ftz.f32 	%f6051, %f6050, %f6050, %f6049;
	rsqrt.approx.ftz.f32 	%f6052, %f6051;
	mov.f32 	%f6045, 0f3F800000;
	mul.ftz.f32 	%f2447, %f6046, %f6052;
	mul.ftz.f32 	%f2448, %f6047, %f6052;
	mul.ftz.f32 	%f2449, %f6050, %f6052;
	mul.ftz.f32 	%f6053, %f828, %f2448;
	fma.rn.ftz.f32 	%f6054, %f827, %f2447, %f6053;
	fma.rn.ftz.f32 	%f6055, %f829, %f2449, %f6054;
	mov.f32 	%f6056, 0f00000000;
	max.ftz.f32 	%f2450, %f6055, %f6056;
	mul.ftz.f32 	%f6057, %f2450, %f2450;
	fma.rn.ftz.f32 	%f6058, %f830, %f830, %f6057;
	add.ftz.f32 	%f2451, %f6058, 0fBF800000;
	setp.lt.ftz.f32 	%p304, %f2451, 0f00000000;
	mov.f32 	%f7756, %f6045;
	@%p304 bra 	$L__BB4_378;

	sqrt.approx.ftz.f32 	%f6059, %f2451;
	sub.ftz.f32 	%f6060, %f6059, %f2450;
	add.ftz.f32 	%f6061, %f2450, %f6059;
	div.approx.ftz.f32 	%f6062, %f6060, %f6061;
	mul.ftz.f32 	%f6063, %f6062, %f6062;
	mul.ftz.f32 	%f6064, %f6063, 0f3F000000;
	fma.rn.ftz.f32 	%f6065, %f2450, %f6061, 0fBF800000;
	fma.rn.ftz.f32 	%f6066, %f2450, %f6060, 0f3F800000;
	div.approx.ftz.f32 	%f6067, %f6065, %f6066;
	fma.rn.ftz.f32 	%f6068, %f6067, %f6067, 0f3F800000;
	mul.ftz.f32 	%f7756, %f6064, %f6068;

$L__BB4_378:
	mul.ftz.f32 	%f6069, %f7148, %f7149;
	sqrt.approx.ftz.f32 	%f6070, %f6069;
	mul.ftz.f32 	%f6071, %f2447, %f2447;
	mul.ftz.f32 	%f6072, %f7148, %f7148;
	div.approx.ftz.f32 	%f6073, %f6071, %f6072;
	mul.ftz.f32 	%f6074, %f2448, %f2448;
	mul.ftz.f32 	%f6075, %f7149, %f7149;
	div.approx.ftz.f32 	%f6076, %f6074, %f6075;
	add.ftz.f32 	%f6077, %f6073, %f6076;
	fma.rn.ftz.f32 	%f6078, %f2449, %f2449, %f6077;
	mov.f32 	%f6079, 0f33D6BF95;
	max.ftz.f32 	%f6080, %f6078, %f6079;
	mul.ftz.f32 	%f6081, %f7148, 0f40490FDB;
	mul.ftz.f32 	%f6082, %f6081, %f7149;
	mul.ftz.f32 	%f6083, %f6082, %f6080;
	mul.ftz.f32 	%f6084, %f6080, %f6083;
	rcp.approx.ftz.f32 	%f6085, %f6084;
	mul.ftz.f32 	%f6087, %f6070, %f6070;
	sub.ftz.f32 	%f6088, %f6045, %f6087;
	mul.ftz.f32 	%f6089, %f2435, %f2435;
	fma.rn.ftz.f32 	%f6090, %f6089, %f6088, %f6087;
	sqrt.approx.ftz.f32 	%f6091, %f6090;
	mul.ftz.f32 	%f6092, %f2434, %f2434;
	fma.rn.ftz.f32 	%f6093, %f6092, %f6088, %f6087;
	sqrt.approx.ftz.f32 	%f6094, %f6093;
	div.approx.ftz.f32 	%f6095, %f6091, %f2435;
	div.approx.ftz.f32 	%f6096, %f6094, %f2434;
	add.ftz.f32 	%f6097, %f6095, %f6096;
	mov.f32 	%f6098, 0f40000000;
	div.approx.ftz.f32 	%f6099, %f6098, %f6097;
	mul.ftz.f32 	%f6100, %f7756, %f6085;
	mul.ftz.f32 	%f6101, %f6100, %f6099;
	sub.ftz.f32 	%f6102, %f6045, %f845;
	mul.ftz.f32 	%f6103, %f6102, %f6101;
	mul.ftz.f32 	%f6104, %f2434, 0f40800000;
	mul.ftz.f32 	%f6105, %f6104, %f2435;
	rcp.approx.ftz.f32 	%f6106, %f6105;
	mul.ftz.f32 	%f7764, %f6106, %f6103;
	mov.f32 	%f7765, %f7764;
	mov.f32 	%f7766, %f7764;
	bra.uni 	$L__BB4_389;

$L__BB4_384:
	add.ftz.f32 	%f6142, %f830, 0fBF800000;
	add.ftz.f32 	%f6143, %f830, 0f3F800000;
	div.approx.ftz.f32 	%f6144, %f6142, %f6143;
	mul.ftz.f32 	%f6145, %f6144, %f6144;
	mov.f32 	%f6146, 0f3D23D70A;
	max.ftz.f32 	%f7758, %f6145, %f6146;
	mov.f32 	%f7759, %f7758;
	mov.f32 	%f7760, %f7758;

$L__BB4_386:
	mov.f32 	%f7761, 0f00000000;
	max.ftz.f32 	%f2477, %f2467, %f7761;
	max.ftz.f32 	%f6158, %f2466, %f7761;
	mov.f32 	%f6159, 0f3F800000;
	sub.ftz.f32 	%f6160, %f6159, %f6158;
	max.ftz.f32 	%f6161, %f6160, %f7761;
	min.ftz.f32 	%f6162, %f6161, %f6159;
	mul.ftz.f32 	%f6163, %f6162, %f6162;
	mul.ftz.f32 	%f6164, %f6163, %f6163;
	mul.ftz.f32 	%f6165, %f6162, %f6164;
	ld.global.f32 	%f6166, [_Z18mx_fresnel_schlickfRK5RGB_TIfE$137];
	sub.ftz.f32 	%f6167, %f6166, %f7758;
	ld.global.f32 	%f6168, [_Z18mx_fresnel_schlickfRK5RGB_TIfE$137+4];
	sub.ftz.f32 	%f6169, %f6168, %f7759;
	ld.global.f32 	%f6170, [_Z18mx_fresnel_schlickfRK5RGB_TIfE$137+8];
	sub.ftz.f32 	%f6171, %f6170, %f7760;
	fma.rn.ftz.f32 	%f2478, %f6167, %f6165, %f7758;
	fma.rn.ftz.f32 	%f2479, %f6169, %f6165, %f7759;
	fma.rn.ftz.f32 	%f2480, %f6165, %f6171, %f7760;
	mul.ftz.f32 	%f6172, %f7148, %f7149;
	sqrt.approx.ftz.f32 	%f2481, %f6172;
	mul.ftz.f32 	%f6173, %f2463, %f2463;
	mul.ftz.f32 	%f6174, %f7148, %f7148;
	div.approx.ftz.f32 	%f6175, %f6173, %f6174;
	mul.ftz.f32 	%f6176, %f2464, %f2464;
	mul.ftz.f32 	%f6177, %f7149, %f7149;
	div.approx.ftz.f32 	%f6178, %f6176, %f6177;
	add.ftz.f32 	%f6179, %f6175, %f6178;
	fma.rn.ftz.f32 	%f6180, %f2465, %f2465, %f6179;
	mov.f32 	%f6181, 0f33D6BF95;
	max.ftz.f32 	%f6182, %f6180, %f6181;
	mul.ftz.f32 	%f6183, %f7148, 0f40490FDB;
	mul.ftz.f32 	%f6184, %f6183, %f7149;
	mul.ftz.f32 	%f6185, %f6184, %f6182;
	mul.ftz.f32 	%f6186, %f6182, %f6185;
	rcp.approx.ftz.f32 	%f2482, %f6186;
	mul.ftz.f32 	%f6187, %f2481, %f2481;
	sub.ftz.f32 	%f6188, %f6159, %f6187;
	mul.ftz.f32 	%f6189, %f2468, %f2468;
	fma.rn.ftz.f32 	%f6190, %f6189, %f6188, %f6187;
	sqrt.approx.ftz.f32 	%f6191, %f6190;
	mul.ftz.f32 	%f6192, %f2469, %f2469;
	fma.rn.ftz.f32 	%f6193, %f6192, %f6188, %f6187;
	sqrt.approx.ftz.f32 	%f6194, %f6193;
	div.approx.ftz.f32 	%f6195, %f6191, %f2468;
	div.approx.ftz.f32 	%f6196, %f6194, %f2469;
	add.ftz.f32 	%f2483, %f6195, %f6196;
	setp.geu.ftz.f32 	%p310, %f844, 0f3F800000;
	mov.f32 	%f7762, %f7761;
	mov.f32 	%f7763, %f7761;
	@%p310 bra 	$L__BB4_388;

	sub.ftz.f32 	%f6198, %f6159, %f844;
	mul.ftz.f32 	%f6199, %f831, %f6198;
	mul.ftz.f32 	%f6200, %f832, %f6198;
	mul.ftz.f32 	%f6201, %f833, %f6198;
	ld.global.f32 	%f6202, [_ZNK16DisneyPrincipled8evaluateERK10Vector3D_TIfLb0EES3_$910];
	sub.ftz.f32 	%f6203, %f6202, %f2478;
	ld.global.f32 	%f6204, [_ZNK16DisneyPrincipled8evaluateERK10Vector3D_TIfLb0EES3_$910+4];
	sub.ftz.f32 	%f6205, %f6204, %f2479;
	ld.global.f32 	%f6206, [_ZNK16DisneyPrincipled8evaluateERK10Vector3D_TIfLb0EES3_$910+8];
	sub.ftz.f32 	%f6207, %f6206, %f2480;
	sub.ftz.f32 	%f6208, %f6159, %f2468;
	mul.ftz.f32 	%f6209, %f6208, %f6208;
	mul.ftz.f32 	%f6210, %f6209, %f6209;
	mul.ftz.f32 	%f6211, %f6208, %f6210;
	sub.ftz.f32 	%f6212, %f6159, %f2469;
	mul.ftz.f32 	%f6213, %f6212, %f6212;
	mul.ftz.f32 	%f6214, %f6213, %f6213;
	mul.ftz.f32 	%f6215, %f6212, %f6214;
	add.ftz.f32 	%f6216, %f2477, %f2477;
	mul.ftz.f32 	%f6217, %f2477, %f6216;
	fma.rn.ftz.f32 	%f6218, %f6217, %f2481, 0f3F000000;
	sub.ftz.f32 	%f6219, %f6159, %f6211;
	fma.rn.ftz.f32 	%f6220, %f6211, %f6218, %f6219;
	sub.ftz.f32 	%f6221, %f6159, %f6215;
	fma.rn.ftz.f32 	%f6222, %f6215, %f6218, %f6221;
	mul.ftz.f32 	%f6223, %f6220, %f6222;
	mul.ftz.f32 	%f6224, %f6199, %f6223;
	mul.ftz.f32 	%f6225, %f6200, %f6223;
	mul.ftz.f32 	%f6226, %f6201, %f6223;
	mul.ftz.f32 	%f6227, %f6224, %f6203;
	mul.ftz.f32 	%f6228, %f6225, %f6205;
	mul.ftz.f32 	%f6229, %f6226, %f6207;
	mul.ftz.f32 	%f7761, %f6227, 0f3EA2F983;
	mul.ftz.f32 	%f7762, %f6228, 0f3EA2F983;
	mul.ftz.f32 	%f7763, %f6229, 0f3EA2F983;

$L__BB4_388:
	mov.f32 	%f6230, 0f40000000;
	div.approx.ftz.f32 	%f6231, %f6230, %f2483;
	mul.ftz.f32 	%f6232, %f2469, 0f40800000;
	mul.ftz.f32 	%f6233, %f2468, %f6232;
	rcp.approx.ftz.f32 	%f6234, %f6233;
	mul.ftz.f32 	%f6235, %f2478, %f2482;
	mul.ftz.f32 	%f6236, %f6235, %f6231;
	fma.rn.ftz.f32 	%f6237, %f6234, %f6236, %f7761;
	mul.ftz.f32 	%f6238, %f2479, %f2482;
	mul.ftz.f32 	%f6239, %f6238, %f6231;
	fma.rn.ftz.f32 	%f6240, %f6234, %f6239, %f7762;
	mul.ftz.f32 	%f6241, %f2480, %f2482;
	mul.ftz.f32 	%f6242, %f6241, %f6231;
	fma.rn.ftz.f32 	%f6243, %f6234, %f6242, %f7763;
	mul.ftz.f32 	%f7766, %f2468, %f6243;
	mul.ftz.f32 	%f7765, %f2468, %f6240;
	mul.ftz.f32 	%f7764, %f2468, %f6237;
	bra.uni 	$L__BB4_389;

$L__BB4_372:
	rcp.approx.ftz.f32 	%f2436, %f830;
	fma.rn.ftz.f32 	%f5955, %f2436, %f2427, %f827;
	fma.rn.ftz.f32 	%f5956, %f2436, %f2428, %f828;
	fma.rn.ftz.f32 	%f5957, %f2436, %f2429, %f829;
	mul.ftz.f32 	%f5958, %f5956, %f5956;
	fma.rn.ftz.f32 	%f5959, %f5955, %f5955, %f5958;
	fma.rn.ftz.f32 	%f5960, %f5957, %f5957, %f5959;
	rsqrt.approx.ftz.f32 	%f5961, %f5960;
	mul.ftz.f32 	%f2437, %f5955, %f5961;
	mul.ftz.f32 	%f2438, %f5956, %f5961;
	mul.ftz.f32 	%f2439, %f5957, %f5961;
	abs.ftz.f32 	%f5962, %f2437;
	setp.geu.ftz.f32 	%p302, %f5962, 0f7F800000;
	mov.f32 	%f7765, %f7764;
	mov.f32 	%f7766, %f7764;
	@%p302 bra 	$L__BB4_389;

	mul.ftz.f32 	%f5964, %f828, %f2438;
	fma.rn.ftz.f32 	%f5965, %f827, %f2437, %f5964;
	fma.rn.ftz.f32 	%f5966, %f829, %f2439, %f5965;
	abs.ftz.f32 	%f2440, %f5966;
	mul.ftz.f32 	%f5967, %f2440, %f2440;
	fma.rn.ftz.f32 	%f5968, %f830, %f830, %f5967;
	add.ftz.f32 	%f2441, %f5968, 0fBF800000;
	setp.lt.ftz.f32 	%p303, %f2441, 0f00000000;
	mov.f32 	%f5963, 0f3F800000;
	mov.f32 	%f7755, %f5963;
	@%p303 bra 	$L__BB4_375;

	sqrt.approx.ftz.f32 	%f5969, %f2441;
	sub.ftz.f32 	%f5970, %f5969, %f2440;
	add.ftz.f32 	%f5971, %f2440, %f5969;
	div.approx.ftz.f32 	%f5972, %f5970, %f5971;
	mul.ftz.f32 	%f5973, %f5972, %f5972;
	mul.ftz.f32 	%f5974, %f5973, 0f3F000000;
	fma.rn.ftz.f32 	%f5975, %f2440, %f5971, 0fBF800000;
	fma.rn.ftz.f32 	%f5976, %f2440, %f5970, 0f3F800000;
	div.approx.ftz.f32 	%f5977, %f5975, %f5976;
	fma.rn.ftz.f32 	%f5978, %f5977, %f5977, 0f3F800000;
	mul.ftz.f32 	%f7755, %f5974, %f5978;

$L__BB4_375:
	mul.ftz.f32 	%f5979, %f7148, %f7149;
	sqrt.approx.ftz.f32 	%f5980, %f5979;
	mul.ftz.f32 	%f5981, %f2437, %f2437;
	mul.ftz.f32 	%f5982, %f7148, %f7148;
	div.approx.ftz.f32 	%f5983, %f5981, %f5982;
	mul.ftz.f32 	%f5984, %f2438, %f2438;
	mul.ftz.f32 	%f5985, %f7149, %f7149;
	div.approx.ftz.f32 	%f5986, %f5984, %f5985;
	add.ftz.f32 	%f5987, %f5983, %f5986;
	fma.rn.ftz.f32 	%f5988, %f2439, %f2439, %f5987;
	mov.f32 	%f5989, 0f33D6BF95;
	max.ftz.f32 	%f5990, %f5988, %f5989;
	mul.ftz.f32 	%f5991, %f7148, 0f40490FDB;
	mul.ftz.f32 	%f5992, %f5991, %f7149;
	mul.ftz.f32 	%f5993, %f5992, %f5990;
	mul.ftz.f32 	%f5994, %f5990, %f5993;
	rcp.approx.ftz.f32 	%f5995, %f5994;
	mul.ftz.f32 	%f5997, %f5980, %f5980;
	sub.ftz.f32 	%f5998, %f5963, %f5997;
	mul.ftz.f32 	%f5999, %f2435, %f2435;
	fma.rn.ftz.f32 	%f6000, %f5999, %f5998, %f5997;
	sqrt.approx.ftz.f32 	%f6001, %f6000;
	mul.ftz.f32 	%f6002, %f2434, %f2434;
	fma.rn.ftz.f32 	%f6003, %f6002, %f5998, %f5997;
	sqrt.approx.ftz.f32 	%f6004, %f6003;
	div.approx.ftz.f32 	%f6005, %f6001, %f2435;
	div.approx.ftz.f32 	%f6006, %f6004, %f2434;
	add.ftz.f32 	%f6007, %f6005, %f6006;
	mov.f32 	%f6008, 0f40000000;
	div.approx.ftz.f32 	%f6009, %f6008, %f6007;
	ld.global.f32 	%f6010, [_ZNK16DisneyPrincipled8evaluateERK10Vector3D_TIfLb0EES3_$908];
	sub.ftz.f32 	%f6011, %f6010, %f7755;
	ld.global.f32 	%f6012, [_ZNK16DisneyPrincipled8evaluateERK10Vector3D_TIfLb0EES3_$908+4];
	sub.ftz.f32 	%f6013, %f6012, %f7755;
	ld.global.f32 	%f6014, [_ZNK16DisneyPrincipled8evaluateERK10Vector3D_TIfLb0EES3_$908+8];
	sub.ftz.f32 	%f6015, %f6014, %f7755;
	mul.ftz.f32 	%f6016, %f831, %f847;
	mul.ftz.f32 	%f6017, %f6016, 0fBFB8AA3B;
	ex2.approx.ftz.f32 	%f6018, %f6017;
	mul.ftz.f32 	%f6019, %f6018, %f6011;
	mul.ftz.f32 	%f6020, %f832, %f847;
	mul.ftz.f32 	%f6021, %f6020, 0fBFB8AA3B;
	ex2.approx.ftz.f32 	%f6022, %f6021;
	mul.ftz.f32 	%f6023, %f6022, %f6013;
	mul.ftz.f32 	%f6024, %f833, %f847;
	mul.ftz.f32 	%f6025, %f6024, 0fBFB8AA3B;
	ex2.approx.ftz.f32 	%f6026, %f6025;
	mul.ftz.f32 	%f6027, %f6026, %f6015;
	mul.ftz.f32 	%f6028, %f845, %f6019;
	mul.ftz.f32 	%f6029, %f845, %f6023;
	mul.ftz.f32 	%f6030, %f845, %f6027;
	mul.ftz.f32 	%f6031, %f846, %f6028;
	mul.ftz.f32 	%f6032, %f846, %f6029;
	mul.ftz.f32 	%f6033, %f846, %f6030;
	mul.ftz.f32 	%f6034, %f5995, %f6031;
	mul.ftz.f32 	%f6035, %f5995, %f6032;
	mul.ftz.f32 	%f6036, %f5995, %f6033;
	mul.ftz.f32 	%f6037, %f6009, %f6034;
	mul.ftz.f32 	%f6038, %f6009, %f6035;
	mul.ftz.f32 	%f6039, %f6009, %f6036;
	mul.ftz.f32 	%f6040, %f2434, 0f40800000;
	mul.ftz.f32 	%f6041, %f6040, %f2435;
	mul.ftz.f32 	%f6042, %f2436, %f6041;
	mul.ftz.f32 	%f6043, %f2436, %f6042;
	rcp.approx.ftz.f32 	%f6044, %f6043;
	mul.ftz.f32 	%f7766, %f6044, %f6039;
	mul.ftz.f32 	%f7765, %f6044, %f6038;
	mul.ftz.f32 	%f7764, %f6044, %f6037;

$L__BB4_389:
	abs.ftz.f32 	%f6244, %f2429;
	mul.ftz.f32 	%f6245, %f2433, %f6244;
	div.approx.ftz.f32 	%f6246, %f6245, %f2422;
	mul.ftz.f32 	%f6247, %f7745, 0f3EA2F983;
	mul.ftz.f32 	%f6248, %f6247, %f7764;
	mul.ftz.f32 	%f6249, %f7746, 0f3EA2F983;
	mul.ftz.f32 	%f6250, %f6249, %f7765;
	mul.ftz.f32 	%f6251, %f7747, 0f3EA2F983;
	mul.ftz.f32 	%f6252, %f6251, %f7766;
	mul.ftz.f32 	%f7769, %f6252, %f6246;
	mul.ftz.f32 	%f7768, %f6250, %f6246;
	mul.ftz.f32 	%f7764, %f6248, %f6246;

$L__BB4_390:
	div.approx.ftz.f32 	%f6253, %f2432, %f2421;
	mul.ftz.f32 	%f7771, %f7768, %f6253;
	mul.ftz.f32 	%f7770, %f7764, %f6253;
	mul.ftz.f32 	%f7772, %f7769, %f6253;

$L__BB4_391:
	ld.f32 	%f6254, [%rd6];
	ld.f32 	%f6255, [%rd6+4];
	ld.f32 	%f6256, [%rd6+8];
	ld.f32 	%f6257, [%rd6+12];
	fma.rn.ftz.f32 	%f6258, %f6254, %f7770, %f6257;
	st.f32 	[%rd6+12], %f6258;
	ld.f32 	%f6259, [%rd6+16];
	fma.rn.ftz.f32 	%f6260, %f7771, %f6255, %f6259;
	st.f32 	[%rd6+16], %f6260;
	ld.f32 	%f6261, [%rd6+20];
	fma.rn.ftz.f32 	%f6262, %f7772, %f6256, %f6261;
	st.f32 	[%rd6+20], %f6262;

$L__BB4_392:
	mov.b64 	%rd1943, {%r2534, %r2533};
	mul.lo.s64 	%rd1944, %rd1943, 6364136223846793005;
	add.s64 	%rd141, %rd1944, 1;
	shr.u64 	%rd1945, %rd1943, 18;
	xor.b64  	%rd1946, %rd1945, %rd1943;
	shr.u64 	%rd1947, %rd1946, 27;
	cvt.u32.u64 	%r2477, %rd1947;
	shr.u64 	%rd1948, %rd1943, 59;
	cvt.u32.u64 	%r2478, %rd1948;
	shf.r.wrap.b32 	%r2479, %r2477, %r2477, %r2478;
	shr.u32 	%r2480, %r2479, 9;
	or.b32  	%r2481, %r2480, 1065353216;
	mov.b32 	%f6263, %r2481;
	add.ftz.f32 	%f2508, %f6263, 0fBF800000;
	shr.u64 	%rd1949, %rd141, 18;
	xor.b64  	%rd1950, %rd1949, %rd141;
	shr.u64 	%rd1951, %rd1950, 27;
	cvt.u32.u64 	%r2482, %rd1951;
	shr.u64 	%rd1952, %rd141, 59;
	cvt.u32.u64 	%r2483, %rd1952;
	shf.r.wrap.b32 	%r2484, %r2482, %r2482, %r2483;
	shr.u32 	%r2485, %r2484, 9;
	or.b32  	%r2486, %r2485, 1065353216;
	mov.b32 	%f6264, %r2486;
	add.ftz.f32 	%f2509, %f6264, 0fBF800000;
	setp.gt.ftz.f32 	%p311, %f844, 0f00000000;
	@%p311 bra 	$L__BB4_429;
	bra.uni 	$L__BB4_393;

$L__BB4_429:
	mul.ftz.f32 	%f6582, %f827, %f7148;
	mul.ftz.f32 	%f6583, %f828, %f7149;
	mul.ftz.f32 	%f6584, %f6583, %f6583;
	fma.rn.ftz.f32 	%f6585, %f6582, %f6582, %f6584;
	fma.rn.ftz.f32 	%f6586, %f829, %f829, %f6585;
	rsqrt.approx.ftz.f32 	%f2638, %f6586;
	mul.ftz.f32 	%f2639, %f6582, %f2638;
	mul.ftz.f32 	%f2640, %f6583, %f2638;
	mul.ftz.f32 	%f6587, %f2640, %f2640;
	fma.rn.ftz.f32 	%f2641, %f2639, %f2639, %f6587;
	setp.gt.ftz.f32 	%p338, %f2641, 0f00000000;
	@%p338 bra 	$L__BB4_431;
	bra.uni 	$L__BB4_430;

$L__BB4_431:
	rsqrt.approx.ftz.f32 	%f6588, %f2641;
	mul.ftz.f32 	%f6589, %f2640, %f6588;
	neg.ftz.f32 	%f7794, %f6589;
	mul.ftz.f32 	%f7795, %f2639, %f6588;
	mul.ftz.f32 	%f7796, %f6588, 0f00000000;
	bra.uni 	$L__BB4_432;

$L__BB4_393:
	setp.gt.ftz.f32 	%p312, %f845, 0f00000000;
	@%p312 bra 	$L__BB4_414;
	bra.uni 	$L__BB4_394;

$L__BB4_414:
	setp.ge.ftz.f32 	%p328, %f829, 0f00000000;
	mov.f32 	%f6481, 0f00000000;
	selp.f32 	%f2583, 0f3F800000, %f830, %p328;
	mov.f32 	%f2596, 0f3F800000;
	selp.f32 	%f2584, %f830, 0f3F800000, %p328;
	neg.ftz.f32 	%f7800, %f827;
	selp.f32 	%f2586, %f827, %f7800, %p328;
	neg.ftz.f32 	%f7799, %f828;
	selp.f32 	%f2588, %f828, %f7799, %p328;
	neg.ftz.f32 	%f7798, %f829;
	selp.f32 	%f2590, %f829, %f7798, %p328;
	abs.ftz.f32 	%f2591, %f2590;
	div.approx.ftz.f32 	%f2592, %f2583, %f2584;
	mul.ftz.f32 	%f6482, %f2591, %f2591;
	sub.ftz.f32 	%f2593, %f2596, %f6482;
	max.ftz.f32 	%f6483, %f6481, %f2593;
	sqrt.approx.ftz.f32 	%f6484, %f6483;
	mul.ftz.f32 	%f2594, %f2592, %f6484;
	setp.ge.ftz.f32 	%p329, %f2594, 0f3F800000;
	@%p329 bra 	$L__BB4_416;

	mul.ftz.f32 	%f6485, %f2594, %f2594;
	mov.f32 	%f6486, 0f3F800000;
	sub.ftz.f32 	%f6487, %f6486, %f6485;
	max.ftz.f32 	%f6489, %f6481, %f6487;
	sqrt.approx.ftz.f32 	%f6490, %f6489;
	mul.ftz.f32 	%f6491, %f2583, %f6490;
	mul.ftz.f32 	%f6492, %f2584, %f2591;
	sub.ftz.f32 	%f6493, %f6492, %f6491;
	add.ftz.f32 	%f6494, %f6492, %f6491;
	div.approx.ftz.f32 	%f6495, %f6493, %f6494;
	mul.ftz.f32 	%f6496, %f2584, %f6490;
	mul.ftz.f32 	%f6497, %f2583, %f2591;
	sub.ftz.f32 	%f6498, %f6497, %f6496;
	add.ftz.f32 	%f6499, %f6497, %f6496;
	div.approx.ftz.f32 	%f6500, %f6498, %f6499;
	mul.ftz.f32 	%f6501, %f6500, %f6500;
	fma.rn.ftz.f32 	%f6502, %f6495, %f6495, %f6501;
	mov.f32 	%f6503, 0f40000000;
	div.approx.ftz.f32 	%f2596, %f6502, %f6503;

$L__BB4_416:
	setp.eq.s32 	%p330, %r27, 0;
	@%p330 bra 	$L__BB4_424;
	bra.uni 	$L__BB4_417;

$L__BB4_424:
	mul.ftz.f32 	%f6544, %f2592, %f2592;
	mul.ftz.f32 	%f6545, %f2593, %f6544;
	mov.f32 	%f6543, 0f3F800000;
	sub.ftz.f32 	%f6546, %f6543, %f6545;
	mov.f32 	%f6547, 0f00000000;
	max.ftz.f32 	%f6548, %f6547, %f6546;
	sqrt.approx.ftz.f32 	%f2623, %f6548;
	mul.ftz.f32 	%f6549, %f2623, %f2623;
	sub.ftz.f32 	%f6550, %f6543, %f6549;
	max.ftz.f32 	%f6551, %f6547, %f6550;
	sqrt.approx.ftz.f32 	%f6552, %f6551;
	div.approx.ftz.f32 	%f6553, %f2584, %f2583;
	mul.ftz.f32 	%f2624, %f6553, %f6552;
	setp.ge.ftz.f32 	%p335, %f2624, 0f3F800000;
	mov.f32 	%f7793, %f6543;
	@%p335 bra 	$L__BB4_426;

	mul.ftz.f32 	%f6554, %f2624, %f2624;
	mov.f32 	%f6555, 0f3F800000;
	sub.ftz.f32 	%f6556, %f6555, %f6554;
	max.ftz.f32 	%f6558, %f6547, %f6556;
	sqrt.approx.ftz.f32 	%f6559, %f6558;
	mul.ftz.f32 	%f6560, %f2584, %f6559;
	mul.ftz.f32 	%f6561, %f2583, %f2623;
	sub.ftz.f32 	%f6562, %f6561, %f6560;
	add.ftz.f32 	%f6563, %f6561, %f6560;
	div.approx.ftz.f32 	%f6564, %f6562, %f6563;
	mul.ftz.f32 	%f6565, %f2583, %f6559;
	mul.ftz.f32 	%f6566, %f2584, %f2623;
	sub.ftz.f32 	%f6567, %f6566, %f6565;
	add.ftz.f32 	%f6568, %f6566, %f6565;
	div.approx.ftz.f32 	%f6569, %f6567, %f6568;
	mul.ftz.f32 	%f6570, %f6569, %f6569;
	fma.rn.ftz.f32 	%f6571, %f6564, %f6564, %f6570;
	mov.f32 	%f6572, 0f40000000;
	div.approx.ftz.f32 	%f7793, %f6571, %f6572;

$L__BB4_426:
	sub.ftz.f32 	%f6574, %f6543, %f7793;
	sub.ftz.f32 	%f6575, %f6543, %f2596;
	mul.ftz.f32 	%f2627, %f6575, %f6574;
	fma.rn.ftz.f32 	%f7801, %f7793, %f2627, %f2596;
	setp.gt.ftz.f32 	%p336, %f7801, %f2508;
	@%p336 bra 	$L__BB4_428;
	bra.uni 	$L__BB4_427;

$L__BB4_428:
	neg.ftz.f32 	%f7800, %f2586;
	neg.ftz.f32 	%f7799, %f2588;
	abs.ftz.f32 	%f6581, %f2591;
	div.approx.ftz.f32 	%f7802, %f7801, %f6581;
	mov.f32 	%f7798, %f2590;
	mov.f32 	%f7803, %f7802;
	mov.f32 	%f7804, %f7802;
	bra.uni 	$L__BB4_436;

$L__BB4_430:
	ld.global.f32 	%f7794, [_Z29mx_ggx_importance_sample_VNDFRK10Vector2D_TIfERK10Vector3D_TIfLb0EES2_$155];
	ld.global.f32 	%f7795, [_Z29mx_ggx_importance_sample_VNDFRK10Vector2D_TIfERK10Vector3D_TIfLb0EES2_$155+4];
	ld.global.f32 	%f7796, [_Z29mx_ggx_importance_sample_VNDFRK10Vector2D_TIfERK10Vector3D_TIfLb0EES2_$155+8];

$L__BB4_432:
	mul.ftz.f32 	%f6594, %f829, %f2638;
	mul.ftz.f32 	%f6595, %f6594, %f7795;
	mul.ftz.f32 	%f6596, %f2640, %f7796;
	sub.ftz.f32 	%f6597, %f6596, %f6595;
	mul.ftz.f32 	%f6598, %f2639, %f7796;
	mul.ftz.f32 	%f6599, %f6594, %f7794;
	sub.ftz.f32 	%f6600, %f6599, %f6598;
	mul.ftz.f32 	%f6601, %f2640, %f7794;
	mul.ftz.f32 	%f6602, %f2639, %f7795;
	sub.ftz.f32 	%f6603, %f6602, %f6601;
	mul.ftz.f32 	%f6604, %f2509, 0f40C90FDB;
	cos.approx.ftz.f32 	%f6605, %f6604;
	sqrt.approx.ftz.f32 	%f6606, %f2508;
	mul.ftz.f32 	%f6607, %f6606, %f6605;
	sin.approx.ftz.f32 	%f6608, %f6604;
	mul.ftz.f32 	%f6609, %f6606, %f6608;
	add.ftz.f32 	%f6610, %f6594, 0f3F800000;
	mov.f32 	%f6611, 0f3F800000;
	mul.ftz.f32 	%f6612, %f6610, 0f3F000000;
	sub.ftz.f32 	%f6613, %f6611, %f6612;
	mul.ftz.f32 	%f6614, %f6607, %f6607;
	sub.ftz.f32 	%f6615, %f6611, %f6614;
	sqrt.approx.ftz.f32 	%f6616, %f6615;
	mul.ftz.f32 	%f6617, %f6612, %f6609;
	fma.rn.ftz.f32 	%f6618, %f6613, %f6616, %f6617;
	mul.ftz.f32 	%f6619, %f6597, %f6618;
	mul.ftz.f32 	%f6620, %f6600, %f6618;
	mul.ftz.f32 	%f6621, %f6603, %f6618;
	fma.rn.ftz.f32 	%f6622, %f7794, %f6607, %f6619;
	fma.rn.ftz.f32 	%f6623, %f7795, %f6607, %f6620;
	fma.rn.ftz.f32 	%f6624, %f7796, %f6607, %f6621;
	mul.ftz.f32 	%f6625, %f6618, %f6618;
	sub.ftz.f32 	%f6626, %f6615, %f6625;
	mov.f32 	%f7801, 0f00000000;
	max.ftz.f32 	%f6627, %f7801, %f6626;
	sqrt.approx.ftz.f32 	%f6628, %f6627;
	fma.rn.ftz.f32 	%f6629, %f2639, %f6628, %f6622;
	fma.rn.ftz.f32 	%f6630, %f2640, %f6628, %f6623;
	fma.rn.ftz.f32 	%f6631, %f6594, %f6628, %f6624;
	mul.ftz.f32 	%f6632, %f7148, %f6629;
	mul.ftz.f32 	%f6633, %f7149, %f6630;
	max.ftz.f32 	%f6634, %f7801, %f6631;
	mul.ftz.f32 	%f6635, %f6633, %f6633;
	fma.rn.ftz.f32 	%f6636, %f6632, %f6632, %f6635;
	fma.rn.ftz.f32 	%f6637, %f6634, %f6634, %f6636;
	rsqrt.approx.ftz.f32 	%f6638, %f6637;
	mul.ftz.f32 	%f2651, %f6638, %f6632;
	mul.ftz.f32 	%f2652, %f6638, %f6633;
	mul.ftz.f32 	%f2653, %f6634, %f6638;
	neg.ftz.f32 	%f6639, %f827;
	mul.ftz.f32 	%f6640, %f2651, %f6639;
	neg.ftz.f32 	%f6641, %f828;
	mul.ftz.f32 	%f6642, %f2652, %f828;
	sub.ftz.f32 	%f6643, %f6640, %f6642;
	neg.ftz.f32 	%f6644, %f829;
	mul.ftz.f32 	%f6645, %f2653, %f829;
	sub.ftz.f32 	%f6646, %f6643, %f6645;
	add.ftz.f32 	%f6647, %f6646, %f6646;
	mul.ftz.f32 	%f6648, %f2651, %f6647;
	mul.ftz.f32 	%f6649, %f2652, %f6647;
	mul.ftz.f32 	%f6650, %f2653, %f6647;
	sub.ftz.f32 	%f7800, %f6639, %f6648;
	sub.ftz.f32 	%f7799, %f6641, %f6649;
	sub.ftz.f32 	%f7798, %f6644, %f6650;
	setp.le.ftz.f32 	%p339, %f7798, 0f00000000;
	mov.f32 	%f7802, %f7801;
	mov.f32 	%f7803, %f7801;
	mov.f32 	%f7804, %f7801;
	@%p339 bra 	$L__BB4_436;

	mov.f32 	%f7797, 0f00000000;
	max.ftz.f32 	%f2657, %f829, %f7797;
	mul.ftz.f32 	%f6652, %f828, %f2652;
	fma.rn.ftz.f32 	%f6653, %f827, %f2651, %f6652;
	fma.rn.ftz.f32 	%f6654, %f829, %f2653, %f6653;
	max.ftz.f32 	%f6655, %f6654, %f7797;
	sub.ftz.f32 	%f6657, %f6611, %f6655;
	max.ftz.f32 	%f6658, %f6657, %f7797;
	min.ftz.f32 	%f6659, %f6658, %f6611;
	mul.ftz.f32 	%f6660, %f6659, %f6659;
	mul.ftz.f32 	%f6661, %f6660, %f6660;
	mul.ftz.f32 	%f6662, %f6659, %f6661;
	ld.global.f32 	%f6663, [_Z18mx_fresnel_schlickfRK5RGB_TIfE$137];
	sub.ftz.f32 	%f6664, %f6663, %f831;
	ld.global.f32 	%f6665, [_Z18mx_fresnel_schlickfRK5RGB_TIfE$137+4];
	sub.ftz.f32 	%f6666, %f6665, %f832;
	ld.global.f32 	%f6667, [_Z18mx_fresnel_schlickfRK5RGB_TIfE$137+8];
	sub.ftz.f32 	%f6668, %f6667, %f833;
	fma.rn.ftz.f32 	%f6669, %f6664, %f6662, %f831;
	fma.rn.ftz.f32 	%f6670, %f6666, %f6662, %f832;
	fma.rn.ftz.f32 	%f6671, %f6662, %f6668, %f833;
	lg2.approx.ftz.f32 	%f6672, %f6657;
	mul.ftz.f32 	%f6673, %f6672, 0f40A00000;
	ex2.approx.ftz.f32 	%f6674, %f6673;
	fma.rn.ftz.f32 	%f6675, %f6674, 0f3F000000, 0f3F800000;
	mul.ftz.f32 	%f2658, %f6669, %f6675;
	mul.ftz.f32 	%f2659, %f6670, %f6675;
	mul.ftz.f32 	%f2660, %f6671, %f6675;
	mul.ftz.f32 	%f6676, %f7148, %f7149;
	sqrt.approx.ftz.f32 	%f2661, %f6676;
	mul.ftz.f32 	%f6677, %f2651, %f2651;
	mul.ftz.f32 	%f6678, %f7148, %f7148;
	div.approx.ftz.f32 	%f6679, %f6677, %f6678;
	mul.ftz.f32 	%f6680, %f2652, %f2652;
	mul.ftz.f32 	%f6681, %f7149, %f7149;
	div.approx.ftz.f32 	%f6682, %f6680, %f6681;
	add.ftz.f32 	%f6683, %f6679, %f6682;
	fma.rn.ftz.f32 	%f6684, %f2653, %f2653, %f6683;
	mov.f32 	%f6685, 0f33D6BF95;
	max.ftz.f32 	%f6686, %f6684, %f6685;
	mul.ftz.f32 	%f6687, %f7148, 0f40490FDB;
	mul.ftz.f32 	%f6688, %f6687, %f7149;
	mul.ftz.f32 	%f6689, %f6688, %f6686;
	mul.ftz.f32 	%f6690, %f6686, %f6689;
	rcp.approx.ftz.f32 	%f2662, %f6690;
	mul.ftz.f32 	%f2663, %f2661, %f2661;
	sub.ftz.f32 	%f6691, %f6611, %f2663;
	max.ftz.f32 	%f2664, %f7798, %f7797;
	mul.ftz.f32 	%f6692, %f2664, %f2664;
	fma.rn.ftz.f32 	%f6693, %f6692, %f6691, %f2663;
	sqrt.approx.ftz.f32 	%f6694, %f6693;
	mul.ftz.f32 	%f2665, %f2657, %f2657;
	fma.rn.ftz.f32 	%f6695, %f2665, %f6691, %f2663;
	sqrt.approx.ftz.f32 	%f6696, %f6695;
	div.approx.ftz.f32 	%f6697, %f6694, %f2664;
	div.approx.ftz.f32 	%f6698, %f6696, %f2657;
	add.ftz.f32 	%f2666, %f6697, %f6698;
	setp.leu.ftz.f32 	%p340, %f2661, 0f00000000;
	@%p340 bra 	$L__BB4_435;

	mul.ftz.f32 	%f6699, %f2657, 0fC123AE14;
	mul.ftz.f32 	%f6700, %f6699, %f2661;
	ex2.approx.ftz.f32 	%f6701, %f6700;
	mul.ftz.f32 	%f6702, %f2661, 0fC123AE14;
	ex2.approx.ftz.f32 	%f6703, %f6702;
	sub.ftz.f32 	%f6704, %f6701, %f6703;
	mov.f32 	%f6705, 0f3F800000;
	min.ftz.f32 	%f6706, %f6704, %f6705;
	sub.ftz.f32 	%f7797, %f6705, %f6706;

$L__BB4_435:
	mov.f32 	%f6707, 0f40000000;
	div.approx.ftz.f32 	%f6708, %f6707, %f2666;
	rcp.approx.ftz.f32 	%f6709, %f7797;
	mov.f32 	%f6710, 0f3F800000;
	add.ftz.f32 	%f6711, %f6709, 0fBF800000;
	ld.global.f32 	%f6712, [_Z26mx_ggx_energy_compensationffRK5RGB_TIfE$179];
	fma.rn.ftz.f32 	%f6713, %f831, %f6711, %f6712;
	ld.global.f32 	%f6714, [_Z26mx_ggx_energy_compensationffRK5RGB_TIfE$179+4];
	fma.rn.ftz.f32 	%f6715, %f832, %f6711, %f6714;
	ld.global.f32 	%f6716, [_Z26mx_ggx_energy_compensationffRK5RGB_TIfE$179+8];
	fma.rn.ftz.f32 	%f6717, %f833, %f6711, %f6716;
	mul.ftz.f32 	%f6718, %f2658, %f2662;
	mul.ftz.f32 	%f6719, %f6718, %f6708;
	mul.ftz.f32 	%f6720, %f2659, %f2662;
	mul.ftz.f32 	%f6721, %f6720, %f6708;
	mul.ftz.f32 	%f6722, %f2660, %f2662;
	mul.ftz.f32 	%f6723, %f6722, %f6708;
	mul.ftz.f32 	%f6724, %f2657, 0f40800000;
	mul.ftz.f32 	%f6725, %f6724, %f2664;
	rcp.approx.ftz.f32 	%f6726, %f6725;
	mul.ftz.f32 	%f6727, %f6726, %f6719;
	mul.ftz.f32 	%f6728, %f6726, %f6721;
	mul.ftz.f32 	%f6729, %f6726, %f6723;
	mul.ftz.f32 	%f7804, %f6729, %f6717;
	mul.ftz.f32 	%f7803, %f6728, %f6715;
	mul.ftz.f32 	%f7802, %f6727, %f6713;
	sub.ftz.f32 	%f6730, %f6710, %f2665;
	div.approx.ftz.f32 	%f6731, %f6730, %f2665;
	fma.rn.ftz.f32 	%f6732, %f2663, %f6731, 0f3F800000;
	sqrt.approx.ftz.f32 	%f6733, %f6732;
	add.ftz.f32 	%f6734, %f6733, 0f3F800000;
	div.approx.ftz.f32 	%f6735, %f6707, %f6734;
	mul.ftz.f32 	%f6736, %f2662, %f6735;
	div.approx.ftz.f32 	%f7801, %f6736, %f6724;
	bra.uni 	$L__BB4_436;

$L__BB4_394:
	mov.f32 	%f6265, 0f3F800000;
	sub.ftz.f32 	%f2510, %f6265, %f844;
	fma.rn.ftz.f32 	%f2511, %f2510, 0f3F000000, %f844;
	setp.gt.ftz.f32 	%p313, %f2511, %f2508;
	@%p313 bra 	$L__BB4_405;
	bra.uni 	$L__BB4_395;

$L__BB4_405:
	div.approx.ftz.f32 	%f2527, %f2508, %f2511;
	mul.ftz.f32 	%f6289, %f827, %f7148;
	mul.ftz.f32 	%f6290, %f828, %f7149;
	mul.ftz.f32 	%f6291, %f6290, %f6290;
	fma.rn.ftz.f32 	%f6292, %f6289, %f6289, %f6291;
	fma.rn.ftz.f32 	%f6293, %f829, %f829, %f6292;
	rsqrt.approx.ftz.f32 	%f2528, %f6293;
	mul.ftz.f32 	%f2529, %f6289, %f2528;
	mul.ftz.f32 	%f2530, %f6290, %f2528;
	mul.ftz.f32 	%f6294, %f2530, %f2530;
	fma.rn.ftz.f32 	%f2531, %f2529, %f2529, %f6294;
	setp.gt.ftz.f32 	%p320, %f2531, 0f00000000;
	@%p320 bra 	$L__BB4_407;
	bra.uni 	$L__BB4_406;

$L__BB4_407:
	rsqrt.approx.ftz.f32 	%f6295, %f2531;
	mul.ftz.f32 	%f6296, %f2530, %f6295;
	neg.ftz.f32 	%f7777, %f6296;
	mul.ftz.f32 	%f7778, %f2529, %f6295;
	mul.ftz.f32 	%f7779, %f6295, 0f00000000;
	bra.uni 	$L__BB4_408;

$L__BB4_417:
	setp.gt.ftz.f32 	%p331, %f2596, %f2508;
	mov.f32 	%f7798, 0f00000000;
	mov.f32 	%f7799, 0f00000000;
	mov.f32 	%f7800, 0f00000000;
	@%p331 bra 	$L__BB4_422;
	bra.uni 	$L__BB4_418;

$L__BB4_422:
	setp.eq.ftz.f32 	%p334, %f2590, 0f00000000;
	mov.f32 	%f7801, 0f00000000;
	mov.f32 	%f7802, %f7801;
	mov.f32 	%f7803, %f7801;
	mov.f32 	%f7804, %f7801;
	@%p334 bra 	$L__BB4_436;

	neg.ftz.f32 	%f7800, %f2586;
	neg.ftz.f32 	%f7799, %f2588;
	rcp.approx.ftz.f32 	%f6542, %f2591;
	mul.ftz.f32 	%f7802, %f2596, %f6542;
	mov.f32 	%f7798, %f2590;
	mov.f32 	%f7801, %f2596;
	mov.f32 	%f7803, %f7802;
	mov.f32 	%f7804, %f7802;
	bra.uni 	$L__BB4_436;

$L__BB4_395:
	sub.ftz.f32 	%f6268, %f2508, %f2511;
	sub.ftz.f32 	%f6270, %f6265, %f2511;
	div.approx.ftz.f32 	%f6271, %f6268, %f6270;
	fma.rn.ftz.f32 	%f2512, %f6271, 0f40000000, 0fBF800000;
	fma.rn.ftz.f32 	%f7773, %f2509, 0f40000000, 0fBF800000;
	setp.eq.ftz.f32 	%p314, %f2512, 0f00000000;
	mov.f32 	%f7783, 0f00000000;
	setp.eq.ftz.f32 	%p315, %f7773, 0f00000000;
	and.pred  	%p316, %p315, %p314;
	mov.f32 	%f7800, %f7783;
	mov.f32 	%f7799, %f7783;
	@%p316 bra 	$L__BB4_404;

	neg.ftz.f32 	%f2514, %f7773;
	setp.ltu.ftz.f32 	%p317, %f2512, %f2514;
	@%p317 bra 	$L__BB4_400;
	bra.uni 	$L__BB4_397;

$L__BB4_400:
	setp.gtu.ftz.f32 	%p319, %f2512, %f7773;
	@%p319 bra 	$L__BB4_402;
	bra.uni 	$L__BB4_401;

$L__BB4_402:
	div.approx.ftz.f32 	%f6275, %f2512, %f7773;
	mov.f32 	%f6276, 0f40C00000;
	sub.ftz.f32 	%f7774, %f6276, %f6275;
	mov.f32 	%f7773, %f2514;
	bra.uni 	$L__BB4_403;

$L__BB4_427:
	mov.f32 	%f6576, 0f3F800000;
	sub.ftz.f32 	%f7801, %f6576, %f7801;
	div.approx.ftz.f32 	%f6577, %f2627, %f7801;
	mul.ftz.f32 	%f6578, %f845, %f6577;
	mul.ftz.f32 	%f6579, %f2591, 0f40A00000;
	mul.ftz.f32 	%f6580, %f6579, %f6578;
	setp.lt.ftz.f32 	%p337, %f2591, 0f3E4CCCCD;
	selp.f32 	%f7802, %f6580, %f6578, %p337;
	mov.f32 	%f7803, %f7802;
	mov.f32 	%f7804, %f7802;
	bra.uni 	$L__BB4_436;

$L__BB4_406:
	ld.global.f32 	%f7777, [_Z29mx_ggx_importance_sample_VNDFRK10Vector2D_TIfERK10Vector3D_TIfLb0EES2_$155];
	ld.global.f32 	%f7778, [_Z29mx_ggx_importance_sample_VNDFRK10Vector2D_TIfERK10Vector3D_TIfLb0EES2_$155+4];
	ld.global.f32 	%f7779, [_Z29mx_ggx_importance_sample_VNDFRK10Vector2D_TIfERK10Vector3D_TIfLb0EES2_$155+8];

$L__BB4_408:
	mul.ftz.f32 	%f6297, %f829, %f2528;
	mul.ftz.f32 	%f6298, %f6297, %f7778;
	mul.ftz.f32 	%f6299, %f2530, %f7779;
	sub.ftz.f32 	%f6300, %f6299, %f6298;
	mul.ftz.f32 	%f6301, %f2529, %f7779;
	mul.ftz.f32 	%f6302, %f6297, %f7777;
	sub.ftz.f32 	%f6303, %f6302, %f6301;
	mul.ftz.f32 	%f6304, %f2530, %f7777;
	mul.ftz.f32 	%f6305, %f2529, %f7778;
	sub.ftz.f32 	%f6306, %f6305, %f6304;
	mul.ftz.f32 	%f6307, %f2509, 0f40C90FDB;
	cos.approx.ftz.f32 	%f6308, %f6307;
	sqrt.approx.ftz.f32 	%f6309, %f2527;
	mul.ftz.f32 	%f6310, %f6309, %f6308;
	sin.approx.ftz.f32 	%f6311, %f6307;
	mul.ftz.f32 	%f6312, %f6309, %f6311;
	add.ftz.f32 	%f6313, %f6297, 0f3F800000;
	mov.f32 	%f6314, 0f3F800000;
	mul.ftz.f32 	%f6315, %f6313, 0f3F000000;
	sub.ftz.f32 	%f6316, %f6314, %f6315;
	mul.ftz.f32 	%f6317, %f6310, %f6310;
	sub.ftz.f32 	%f6318, %f6314, %f6317;
	sqrt.approx.ftz.f32 	%f6319, %f6318;
	mul.ftz.f32 	%f6320, %f6315, %f6312;
	fma.rn.ftz.f32 	%f6321, %f6316, %f6319, %f6320;
	mul.ftz.f32 	%f6322, %f6300, %f6321;
	mul.ftz.f32 	%f6323, %f6303, %f6321;
	mul.ftz.f32 	%f6324, %f6306, %f6321;
	fma.rn.ftz.f32 	%f6325, %f7777, %f6310, %f6322;
	fma.rn.ftz.f32 	%f6326, %f7778, %f6310, %f6323;
	fma.rn.ftz.f32 	%f6327, %f7779, %f6310, %f6324;
	mul.ftz.f32 	%f6328, %f6321, %f6321;
	sub.ftz.f32 	%f6329, %f6318, %f6328;
	mov.f32 	%f6330, 0f00000000;
	max.ftz.f32 	%f6331, %f6330, %f6329;
	sqrt.approx.ftz.f32 	%f6332, %f6331;
	fma.rn.ftz.f32 	%f6333, %f2529, %f6332, %f6325;
	fma.rn.ftz.f32 	%f6334, %f2530, %f6332, %f6326;
	fma.rn.ftz.f32 	%f6335, %f6297, %f6332, %f6327;
	mul.ftz.f32 	%f6336, %f7148, %f6333;
	mul.ftz.f32 	%f6337, %f7149, %f6334;
	max.ftz.f32 	%f6338, %f6330, %f6335;
	mul.ftz.f32 	%f6339, %f6337, %f6337;
	fma.rn.ftz.f32 	%f6340, %f6336, %f6336, %f6339;
	fma.rn.ftz.f32 	%f6341, %f6338, %f6338, %f6340;
	rsqrt.approx.ftz.f32 	%f6342, %f6341;
	mul.ftz.f32 	%f7783, %f6342, %f6336;
	mul.ftz.f32 	%f7784, %f6342, %f6337;
	mul.ftz.f32 	%f7785, %f6338, %f6342;
	neg.ftz.f32 	%f6343, %f827;
	mul.ftz.f32 	%f6344, %f7783, %f6343;
	neg.ftz.f32 	%f6345, %f828;
	mul.ftz.f32 	%f6346, %f7784, %f828;
	sub.ftz.f32 	%f6347, %f6344, %f6346;
	neg.ftz.f32 	%f6348, %f829;
	mul.ftz.f32 	%f6349, %f7785, %f829;
	sub.ftz.f32 	%f6350, %f6347, %f6349;
	add.ftz.f32 	%f6351, %f6350, %f6350;
	mul.ftz.f32 	%f6352, %f7783, %f6351;
	mul.ftz.f32 	%f6353, %f7784, %f6351;
	mul.ftz.f32 	%f6354, %f7785, %f6351;
	sub.ftz.f32 	%f7800, %f6343, %f6352;
	sub.ftz.f32 	%f7799, %f6345, %f6353;
	sub.ftz.f32 	%f7798, %f6348, %f6354;
	bra.uni 	$L__BB4_409;

$L__BB4_418:
	mul.ftz.f32 	%f6511, %f2590, %f2590;
	mov.f32 	%f6512, 0f3F800000;
	sub.ftz.f32 	%f6513, %f6512, %f6511;
	mul.ftz.f32 	%f2597, %f2592, %f2592;
	mul.ftz.f32 	%f2598, %f6513, %f2597;
	setp.ge.ftz.f32 	%p332, %f2598, 0f3F800000;
	mov.f32 	%f7801, 0f00000000;
	mov.f32 	%f7802, %f7801;
	mov.f32 	%f7803, %f7801;
	mov.f32 	%f7804, %f7801;
	@%p332 bra 	$L__BB4_436;

	mov.f32 	%f6514, 0f00000000;
	sub.ftz.f32 	%f6516, %f6512, %f2598;
	max.ftz.f32 	%f6517, %f6514, %f6516;
	sqrt.approx.ftz.f32 	%f2599, %f6517;
	mul.ftz.f32 	%f7800, %f2586, %f2592;
	mul.ftz.f32 	%f7799, %f2588, %f2592;
	mov.f32 	%f7798, %f2599;
	@%p328 bra 	$L__BB4_420;
	bra.uni 	$L__BB4_421;

$L__BB4_420:
	neg.ftz.f32 	%f7798, %f2599;
	neg.ftz.f32 	%f7799, %f7799;
	neg.ftz.f32 	%f7800, %f7800;

$L__BB4_421:
	mov.f32 	%f6518, 0f3F800000;
	sub.ftz.f32 	%f6519, %f6518, %f2596;
	mul.ftz.f32 	%f6520, %f845, %f6519;
	mul.ftz.f32 	%f6521, %f831, %f847;
	mul.ftz.f32 	%f6522, %f6521, 0fBFB8AA3B;
	ex2.approx.ftz.f32 	%f6523, %f6522;
	mul.ftz.f32 	%f6524, %f6520, %f6523;
	mul.ftz.f32 	%f6525, %f832, %f847;
	mul.ftz.f32 	%f6526, %f6525, 0fBFB8AA3B;
	ex2.approx.ftz.f32 	%f6527, %f6526;
	mul.ftz.f32 	%f6528, %f6520, %f6527;
	mul.ftz.f32 	%f6529, %f833, %f847;
	mul.ftz.f32 	%f6530, %f6529, 0fBFB8AA3B;
	ex2.approx.ftz.f32 	%f6531, %f6530;
	mul.ftz.f32 	%f6532, %f6520, %f6531;
	abs.ftz.f32 	%f6533, %f2599;
	div.approx.ftz.f32 	%f6534, %f2597, %f6533;
	mul.ftz.f32 	%f7801, %f6519, %f2597;
	mul.ftz.f32 	%f7804, %f6532, %f6534;
	mul.ftz.f32 	%f7803, %f6528, %f6534;
	mul.ftz.f32 	%f7802, %f6524, %f6534;
	bra.uni 	$L__BB4_436;

$L__BB4_397:
	setp.gt.ftz.f32 	%p318, %f2512, %f7773;
	@%p318 bra 	$L__BB4_399;
	bra.uni 	$L__BB4_398;

$L__BB4_399:
	div.approx.ftz.f32 	%f7774, %f7773, %f2512;
	mov.f32 	%f7773, %f2512;
	bra.uni 	$L__BB4_403;

$L__BB4_401:
	neg.ftz.f32 	%f2517, %f2512;
	div.approx.ftz.f32 	%f6274, %f7773, %f2512;
	add.ftz.f32 	%f7774, %f6274, 0f40800000;
	mov.f32 	%f7773, %f2517;
	bra.uni 	$L__BB4_403;

$L__BB4_398:
	div.approx.ftz.f32 	%f6272, %f2512, %f7773;
	mov.f32 	%f6273, 0f40000000;
	sub.ftz.f32 	%f7774, %f6273, %f6272;

$L__BB4_403:
	mul.ftz.f32 	%f6277, %f7774, 0f3F490FDB;
	cos.approx.ftz.f32 	%f6278, %f6277;
	mul.ftz.f32 	%f7800, %f7773, %f6278;
	sin.approx.ftz.f32 	%f6279, %f6277;
	mul.ftz.f32 	%f7799, %f7773, %f6279;

$L__BB4_404:
	mul.ftz.f32 	%f6283, %f7800, %f7800;
	mov.f32 	%f6284, 0f3F800000;
	sub.ftz.f32 	%f6285, %f6284, %f6283;
	mul.ftz.f32 	%f6286, %f7799, %f7799;
	sub.ftz.f32 	%f6287, %f6285, %f6286;
	max.ftz.f32 	%f6288, %f7783, %f6287;
	sqrt.approx.ftz.f32 	%f7798, %f6288;
	mov.f32 	%f7784, %f7783;
	mov.f32 	%f7785, %f7783;

$L__BB4_409:
	mul.ftz.f32 	%f6358, %f7148, %f7149;
	sqrt.approx.ftz.f32 	%f2553, %f6358;
	mov.f32 	%f7802, 0f00000000;
	max.ftz.f32 	%f2554, %f829, %f7802;
	mul.ftz.f32 	%f2555, %f2554, %f2554;
	mov.f32 	%f6359, 0f3F800000;
	sub.ftz.f32 	%f6360, %f6359, %f2555;
	div.approx.ftz.f32 	%f6361, %f6360, %f2555;
	mul.ftz.f32 	%f2556, %f2553, %f2553;
	fma.rn.ftz.f32 	%f6362, %f2556, %f6361, 0f3F800000;
	sqrt.approx.ftz.f32 	%f6363, %f6362;
	add.ftz.f32 	%f6364, %f6363, 0f3F800000;
	mov.f32 	%f6365, 0f40000000;
	div.approx.ftz.f32 	%f6366, %f6365, %f6364;
	mul.ftz.f32 	%f6367, %f7783, %f7783;
	mul.ftz.f32 	%f2557, %f7148, %f7148;
	div.approx.ftz.f32 	%f6368, %f6367, %f2557;
	mul.ftz.f32 	%f6369, %f7784, %f7784;
	mul.ftz.f32 	%f2558, %f7149, %f7149;
	div.approx.ftz.f32 	%f6370, %f6369, %f2558;
	add.ftz.f32 	%f6371, %f6368, %f6370;
	fma.rn.ftz.f32 	%f6372, %f7785, %f7785, %f6371;
	mov.f32 	%f6373, 0f33D6BF95;
	max.ftz.f32 	%f6374, %f6372, %f6373;
	mul.ftz.f32 	%f6375, %f7148, 0f40490FDB;
	mul.ftz.f32 	%f2559, %f6375, %f7149;
	mul.ftz.f32 	%f6376, %f2559, %f6374;
	mul.ftz.f32 	%f6377, %f6374, %f6376;
	rcp.approx.ftz.f32 	%f6378, %f6377;
	mul.ftz.f32 	%f6379, %f6366, %f6378;
	mul.ftz.f32 	%f2560, %f2554, 0f40800000;
	div.approx.ftz.f32 	%f7801, %f6379, %f2560;
	setp.gt.ftz.f32 	%p321, %f845, 0f3F666666;
	setp.lt.ftz.f32 	%p322, %f848, 0f3B03126F;
	and.pred  	%p323, %p322, %p321;
	mov.f32 	%f7803, %f7802;
	mov.f32 	%f7804, %f7802;
	@%p323 bra 	$L__BB4_436;

	add.ftz.f32 	%f6383, %f827, %f7800;
	mul.ftz.f32 	%f6384, %f6383, %f6383;
	add.ftz.f32 	%f6385, %f828, %f7799;
	fma.rn.ftz.f32 	%f6386, %f6385, %f6385, %f6384;
	add.ftz.f32 	%f6387, %f829, %f7798;
	fma.rn.ftz.f32 	%f6388, %f6387, %f6387, %f6386;
	rsqrt.approx.ftz.f32 	%f6389, %f6388;
	mul.ftz.f32 	%f2562, %f6383, %f6389;
	mul.ftz.f32 	%f2563, %f6385, %f6389;
	mul.ftz.f32 	%f2564, %f6387, %f6389;
	mul.ftz.f32 	%f6390, %f828, %f2563;
	fma.rn.ftz.f32 	%f6391, %f827, %f2562, %f6390;
	fma.rn.ftz.f32 	%f2565, %f829, %f2564, %f6391;
	mul.ftz.f32 	%f6392, %f7799, %f2563;
	fma.rn.ftz.f32 	%f6393, %f7800, %f2562, %f6392;
	fma.rn.ftz.f32 	%f2566, %f7798, %f2564, %f6393;
	mov.f32 	%f7802, 0f00000000;
	max.ftz.f32 	%f2567, %f7798, %f7802;
	setp.le.ftz.f32 	%p324, %f2567, 0f00000000;
	setp.le.ftz.f32 	%p325, %f2554, 0f00000000;
	or.pred  	%p326, %p325, %p324;
	@%p326 bra 	$L__BB4_436;

	mov.f32 	%f7786, 0f00000000;
	max.ftz.f32 	%f2568, %f2566, %f7786;
	max.ftz.f32 	%f6397, %f2565, %f7786;
	add.ftz.f32 	%f6398, %f830, 0f3F800000;
	mov.f32 	%f6399, 0f3F800000;
	add.ftz.f32 	%f6400, %f830, 0fBF800000;
	div.approx.ftz.f32 	%f6401, %f6400, %f6398;
	mul.ftz.f32 	%f6402, %f6401, %f6401;
	mov.f32 	%f6403, 0f3D23D70A;
	max.ftz.f32 	%f6404, %f6402, %f6403;
	sub.ftz.f32 	%f6405, %f6399, %f6397;
	max.ftz.f32 	%f6406, %f6405, %f7786;
	min.ftz.f32 	%f6407, %f6406, %f6399;
	mul.ftz.f32 	%f6408, %f6407, %f6407;
	mul.ftz.f32 	%f6409, %f6408, %f6408;
	mul.ftz.f32 	%f6410, %f6407, %f6409;
	ld.global.f32 	%f6411, [_Z18mx_fresnel_schlickfRK5RGB_TIfE$137];
	sub.ftz.f32 	%f6412, %f6411, %f6404;
	ld.global.f32 	%f6413, [_Z18mx_fresnel_schlickfRK5RGB_TIfE$137+4];
	sub.ftz.f32 	%f6414, %f6413, %f6404;
	ld.global.f32 	%f6415, [_Z18mx_fresnel_schlickfRK5RGB_TIfE$137+8];
	sub.ftz.f32 	%f6416, %f6415, %f6404;
	fma.rn.ftz.f32 	%f2569, %f6412, %f6410, %f6404;
	fma.rn.ftz.f32 	%f2570, %f6414, %f6410, %f6404;
	fma.rn.ftz.f32 	%f2571, %f6410, %f6416, %f6404;
	mul.ftz.f32 	%f6417, %f2562, %f2562;
	div.approx.ftz.f32 	%f6418, %f6417, %f2557;
	mul.ftz.f32 	%f6419, %f2563, %f2563;
	div.approx.ftz.f32 	%f6420, %f6419, %f2558;
	add.ftz.f32 	%f6421, %f6418, %f6420;
	fma.rn.ftz.f32 	%f6422, %f2564, %f2564, %f6421;
	mov.f32 	%f6423, 0f33D6BF95;
	max.ftz.f32 	%f6424, %f6422, %f6423;
	mul.ftz.f32 	%f6425, %f2559, %f6424;
	mul.ftz.f32 	%f6426, %f6424, %f6425;
	rcp.approx.ftz.f32 	%f2572, %f6426;
	mul.ftz.f32 	%f6427, %f2567, %f2567;
	sub.ftz.f32 	%f6428, %f6399, %f2556;
	fma.rn.ftz.f32 	%f6429, %f6428, %f6427, %f2556;
	sqrt.approx.ftz.f32 	%f6430, %f6429;
	fma.rn.ftz.f32 	%f6431, %f2555, %f6428, %f2556;
	sqrt.approx.ftz.f32 	%f6432, %f6431;
	div.approx.ftz.f32 	%f6433, %f6430, %f2567;
	div.approx.ftz.f32 	%f6434, %f6432, %f2554;
	add.ftz.f32 	%f2573, %f6433, %f6434;
	setp.geu.ftz.f32 	%p327, %f844, 0f3F800000;
	mov.f32 	%f7787, %f7786;
	mov.f32 	%f7788, %f7786;
	@%p327 bra 	$L__BB4_413;

	mul.ftz.f32 	%f6435, %f831, %f2510;
	ld.global.f32 	%f6436, [_ZNK16DisneyPrincipled8evaluateERK10Vector3D_TIfLb0EES3_$910];
	sub.ftz.f32 	%f6437, %f6436, %f2569;
	ld.global.f32 	%f6438, [_ZNK16DisneyPrincipled8evaluateERK10Vector3D_TIfLb0EES3_$910+4];
	sub.ftz.f32 	%f6439, %f6438, %f2570;
	ld.global.f32 	%f6440, [_ZNK16DisneyPrincipled8evaluateERK10Vector3D_TIfLb0EES3_$910+8];
	sub.ftz.f32 	%f6441, %f6440, %f2571;
	sub.ftz.f32 	%f6443, %f6399, %f2567;
	mul.ftz.f32 	%f6444, %f6443, %f6443;
	mul.ftz.f32 	%f6445, %f6444, %f6444;
	mul.ftz.f32 	%f6446, %f6443, %f6445;
	sub.ftz.f32 	%f6447, %f6399, %f2554;
	mul.ftz.f32 	%f6448, %f6447, %f6447;
	mul.ftz.f32 	%f6449, %f6448, %f6448;
	mul.ftz.f32 	%f6450, %f6447, %f6449;
	add.ftz.f32 	%f6451, %f2568, %f2568;
	mul.ftz.f32 	%f6452, %f2568, %f6451;
	fma.rn.ftz.f32 	%f6453, %f2553, %f6452, 0f3F000000;
	sub.ftz.f32 	%f6454, %f6399, %f6446;
	fma.rn.ftz.f32 	%f6455, %f6446, %f6453, %f6454;
	sub.ftz.f32 	%f6456, %f6399, %f6450;
	fma.rn.ftz.f32 	%f6457, %f6450, %f6453, %f6456;
	mul.ftz.f32 	%f6458, %f6455, %f6457;
	mul.ftz.f32 	%f6459, %f6435, %f6458;
	mul.ftz.f32 	%f6460, %f832, %f2510;
	mul.ftz.f32 	%f6461, %f6460, %f6458;
	mul.ftz.f32 	%f6462, %f833, %f2510;
	mul.ftz.f32 	%f6463, %f6462, %f6458;
	mul.ftz.f32 	%f6464, %f6459, %f6437;
	mul.ftz.f32 	%f6465, %f6461, %f6439;
	mul.ftz.f32 	%f6466, %f6463, %f6441;
	mul.ftz.f32 	%f7786, %f6464, 0f3EA2F983;
	mul.ftz.f32 	%f7787, %f6465, 0f3EA2F983;
	mul.ftz.f32 	%f7788, %f6466, 0f3EA2F983;

$L__BB4_413:
	mov.f32 	%f6467, 0f40000000;
	div.approx.ftz.f32 	%f6468, %f6467, %f2573;
	mul.ftz.f32 	%f6469, %f2560, %f2567;
	rcp.approx.ftz.f32 	%f6470, %f6469;
	mul.ftz.f32 	%f6471, %f2569, %f2572;
	mul.ftz.f32 	%f6472, %f6471, %f6468;
	fma.rn.ftz.f32 	%f6473, %f6470, %f6472, %f7786;
	mul.ftz.f32 	%f6474, %f2570, %f2572;
	mul.ftz.f32 	%f6475, %f6474, %f6468;
	fma.rn.ftz.f32 	%f6476, %f6470, %f6475, %f7787;
	mul.ftz.f32 	%f6477, %f2571, %f2572;
	mul.ftz.f32 	%f6478, %f6477, %f6468;
	fma.rn.ftz.f32 	%f6479, %f6470, %f6478, %f7788;
	mul.ftz.f32 	%f7804, %f2567, %f6479;
	mul.ftz.f32 	%f7803, %f2567, %f6476;
	mul.ftz.f32 	%f7802, %f2567, %f6473;

$L__BB4_436:
	setp.gt.ftz.f32 	%p341, %f7801, 0f00000000;
	@%p341 bra 	$L__BB4_438;
	bra.uni 	$L__BB4_437;

$L__BB4_438:
	abs.ftz.f32 	%f6737, %f7798;
	mul.ftz.f32 	%f6738, %f7802, %f6737;
	mul.ftz.f32 	%f6739, %f7803, %f6737;
	mul.ftz.f32 	%f6740, %f7804, %f6737;
	rcp.approx.ftz.f32 	%f6741, %f7801;
	mul.ftz.f32 	%f6742, %f6741, %f6738;
	mul.ftz.f32 	%f6743, %f6741, %f6739;
	mul.ftz.f32 	%f6744, %f6741, %f6740;
	ld.f32 	%f6745, [%rd6];
	mul.ftz.f32 	%f6746, %f6745, %f6742;
	ld.f32 	%f6747, [%rd6+4];
	mul.ftz.f32 	%f6748, %f6747, %f6743;
	ld.f32 	%f6749, [%rd6+8];
	mul.ftz.f32 	%f6750, %f6744, %f6749;
	st.f32 	[%rd6], %f6746;
	st.f32 	[%rd6+4], %f6748;
	st.f32 	[%rd6+8], %f6750;
	setp.gt.ftz.f32 	%p342, %f7798, 0f00000000;
	selp.f32 	%f6751, 0f3A83126F, 0fBA83126F, %p342;
	fma.rn.ftz.f32 	%f6752, %f7141, %f6751, %f824;
	fma.rn.ftz.f32 	%f6753, %f7140, %f6751, %f825;
	fma.rn.ftz.f32 	%f6754, %f7139, %f6751, %f826;
	st.f32 	[%rd6+24], %f6752;
	st.f32 	[%rd6+28], %f6753;
	st.f32 	[%rd6+32], %f6754;
	mul.ftz.f32 	%f6755, %f7147, %f7800;
	fma.rn.ftz.f32 	%f6756, %f821, %f7799, %f6755;
	fma.rn.ftz.f32 	%f6757, %f7141, %f7798, %f6756;
	mul.ftz.f32 	%f6758, %f7146, %f7800;
	fma.rn.ftz.f32 	%f6759, %f822, %f7799, %f6758;
	fma.rn.ftz.f32 	%f6760, %f7140, %f7798, %f6759;
	mul.ftz.f32 	%f6761, %f7145, %f7800;
	fma.rn.ftz.f32 	%f6762, %f823, %f7799, %f6761;
	fma.rn.ftz.f32 	%f6763, %f7139, %f7798, %f6762;
	st.f32 	[%rd6+36], %f6757;
	st.f32 	[%rd6+40], %f6760;
	st.f32 	[%rd6+44], %f6763;
	st.f32 	[%rd6+48], %f7801;
	ld.u32 	%r2489, [%rd6+52];
	and.b32  	%r2490, %r2489, 1073741823;
	selp.u32 	%r2491, -1, 0, %p345;
	bfi.b32 	%r2492, %r2491, %r2490, 31, 1;
	st.u32 	[%rd6+52], %r2492;
	setp.ne.s32 	%p343, %r2490, 1;
	@%p343 bra 	$L__BB4_446;

	@%p345 bra 	$L__BB4_444;
	bra.uni 	$L__BB4_440;

$L__BB4_444:
	ld.global.u64 	%rd1953, [%rd51];
	cvt.rn.f32.u64 	%f6805, %rd1953;
	st.f32 	[%rd8], %f6805;
	st.f32 	[%rd8+4], %f6805;
	st.f32 	[%rd8+8], %f6805;
	bra.uni 	$L__BB4_445;

$L__BB4_437:
	ld.u32 	%r2487, [%rd6+52];
	or.b32  	%r2488, %r2487, 1073741824;
	st.u32 	[%rd6+52], %r2488;
	bra.uni 	$L__BB4_446;

$L__BB4_440:
	@%p311 bra 	$L__BB4_442;
	bra.uni 	$L__BB4_441;

$L__BB4_442:
	ld.global.f32 	%f6768, [_ZNK16DisneyPrincipled29evaluateDHReflectanceEstimateERK10Vector3D_TIfLb0EE$1099];
	mov.f32 	%f6769, 0f3F800000;
	sub.ftz.f32 	%f7805, %f6769, %f844;
	mul.ftz.f32 	%f6770, %f7805, %f6768;
	ld.global.f32 	%f6771, [_ZNK16DisneyPrincipled29evaluateDHReflectanceEstimateERK10Vector3D_TIfLb0EE$1099+4];
	mul.ftz.f32 	%f6772, %f7805, %f6771;
	ld.global.f32 	%f6773, [_ZNK16DisneyPrincipled29evaluateDHReflectanceEstimateERK10Vector3D_TIfLb0EE$1099+8];
	mul.ftz.f32 	%f6774, %f7805, %f6773;
	fma.rn.ftz.f32 	%f7808, %f831, %f844, %f6770;
	fma.rn.ftz.f32 	%f7807, %f832, %f844, %f6772;
	fma.rn.ftz.f32 	%f7806, %f833, %f844, %f6774;
	bra.uni 	$L__BB4_443;

$L__BB4_441:
	add.ftz.f32 	%f6764, %f830, 0fBF800000;
	add.ftz.f32 	%f6765, %f830, 0f3F800000;
	mov.f32 	%f6766, 0f3F800000;
	div.approx.ftz.f32 	%f6767, %f6764, %f6765;
	mul.ftz.f32 	%f7806, %f6767, %f6767;
	sub.ftz.f32 	%f7805, %f6766, %f844;
	mov.f32 	%f7807, %f7806;
	mov.f32 	%f7808, %f7806;

$L__BB4_443:
	mov.f32 	%f6775, 0f00000000;
	max.ftz.f32 	%f6776, %f829, %f6775;
	mov.f32 	%f6777, 0f3F800000;
	sub.ftz.f32 	%f6778, %f6777, %f6776;
	max.ftz.f32 	%f6779, %f6778, %f6775;
	min.ftz.f32 	%f6780, %f6779, %f6777;
	mul.ftz.f32 	%f6781, %f6780, %f6780;
	mul.ftz.f32 	%f6782, %f6781, %f6781;
	mul.ftz.f32 	%f6783, %f6780, %f6782;
	ld.global.f32 	%f6784, [_Z18mx_fresnel_schlickfRK5RGB_TIfE$137];
	sub.ftz.f32 	%f6785, %f6784, %f7808;
	ld.global.f32 	%f6786, [_Z18mx_fresnel_schlickfRK5RGB_TIfE$137+4];
	sub.ftz.f32 	%f6787, %f6786, %f7807;
	ld.global.f32 	%f6788, [_Z18mx_fresnel_schlickfRK5RGB_TIfE$137+8];
	sub.ftz.f32 	%f6789, %f6788, %f7806;
	fma.rn.ftz.f32 	%f6790, %f6785, %f6783, %f7808;
	fma.rn.ftz.f32 	%f6791, %f6787, %f6783, %f7807;
	fma.rn.ftz.f32 	%f6792, %f6783, %f6789, %f7806;
	sub.ftz.f32 	%f6793, %f6777, %f6790;
	sub.ftz.f32 	%f6794, %f6777, %f6791;
	sub.ftz.f32 	%f6795, %f6777, %f6792;
	mul.ftz.f32 	%f6796, %f831, %f6793;
	mul.ftz.f32 	%f6797, %f832, %f6794;
	mul.ftz.f32 	%f6798, %f833, %f6795;
	mul.ftz.f32 	%f6799, %f7805, %f6796;
	mul.ftz.f32 	%f6800, %f7805, %f6797;
	mul.ftz.f32 	%f6801, %f7805, %f6798;
	fma.rn.ftz.f32 	%f6802, %f844, %f6790, %f6799;
	fma.rn.ftz.f32 	%f6803, %f844, %f6791, %f6800;
	fma.rn.ftz.f32 	%f6804, %f844, %f6792, %f6801;
	st.f32 	[%rd8], %f6802;
	st.f32 	[%rd8+4], %f6803;
	st.f32 	[%rd8+8], %f6804;

$L__BB4_445:
	mov.b64 	%rd1954, {%r148, %r150};
	st.f32 	[%rd1954], %f7141;
	st.f32 	[%rd1954+4], %f7140;
	st.f32 	[%rd1954+8], %f7139;

$L__BB4_446:
	mul.lo.s64 	%rd1955, %rd141, 6364136223846793005;
	add.s64 	%rd1956, %rd1955, 1;
	mov.u32 	%r2493, 0;
	mov.b64 	{%r2494, %r2496}, %rd1956;
	// begin inline asm
	call _optix_set_payload, (%r2493, %r2494);
	// end inline asm
	mov.u32 	%r2495, 1;
	// begin inline asm
	call _optix_set_payload, (%r2495, %r2496);
	// end inline asm
	ret;

}
	// .globl	__anyhit__visibility
.visible .entry __anyhit__visibility()
{
	.reg .pred 	%p<22>;
	.reg .b16 	%rs<3>;
	.reg .f32 	%f<524>;
	.reg .b32 	%r<174>;
	.reg .b64 	%rd<154>;


	// begin inline asm
	call (%rd13), _optix_get_sbt_data_ptr_64, ();
	// end inline asm
	ld.const.u64 	%rd14, [plp+336];
	cvta.to.global.u64 	%rd15, %rd14;
	ld.u32 	%r7, [%rd13+4];
	ld.const.u64 	%rd16, [plp+352];
	cvta.to.global.u64 	%rd17, %rd16;
	ld.u32 	%r8, [%rd13];
	// begin inline asm
	call (%f171, %f172), _optix_get_triangle_barycentrics, ();
	// end inline asm
	// begin inline asm
	call (%r6), _optix_read_primitive_idx, ();
	// end inline asm
	mul.wide.u32 	%rd18, %r8, 64;
	add.s64 	%rd19, %rd17, %rd18;
	ld.global.u64 	%rd20, [%rd19+16];
	mul.wide.s32 	%rd21, %r6, 12;
	add.s64 	%rd22, %rd20, %rd21;
	ld.u32 	%r9, [%rd22];
	ld.u32 	%r10, [%rd22+4];
	ld.u32 	%r11, [%rd22+8];
	add.ftz.f32 	%f173, %f171, %f172;
	mov.f32 	%f174, 0f3F800000;
	sub.ftz.f32 	%f3, %f174, %f173;
	ld.global.u64 	%rd23, [%rd19];
	mul.wide.u32 	%rd24, %r9, 44;
	add.s64 	%rd25, %rd23, %rd24;
	add.s64 	%rd1, %rd25, 36;
	ld.f32 	%f175, [%rd25+36];
	ld.f32 	%f176, [%rd25+40];
	mul.wide.u32 	%rd26, %r10, 44;
	add.s64 	%rd27, %rd23, %rd26;
	add.s64 	%rd2, %rd27, 36;
	ld.f32 	%f177, [%rd27+36];
	mul.ftz.f32 	%f178, %f171, %f177;
	ld.f32 	%f179, [%rd27+40];
	mul.ftz.f32 	%f180, %f171, %f179;
	fma.rn.ftz.f32 	%f181, %f3, %f175, %f178;
	fma.rn.ftz.f32 	%f182, %f3, %f176, %f180;
	mul.wide.u32 	%rd28, %r11, 44;
	add.s64 	%rd29, %rd23, %rd28;
	add.s64 	%rd3, %rd29, 36;
	ld.f32 	%f183, [%rd29+36];
	ld.f32 	%f184, [%rd29+40];
	fma.rn.ftz.f32 	%f4, %f172, %f183, %f181;
	fma.rn.ftz.f32 	%f5, %f172, %f184, %f182;
	mul.wide.u32 	%rd30, %r7, 272;
	add.s64 	%rd31, %rd15, %rd30;
	add.s64 	%rd4, %rd31, 120;
	ld.global.u64 	%rd32, [%rd31+120];
	mov.f32 	%f185, 0f00000000;
	tex.level.2d.v4.f32.f32 	{%f463, %f186, %f187, %f188}, [%rd32, {%f4, %f5}], %f185;
	ld.global.u32 	%r12, [%rd31+268];
	setp.eq.s32 	%p1, %r12, 0;
	ld.global.u64 	%rd5, [%rd31];
	@%p1 bra 	$L__BB5_3;

	tex.level.2d.v4.f32.f32 	{%f190, %f191, %f192, %f193}, [%rd5, {%f4, %f5}], %f185;
	setp.geu.ftz.f32 	%p2, %f193, 0f3F000000;
	setp.lt.ftz.f32 	%p3, %f463, 0f3DCCCCCD;
	selp.f32 	%f463, 0f00000000, %f463, %p3;
	@%p2 bra 	$L__BB5_3;

	mov.f32 	%f463, 0f3F800000;

$L__BB5_3:
	ld.global.u64 	%rd33, [%rd4+8];
	tex.level.2d.v4.f32.f32 	{%f9, %f10, %f11, %f12}, [%rd33, {%f4, %f5}], %f185;
	tex.level.2d.v4.f32.f32 	{%f13, %f14, %f15, %f16}, [%rd5, {%f4, %f5}], %f185;
	mov.u32 	%r14, 0;
	// begin inline asm
	call (%r13), _optix_get_payload, (%r14);
	// end inline asm
	setp.gtu.ftz.f32 	%p4, %f463, 0f00000000;
	@%p4 bra 	$L__BB5_5;
	bra.uni 	$L__BB5_4;

$L__BB5_5:
	// begin inline asm
	call (%f196), _optix_get_world_ray_direction_x, ();
	// end inline asm
	// begin inline asm
	call (%f197), _optix_get_world_ray_direction_y, ();
	// end inline asm
	// begin inline asm
	call (%f198), _optix_get_world_ray_direction_z, ();
	// end inline asm
	mul.ftz.f32 	%f199, %f197, %f197;
	fma.rn.ftz.f32 	%f200, %f196, %f196, %f199;
	fma.rn.ftz.f32 	%f201, %f198, %f198, %f200;
	rsqrt.approx.ftz.f32 	%f202, %f201;
	mul.ftz.f32 	%f17, %f196, %f202;
	mul.ftz.f32 	%f18, %f197, %f202;
	mul.ftz.f32 	%f19, %f198, %f202;
	ld.f32 	%f203, [%rd1+-24];
	ld.f32 	%f204, [%rd1+-20];
	ld.f32 	%f205, [%rd1+-16];
	ld.f32 	%f206, [%rd2+-24];
	mul.ftz.f32 	%f207, %f171, %f206;
	ld.f32 	%f208, [%rd2+-20];
	mul.ftz.f32 	%f209, %f171, %f208;
	ld.f32 	%f210, [%rd2+-16];
	mul.ftz.f32 	%f211, %f171, %f210;
	fma.rn.ftz.f32 	%f212, %f3, %f203, %f207;
	fma.rn.ftz.f32 	%f213, %f3, %f204, %f209;
	fma.rn.ftz.f32 	%f214, %f3, %f205, %f211;
	ld.f32 	%f215, [%rd3+-24];
	ld.f32 	%f216, [%rd3+-20];
	ld.f32 	%f217, [%rd3+-16];
	fma.rn.ftz.f32 	%f218, %f172, %f215, %f212;
	fma.rn.ftz.f32 	%f219, %f172, %f216, %f213;
	fma.rn.ftz.f32 	%f220, %f172, %f217, %f214;
	mul.ftz.f32 	%f221, %f219, %f219;
	fma.rn.ftz.f32 	%f222, %f218, %f218, %f221;
	fma.rn.ftz.f32 	%f223, %f220, %f220, %f222;
	rsqrt.approx.ftz.f32 	%f224, %f223;
	mul.ftz.f32 	%f519, %f218, %f224;
	mul.ftz.f32 	%f520, %f219, %f224;
	mul.ftz.f32 	%f22, %f220, %f224;
	// begin inline asm
	call (%r17), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p5, %r17, 0;
	@%p5 bra 	$L__BB5_26;

	// begin inline asm
	call (%r18), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f225), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p6, %r18, 0;
	@%p6 bra 	$L__BB5_25;

	mov.u32 	%r173, 0;

$L__BB5_8:
	.pragma "nounroll";
	// begin inline asm
	call (%rd34), _optix_get_transform_list_handle, (%r173);
	// end inline asm
	// begin inline asm
	call (%r21), _optix_get_transform_type_from_handle, (%rd34);
	// end inline asm
	or.b32  	%r22, %r21, 1;
	setp.eq.s32 	%p7, %r22, 3;
	@%p7 bra 	$L__BB5_15;
	bra.uni 	$L__BB5_9;

$L__BB5_15:
	setp.eq.s32 	%p11, %r21, 2;
	@%p11 bra 	$L__BB5_19;
	bra.uni 	$L__BB5_16;

$L__BB5_19:
	// begin inline asm
	call (%rd106), _optix_get_matrix_motion_transform_from_handle, (%rd34);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd108, %rd106;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r110,%r111,%r112,%r113}, [%rd108];
	// end inline asm
	add.s64 	%rd112, %rd106, 16;
	// begin inline asm
	cvta.to.global.u64 %rd111, %rd112;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r114,%r115,%r116,%r117}, [%rd111];
	// end inline asm
	add.s64 	%rd115, %rd106, 32;
	// begin inline asm
	cvta.to.global.u64 %rd114, %rd115;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r118,%r119,%r120,%r121}, [%rd114];
	// end inline asm
	add.s64 	%rd118, %rd106, 48;
	// begin inline asm
	cvta.to.global.u64 %rd117, %rd118;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r122,%r123,%r124,%r125}, [%rd117];
	// end inline asm
	add.s64 	%rd121, %rd106, 64;
	// begin inline asm
	cvta.to.global.u64 %rd120, %rd121;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r126,%r127,%r128,%r129}, [%rd120];
	// end inline asm
	add.s64 	%rd124, %rd106, 80;
	// begin inline asm
	cvta.to.global.u64 %rd123, %rd124;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r130,%r131,%r132,%r133}, [%rd123];
	// end inline asm
	add.s64 	%rd127, %rd106, 96;
	// begin inline asm
	cvta.to.global.u64 %rd126, %rd127;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r134,%r135,%r136,%r137}, [%rd126];
	// end inline asm
	add.s64 	%rd130, %rd106, 112;
	// begin inline asm
	cvta.to.global.u64 %rd129, %rd130;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r138,%r139,%r140,%r141}, [%rd129];
	// end inline asm
	mov.b32 	%f322, %r113;
	mov.b32 	%f323, %r114;
	and.b32  	%r154, %r112, 65535;
	add.s32 	%r155, %r154, -1;
	cvt.rn.f32.s32 	%f324, %r155;
	sub.ftz.f32 	%f325, %f225, %f322;
	sub.ftz.f32 	%f326, %f323, %f322;
	div.approx.ftz.f32 	%f327, %f325, %f326;
	mul.ftz.f32 	%f328, %f327, %f324;
	min.ftz.f32 	%f329, %f324, %f328;
	mov.f32 	%f330, 0f00000000;
	max.ftz.f32 	%f331, %f330, %f329;
	setp.num.ftz.f32 	%p14, %f331, %f331;
	selp.f32 	%f332, %f331, 0f00000000, %p14;
	cvt.rmi.ftz.f32.f32 	%f333, %f332;
	add.ftz.f32 	%f334, %f324, 0fBF800000;
	min.ftz.f32 	%f335, %f333, %f334;
	sub.ftz.f32 	%f82, %f332, %f335;
	cvt.rzi.ftz.s32.f32 	%r156, %f335;
	cvt.s64.s32 	%rd12, %r156;
	mul.wide.s32 	%rd141, %r156, 48;
	add.s64 	%rd133, %rd115, %rd141;
	// begin inline asm
	cvta.to.global.u64 %rd132, %rd133;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r142,%r143,%r144,%r145}, [%rd132];
	// end inline asm
	mov.b32 	%f489, %r142;
	mov.b32 	%f490, %r143;
	mov.b32 	%f491, %r144;
	add.s64 	%rd136, %rd133, 16;
	// begin inline asm
	cvta.to.global.u64 %rd135, %rd136;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r146,%r147,%r148,%r149}, [%rd135];
	// end inline asm
	mov.b32 	%f486, %r146;
	mov.b32 	%f487, %r147;
	mov.b32 	%f488, %r148;
	add.s64 	%rd139, %rd133, 32;
	// begin inline asm
	cvta.to.global.u64 %rd138, %rd139;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r150,%r151,%r152,%r153}, [%rd138];
	// end inline asm
	mov.b32 	%f483, %r150;
	mov.b32 	%f484, %r151;
	mov.b32 	%f485, %r152;
	setp.leu.ftz.f32 	%p15, %f82, 0f00000000;
	@%p15 bra 	$L__BB5_21;

	mov.f32 	%f336, 0f3F800000;
	sub.ftz.f32 	%f337, %f336, %f82;
	mul.lo.s64 	%rd151, %rd12, 48;
	add.s64 	%rd152, %rd106, %rd151;
	add.s64 	%rd143, %rd152, 80;
	// begin inline asm
	cvta.to.global.u64 %rd142, %rd143;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r157,%r158,%r159,%r160}, [%rd142];
	// end inline asm
	mov.b32 	%f338, %r157;
	mov.b32 	%f339, %r158;
	mov.b32 	%f340, %r159;
	mul.ftz.f32 	%f341, %f82, %f338;
	mul.ftz.f32 	%f342, %f82, %f339;
	mul.ftz.f32 	%f343, %f82, %f340;
	fma.rn.ftz.f32 	%f489, %f337, %f489, %f341;
	fma.rn.ftz.f32 	%f490, %f337, %f490, %f342;
	fma.rn.ftz.f32 	%f491, %f337, %f491, %f343;
	add.s64 	%rd146, %rd152, 96;
	// begin inline asm
	cvta.to.global.u64 %rd145, %rd146;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r161,%r162,%r163,%r164}, [%rd145];
	// end inline asm
	mov.b32 	%f344, %r161;
	mov.b32 	%f345, %r162;
	mov.b32 	%f346, %r163;
	mul.ftz.f32 	%f347, %f82, %f344;
	mul.ftz.f32 	%f348, %f82, %f345;
	mul.ftz.f32 	%f349, %f82, %f346;
	fma.rn.ftz.f32 	%f486, %f337, %f486, %f347;
	fma.rn.ftz.f32 	%f487, %f337, %f487, %f348;
	fma.rn.ftz.f32 	%f488, %f337, %f488, %f349;
	add.s64 	%rd149, %rd152, 112;
	// begin inline asm
	cvta.to.global.u64 %rd148, %rd149;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r165,%r166,%r167,%r168}, [%rd148];
	// end inline asm
	mov.b32 	%f350, %r165;
	mov.b32 	%f351, %r166;
	mov.b32 	%f352, %r167;
	mul.ftz.f32 	%f353, %f82, %f350;
	mul.ftz.f32 	%f354, %f82, %f351;
	mul.ftz.f32 	%f355, %f82, %f352;
	fma.rn.ftz.f32 	%f483, %f337, %f483, %f353;
	fma.rn.ftz.f32 	%f484, %f337, %f484, %f354;
	fma.rn.ftz.f32 	%f485, %f337, %f485, %f355;
	bra.uni 	$L__BB5_21;

$L__BB5_9:
	mov.f32 	%f492, 0f00000000;
	mov.f32 	%f494, 0f3F800000;
	setp.eq.s32 	%p8, %r21, 4;
	@%p8 bra 	$L__BB5_11;

	setp.ne.s32 	%p9, %r21, 1;
	mov.f32 	%f493, %f492;
	mov.f32 	%f495, %f492;
	mov.f32 	%f496, %f494;
	mov.f32 	%f497, %f492;
	mov.f32 	%f498, %f494;
	mov.f32 	%f499, %f492;
	mov.f32 	%f500, %f492;
	@%p9 bra 	$L__BB5_22;

$L__BB5_11:
	@%p8 bra 	$L__BB5_13;
	bra.uni 	$L__BB5_12;

$L__BB5_13:
	// begin inline asm
	call (%rd153), _optix_get_instance_inverse_transform_from_handle, (%rd34);
	// end inline asm
	bra.uni 	$L__BB5_14;

$L__BB5_16:
	// begin inline asm
	call (%rd49), _optix_get_srt_motion_transform_from_handle, (%rd34);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd51, %rd49;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r35,%r36,%r37,%r38}, [%rd51];
	// end inline asm
	add.s64 	%rd55, %rd49, 16;
	// begin inline asm
	cvta.to.global.u64 %rd54, %rd55;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r39,%r40,%r41,%r42}, [%rd54];
	// end inline asm
	add.s64 	%rd58, %rd49, 32;
	// begin inline asm
	cvta.to.global.u64 %rd57, %rd58;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r43,%r44,%r45,%r46}, [%rd57];
	// end inline asm
	add.s64 	%rd61, %rd49, 48;
	// begin inline asm
	cvta.to.global.u64 %rd60, %rd61;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r47,%r48,%r49,%r50}, [%rd60];
	// end inline asm
	add.s64 	%rd64, %rd49, 64;
	// begin inline asm
	cvta.to.global.u64 %rd63, %rd64;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r51,%r52,%r53,%r54}, [%rd63];
	// end inline asm
	add.s64 	%rd67, %rd49, 80;
	// begin inline asm
	cvta.to.global.u64 %rd66, %rd67;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r55,%r56,%r57,%r58}, [%rd66];
	// end inline asm
	add.s64 	%rd70, %rd49, 96;
	// begin inline asm
	cvta.to.global.u64 %rd69, %rd70;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r59,%r60,%r61,%r62}, [%rd69];
	// end inline asm
	add.s64 	%rd73, %rd49, 112;
	// begin inline asm
	cvta.to.global.u64 %rd72, %rd73;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r63,%r64,%r65,%r66}, [%rd72];
	// end inline asm
	add.s64 	%rd76, %rd49, 128;
	// begin inline asm
	cvta.to.global.u64 %rd75, %rd76;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r67,%r68,%r69,%r70}, [%rd75];
	// end inline asm
	add.s64 	%rd79, %rd49, 144;
	// begin inline asm
	cvta.to.global.u64 %rd78, %rd79;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r71,%r72,%r73,%r74}, [%rd78];
	// end inline asm
	mov.b32 	%f237, %r38;
	mov.b32 	%f238, %r39;
	and.b32  	%r91, %r37, 65535;
	add.s32 	%r92, %r91, -1;
	cvt.rn.f32.s32 	%f239, %r92;
	sub.ftz.f32 	%f240, %f225, %f237;
	sub.ftz.f32 	%f241, %f238, %f237;
	div.approx.ftz.f32 	%f242, %f240, %f241;
	mul.ftz.f32 	%f243, %f242, %f239;
	min.ftz.f32 	%f244, %f239, %f243;
	mov.f32 	%f245, 0f00000000;
	max.ftz.f32 	%f246, %f245, %f244;
	setp.num.ftz.f32 	%p12, %f246, %f246;
	selp.f32 	%f247, %f246, 0f00000000, %p12;
	cvt.rmi.ftz.f32.f32 	%f248, %f247;
	add.ftz.f32 	%f249, %f239, 0fBF800000;
	min.ftz.f32 	%f250, %f248, %f249;
	sub.ftz.f32 	%f42, %f247, %f250;
	cvt.rzi.ftz.s32.f32 	%r93, %f250;
	mul.wide.s32 	%rd93, %r93, 64;
	add.s64 	%rd82, %rd58, %rd93;
	// begin inline asm
	cvta.to.global.u64 %rd81, %rd82;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r75,%r76,%r77,%r78}, [%rd81];
	// end inline asm
	mov.b32 	%f473, %r75;
	mov.b32 	%f474, %r76;
	mov.b32 	%f475, %r77;
	add.s64 	%rd85, %rd82, 16;
	// begin inline asm
	cvta.to.global.u64 %rd84, %rd85;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r79,%r80,%r81,%r82}, [%rd84];
	// end inline asm
	mov.b32 	%f476, %r79;
	mov.b32 	%f477, %r80;
	mov.b32 	%f478, %r82;
	add.s64 	%rd88, %rd82, 32;
	// begin inline asm
	cvta.to.global.u64 %rd87, %rd88;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r83,%r84,%r85,%r86}, [%rd87];
	// end inline asm
	mov.b32 	%f479, %r84;
	mov.b32 	%f480, %r85;
	mov.b32 	%f481, %r86;
	add.s64 	%rd91, %rd82, 48;
	// begin inline asm
	cvta.to.global.u64 %rd90, %rd91;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r87,%r88,%r89,%r90}, [%rd90];
	// end inline asm
	mov.b32 	%f482, %r87;
	setp.leu.ftz.f32 	%p13, %f42, 0f00000000;
	@%p13 bra 	$L__BB5_18;

	mov.f32 	%f251, 0f3F800000;
	sub.ftz.f32 	%f252, %f251, %f42;
	add.s64 	%rd95, %rd82, 64;
	// begin inline asm
	cvta.to.global.u64 %rd94, %rd95;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r94,%r95,%r96,%r97}, [%rd94];
	// end inline asm
	mov.b32 	%f253, %r94;
	mov.b32 	%f254, %r95;
	mov.b32 	%f255, %r96;
	mul.ftz.f32 	%f256, %f42, %f253;
	mul.ftz.f32 	%f257, %f42, %f254;
	mul.ftz.f32 	%f258, %f42, %f255;
	fma.rn.ftz.f32 	%f473, %f252, %f473, %f256;
	fma.rn.ftz.f32 	%f474, %f252, %f474, %f257;
	fma.rn.ftz.f32 	%f475, %f252, %f475, %f258;
	add.s64 	%rd98, %rd82, 80;
	// begin inline asm
	cvta.to.global.u64 %rd97, %rd98;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r98,%r99,%r100,%r101}, [%rd97];
	// end inline asm
	mov.b32 	%f259, %r98;
	mov.b32 	%f260, %r99;
	mov.b32 	%f261, %r101;
	mul.ftz.f32 	%f262, %f42, %f259;
	mul.ftz.f32 	%f263, %f42, %f260;
	mul.ftz.f32 	%f264, %f42, %f261;
	fma.rn.ftz.f32 	%f476, %f252, %f476, %f262;
	fma.rn.ftz.f32 	%f477, %f252, %f477, %f263;
	fma.rn.ftz.f32 	%f478, %f252, %f478, %f264;
	add.s64 	%rd101, %rd82, 96;
	// begin inline asm
	cvta.to.global.u64 %rd100, %rd101;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r102,%r103,%r104,%r105}, [%rd100];
	// end inline asm
	mov.b32 	%f265, %r103;
	mov.b32 	%f266, %r104;
	mov.b32 	%f267, %r105;
	mul.ftz.f32 	%f268, %f42, %f265;
	mul.ftz.f32 	%f269, %f42, %f266;
	mul.ftz.f32 	%f270, %f42, %f267;
	fma.rn.ftz.f32 	%f271, %f252, %f479, %f268;
	fma.rn.ftz.f32 	%f272, %f252, %f480, %f269;
	fma.rn.ftz.f32 	%f273, %f252, %f481, %f270;
	add.s64 	%rd104, %rd82, 112;
	// begin inline asm
	cvta.to.global.u64 %rd103, %rd104;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r106,%r107,%r108,%r109}, [%rd103];
	// end inline asm
	mov.b32 	%f274, %r106;
	mul.ftz.f32 	%f275, %f42, %f274;
	fma.rn.ftz.f32 	%f276, %f252, %f482, %f275;
	mul.ftz.f32 	%f277, %f272, %f272;
	fma.rn.ftz.f32 	%f278, %f271, %f271, %f277;
	fma.rn.ftz.f32 	%f279, %f273, %f273, %f278;
	fma.rn.ftz.f32 	%f280, %f276, %f276, %f279;
	rsqrt.approx.ftz.f32 	%f281, %f280;
	mul.ftz.f32 	%f479, %f271, %f281;
	mul.ftz.f32 	%f480, %f272, %f281;
	mul.ftz.f32 	%f481, %f273, %f281;
	mul.ftz.f32 	%f482, %f281, %f276;

$L__BB5_18:
	mul.ftz.f32 	%f282, %f480, %f480;
	mul.ftz.f32 	%f283, %f479, %f479;
	sub.ftz.f32 	%f284, %f283, %f282;
	mul.ftz.f32 	%f285, %f481, %f481;
	sub.ftz.f32 	%f286, %f284, %f285;
	fma.rn.ftz.f32 	%f287, %f482, %f482, %f286;
	mul.ftz.f32 	%f288, %f481, %f482;
	mul.ftz.f32 	%f289, %f479, %f480;
	sub.ftz.f32 	%f290, %f289, %f288;
	add.ftz.f32 	%f291, %f290, %f290;
	mul.ftz.f32 	%f292, %f480, %f482;
	mul.ftz.f32 	%f293, %f479, %f481;
	add.ftz.f32 	%f294, %f293, %f292;
	add.ftz.f32 	%f295, %f294, %f294;
	add.ftz.f32 	%f296, %f289, %f288;
	add.ftz.f32 	%f297, %f296, %f296;
	sub.ftz.f32 	%f298, %f282, %f283;
	sub.ftz.f32 	%f299, %f298, %f285;
	fma.rn.ftz.f32 	%f300, %f482, %f482, %f299;
	mul.ftz.f32 	%f301, %f479, %f482;
	mul.ftz.f32 	%f302, %f480, %f481;
	sub.ftz.f32 	%f303, %f302, %f301;
	add.ftz.f32 	%f304, %f303, %f303;
	sub.ftz.f32 	%f305, %f293, %f292;
	add.ftz.f32 	%f306, %f305, %f305;
	add.ftz.f32 	%f307, %f302, %f301;
	add.ftz.f32 	%f308, %f307, %f307;
	neg.ftz.f32 	%f309, %f283;
	sub.ftz.f32 	%f310, %f309, %f282;
	add.ftz.f32 	%f311, %f310, %f285;
	fma.rn.ftz.f32 	%f312, %f482, %f482, %f311;
	mul.ftz.f32 	%f313, %f477, %f291;
	fma.rn.ftz.f32 	%f314, %f475, %f287, %f313;
	fma.rn.ftz.f32 	%f491, %f478, %f295, %f314;
	mul.ftz.f32 	%f315, %f475, %f297;
	fma.rn.ftz.f32 	%f316, %f477, %f300, %f315;
	fma.rn.ftz.f32 	%f488, %f478, %f304, %f316;
	mul.ftz.f32 	%f317, %f477, %f308;
	fma.rn.ftz.f32 	%f318, %f475, %f306, %f317;
	fma.rn.ftz.f32 	%f485, %f478, %f312, %f318;
	mul.ftz.f32 	%f319, %f476, %f291;
	fma.rn.ftz.f32 	%f490, %f474, %f287, %f319;
	mul.ftz.f32 	%f320, %f474, %f297;
	fma.rn.ftz.f32 	%f487, %f476, %f300, %f320;
	mul.ftz.f32 	%f321, %f476, %f308;
	fma.rn.ftz.f32 	%f484, %f474, %f306, %f321;
	mul.ftz.f32 	%f489, %f473, %f287;
	mul.ftz.f32 	%f486, %f473, %f297;
	mul.ftz.f32 	%f483, %f473, %f306;

$L__BB5_21:
	mul.ftz.f32 	%f356, %f484, %f488;
	mul.ftz.f32 	%f357, %f485, %f487;
	sub.ftz.f32 	%f358, %f357, %f356;
	mul.ftz.f32 	%f359, %f489, %f358;
	mul.ftz.f32 	%f360, %f483, %f488;
	mul.ftz.f32 	%f361, %f485, %f486;
	sub.ftz.f32 	%f362, %f361, %f360;
	mul.ftz.f32 	%f363, %f362, %f490;
	sub.ftz.f32 	%f364, %f359, %f363;
	mul.ftz.f32 	%f365, %f483, %f487;
	mul.ftz.f32 	%f366, %f484, %f486;
	sub.ftz.f32 	%f367, %f366, %f365;
	fma.rn.ftz.f32 	%f368, %f367, %f491, %f364;
	rcp.approx.ftz.f32 	%f369, %f368;
	mul.ftz.f32 	%f498, %f358, %f369;
	mul.ftz.f32 	%f370, %f485, %f490;
	mul.ftz.f32 	%f371, %f484, %f491;
	sub.ftz.f32 	%f372, %f371, %f370;
	mul.ftz.f32 	%f499, %f372, %f369;
	mul.ftz.f32 	%f373, %f487, %f491;
	mul.ftz.f32 	%f374, %f488, %f490;
	sub.ftz.f32 	%f375, %f374, %f373;
	mul.ftz.f32 	%f500, %f375, %f369;
	sub.ftz.f32 	%f376, %f360, %f361;
	mul.ftz.f32 	%f495, %f376, %f369;
	mul.ftz.f32 	%f377, %f483, %f491;
	mul.ftz.f32 	%f378, %f485, %f489;
	sub.ftz.f32 	%f379, %f378, %f377;
	mul.ftz.f32 	%f496, %f379, %f369;
	mul.ftz.f32 	%f380, %f488, %f489;
	mul.ftz.f32 	%f381, %f486, %f491;
	sub.ftz.f32 	%f382, %f381, %f380;
	mul.ftz.f32 	%f497, %f382, %f369;
	mul.ftz.f32 	%f492, %f367, %f369;
	mul.ftz.f32 	%f383, %f484, %f489;
	mul.ftz.f32 	%f384, %f483, %f490;
	sub.ftz.f32 	%f385, %f384, %f383;
	mul.ftz.f32 	%f493, %f385, %f369;
	mul.ftz.f32 	%f386, %f486, %f490;
	mul.ftz.f32 	%f387, %f487, %f489;
	sub.ftz.f32 	%f388, %f387, %f386;
	mul.ftz.f32 	%f494, %f388, %f369;
	bra.uni 	$L__BB5_22;

$L__BB5_12:
	// begin inline asm
	call (%rd36), _optix_get_static_transform_from_handle, (%rd34);
	// end inline asm
	add.s64 	%rd153, %rd36, 64;

$L__BB5_14:
	// begin inline asm
	cvta.to.global.u64 %rd40, %rd153;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r23,%r24,%r25,%r26}, [%rd40];
	// end inline asm
	mov.b32 	%f498, %r23;
	mov.b32 	%f499, %r24;
	mov.b32 	%f500, %r25;
	add.s64 	%rd44, %rd153, 16;
	// begin inline asm
	cvta.to.global.u64 %rd43, %rd44;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r27,%r28,%r29,%r30}, [%rd43];
	// end inline asm
	mov.b32 	%f495, %r27;
	mov.b32 	%f496, %r28;
	mov.b32 	%f497, %r29;
	add.s64 	%rd47, %rd153, 32;
	// begin inline asm
	cvta.to.global.u64 %rd46, %rd47;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r31,%r32,%r33,%r34}, [%rd46];
	// end inline asm
	mov.b32 	%f492, %r31;
	mov.b32 	%f493, %r32;
	mov.b32 	%f494, %r33;

$L__BB5_22:
	setp.eq.s32 	%p16, %r173, 0;
	@%p16 bra 	$L__BB5_24;

	mul.ftz.f32 	%f389, %f469, %f499;
	fma.rn.ftz.f32 	%f390, %f466, %f498, %f389;
	fma.rn.ftz.f32 	%f128, %f472, %f500, %f390;
	mul.ftz.f32 	%f391, %f468, %f499;
	fma.rn.ftz.f32 	%f392, %f465, %f498, %f391;
	fma.rn.ftz.f32 	%f129, %f471, %f500, %f392;
	mul.ftz.f32 	%f393, %f467, %f499;
	fma.rn.ftz.f32 	%f394, %f464, %f498, %f393;
	fma.rn.ftz.f32 	%f500, %f470, %f500, %f394;
	mul.ftz.f32 	%f395, %f469, %f496;
	fma.rn.ftz.f32 	%f396, %f466, %f495, %f395;
	fma.rn.ftz.f32 	%f131, %f472, %f497, %f396;
	mul.ftz.f32 	%f397, %f468, %f496;
	fma.rn.ftz.f32 	%f398, %f465, %f495, %f397;
	fma.rn.ftz.f32 	%f132, %f471, %f497, %f398;
	mul.ftz.f32 	%f399, %f467, %f496;
	fma.rn.ftz.f32 	%f400, %f464, %f495, %f399;
	fma.rn.ftz.f32 	%f497, %f470, %f497, %f400;
	mul.ftz.f32 	%f401, %f469, %f493;
	fma.rn.ftz.f32 	%f402, %f466, %f492, %f401;
	fma.rn.ftz.f32 	%f134, %f472, %f494, %f402;
	mul.ftz.f32 	%f403, %f468, %f493;
	fma.rn.ftz.f32 	%f404, %f465, %f492, %f403;
	fma.rn.ftz.f32 	%f135, %f471, %f494, %f404;
	mul.ftz.f32 	%f405, %f467, %f493;
	fma.rn.ftz.f32 	%f406, %f464, %f492, %f405;
	fma.rn.ftz.f32 	%f494, %f470, %f494, %f406;
	mov.f32 	%f492, %f134;
	mov.f32 	%f493, %f135;
	mov.f32 	%f495, %f131;
	mov.f32 	%f496, %f132;
	mov.f32 	%f498, %f128;
	mov.f32 	%f499, %f129;

$L__BB5_24:
	add.s32 	%r173, %r173, 1;
	setp.lt.u32 	%p17, %r173, %r18;
	mov.f32 	%f464, %f500;
	mov.f32 	%f465, %f499;
	mov.f32 	%f466, %f498;
	mov.f32 	%f467, %f497;
	mov.f32 	%f468, %f496;
	mov.f32 	%f469, %f495;
	mov.f32 	%f470, %f494;
	mov.f32 	%f471, %f493;
	mov.f32 	%f472, %f492;
	@%p17 bra 	$L__BB5_8;

$L__BB5_25:
	mul.ftz.f32 	%f407, %f519, %f498;
	fma.rn.ftz.f32 	%f408, %f520, %f495, %f407;
	mul.ftz.f32 	%f409, %f519, %f499;
	fma.rn.ftz.f32 	%f410, %f520, %f496, %f409;
	mul.ftz.f32 	%f411, %f519, %f500;
	fma.rn.ftz.f32 	%f412, %f520, %f497, %f411;
	fma.rn.ftz.f32 	%f521, %f22, %f494, %f412;
	fma.rn.ftz.f32 	%f520, %f22, %f493, %f410;
	fma.rn.ftz.f32 	%f519, %f22, %f492, %f408;
	bra.uni 	$L__BB5_27;

$L__BB5_4:
	// begin inline asm
	call _optix_set_payload, (%r14, %r14);
	// end inline asm
	// begin inline asm
	call _optix_terminate_ray, ();
	// end inline asm
	bra.uni 	$L__BB5_33;

$L__BB5_26:
	mov.f32 	%f521, %f22;

$L__BB5_27:
	mul.ftz.f32 	%f414, %f520, %f520;
	fma.rn.ftz.f32 	%f415, %f519, %f519, %f414;
	fma.rn.ftz.f32 	%f416, %f521, %f521, %f415;
	rsqrt.approx.ftz.f32 	%f417, %f416;
	mov.f32 	%f413, 0f3F800000;
	mul.ftz.f32 	%f418, %f519, %f417;
	mul.ftz.f32 	%f419, %f520, %f417;
	mul.ftz.f32 	%f420, %f521, %f417;
	mul.ftz.f32 	%f421, %f18, %f419;
	fma.rn.ftz.f32 	%f422, %f17, %f418, %f421;
	fma.rn.ftz.f32 	%f423, %f19, %f420, %f422;
	setp.gt.ftz.f32 	%p18, %f423, 0f00000000;
	neg.ftz.f32 	%f424, %f418;
	neg.ftz.f32 	%f425, %f419;
	neg.ftz.f32 	%f426, %f420;
	selp.f32 	%f427, %f426, %f420, %p18;
	selp.f32 	%f428, %f425, %f419, %p18;
	selp.f32 	%f429, %f424, %f418, %p18;
	mul.ftz.f32 	%f430, %f18, %f428;
	fma.rn.ftz.f32 	%f431, %f17, %f429, %f430;
	fma.rn.ftz.f32 	%f432, %f19, %f427, %f431;
	abs.ftz.f32 	%f164, %f432;
	ld.const.f32 	%f433, [plp+220];
	mul.ftz.f32 	%f434, %f433, %f433;
	fma.rn.ftz.f32 	%f435, %f164, %f164, %f434;
	add.ftz.f32 	%f165, %f435, 0fBF800000;
	setp.lt.ftz.f32 	%p19, %f165, 0f00000000;
	mov.f32 	%f522, %f413;
	@%p19 bra 	$L__BB5_29;

	sqrt.approx.ftz.f32 	%f436, %f165;
	sub.ftz.f32 	%f437, %f436, %f164;
	add.ftz.f32 	%f438, %f164, %f436;
	div.approx.ftz.f32 	%f439, %f437, %f438;
	mul.ftz.f32 	%f440, %f439, %f439;
	mul.ftz.f32 	%f441, %f440, 0f3F000000;
	fma.rn.ftz.f32 	%f442, %f164, %f438, 0fBF800000;
	fma.rn.ftz.f32 	%f443, %f164, %f437, 0f3F800000;
	div.approx.ftz.f32 	%f444, %f442, %f443;
	fma.rn.ftz.f32 	%f445, %f444, %f444, 0f3F800000;
	mul.ftz.f32 	%f522, %f441, %f445;

$L__BB5_29:
	sub.ftz.f32 	%f447, %f413, %f522;
	mul.ftz.f32 	%f448, %f463, %f447;
	mul.ftz.f32 	%f523, %f9, %f448;
	ld.const.u8 	%rs1, [plp+216];
	and.b16  	%rs2, %rs1, 2;
	setp.eq.s16 	%p20, %rs2, 0;
	@%p20 bra 	$L__BB5_31;

	mul.ftz.f32 	%f449, %f13, 0fBF000000;
	mul.ftz.f32 	%f450, %f449, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f451, %f450;
	mul.ftz.f32 	%f452, %f14, 0fBF000000;
	mul.ftz.f32 	%f453, %f452, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f454, %f453;
	mul.ftz.f32 	%f455, %f15, 0fBF000000;
	mul.ftz.f32 	%f456, %f455, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f457, %f456;
	mul.ftz.f32 	%f458, %f454, 0f3F371759;
	fma.rn.ftz.f32 	%f459, %f451, 0f3E59B3D0, %f458;
	fma.rn.ftz.f32 	%f460, %f457, 0f3D93DD98, %f459;
	mul.ftz.f32 	%f523, %f523, %f460;

$L__BB5_31:
	mov.b32 	%f461, %r13;
	mul.ftz.f32 	%f462, %f523, %f461;
	mov.b32 	%r170, %f462;
	mov.u32 	%r169, 0;
	// begin inline asm
	call _optix_set_payload, (%r169, %r170);
	// end inline asm
	setp.gt.ftz.f32 	%p21, %f462, 0f3C23D70A;
	@%p21 bra 	$L__BB5_33;

	// begin inline asm
	call _optix_set_payload, (%r169, %r169);
	// end inline asm
	// begin inline asm
	call _optix_terminate_ray, ();
	// end inline asm

$L__BB5_33:
	ret;

}

